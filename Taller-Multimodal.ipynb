{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de las imagenes y las clases\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (1500, 784), (1500,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]/255.\n",
    "y=mnist[:,0]\n",
    "print (\"dimension de las imagenes y las clases\"), X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 784) (300, 10) (1200, 784) (1200, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X[:300], X[300:], y[:300], y[300:]\n",
    "y_train_oh = np.eye(10)[y_train]\n",
    "y_test_oh  = np.eye(10)[y_test]\n",
    "print( X_train.shape, y_train_oh.shape,  X_test.shape, y_test_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architectures lab\n",
    "\n",
    "\n",
    "from the notes we have two architectures:\n",
    "    \n",
    "- **A**: Three layer network accepting a 784 element vector as input and outputing a 10-class vector\n",
    "- **B**: Same as **A** but accepts an additional 2 element vector with _evenness_ information that is injected at the third layer.\n",
    "\n",
    "This lab requires you to do two things:\n",
    "\n",
    "**1**. Create a **C** architecture similar to **B** but where the 2 element vector is injected at the second layer. This will make the network have 41,650 parameters, distributed in the following way:\n",
    "   \n",
    "   \n",
    "\n",
    "        INPUT 1 to LAYER 1:              784*50 + 50 (bias) = 39250\n",
    "        LAYER 1 to LAYER 2:               50*30 + 30 (bias) = 1530\n",
    "        LAYER 2 + INPUT 2 to LAYER 3: (30+2)*20 + 20 (bias) = 660\n",
    "        LAYER 3 to OUTPUT:                20*10 + 10 (bias) = 210\n",
    "    \n",
    "                                                       TOTAL 41650\n",
    "                                                       \n",
    "**2**. Run an experimental setup where you train different network configurations and measure the accuracy on test data. Fix the number of neurons to 50, 30 and 20 for each layer and the following combination of parameters:\n",
    "\n",
    "- For architecture **A** (3 configurations)\n",
    "\n",
    "    `s3_activation` $\\in$ `[\"linear\", \"relu\", \"tanh\"]`\n",
    "\n",
    "- For architectures **B** and **C** (15 configurations for each architecture)\n",
    "\n",
    "    `s3_activation` $\\in$ `[\"linear\", \"relu\", \"tanh\"]`\n",
    "    \n",
    "    `k1,k2` $\\in$ `[(0,1), (-.5,2),(-.5,30), (0,15),(0,30)]`\n",
    "\n",
    "And create a heat map showing the accuracy in test obtained for each configuration, such as the following (your results should be approximate to this):\n",
    "\n",
    "![alt text](./Images/mm_results_1.png)\n",
    "\n",
    "\n",
    "And two bar plots with the average per architecture and k1,k2 configuration, such as the following (again, your results should be approximetely similar):\n",
    "\n",
    "![alt text](./Images/mm_results_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_A(input_dim, s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(s1, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(s2, activation='relu'))\n",
    "    model.add(Dense(s3, activation=s3_activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_B(input_dim, extra_info_dim,  s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    inp1 = Input(shape=(input_dim,))\n",
    "    l11 = Dense(s1, activation=\"relu\")(inp1)\n",
    "    l12 = Dense(s2, activation=\"relu\")(l11)\n",
    "    l13 = Dense(s3, activation=s3_activation)(l12)\n",
    "    inp2 = Input(shape=(extra_info_dim,))\n",
    "    cc1 = concatenate([l13, inp2],axis=1) # Merge row, same column\n",
    "    output = Dense(10, activation='softmax')(cc1)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_C(input_dim, extra_info_dim,  s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    inp1 = Input(shape=(input_dim,))\n",
    "    l11 = Dense(s1, activation=\"relu\")(inp1)\n",
    "    l12 = Dense(s2, activation=\"relu\")(l11)\n",
    "    inp2 = Input(shape=(extra_info_dim,))\n",
    "    cc1 = concatenate([l12, inp2],axis=1) # Merge row, same column\n",
    "    l13 = Dense(s3, activation=s3_activation)(cc1)\n",
    "    output = Dense(10, activation='softmax')(l13)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_extra(y_train, y_test, k0, k1):\n",
    "    X_train_extra = (np.eye(2)[y_train%2]+k0)*k1\n",
    "    X_test_extra  = (np.eye(2)[y_test%2]+k0)*k1\n",
    "    return X_train_extra, X_test_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following dataframe to record your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(-0.5, 2)</th>\n",
       "      <th>(-0.5, 30)</th>\n",
       "      <th>(0, 15)</th>\n",
       "      <th>(0, 30)</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          (0, 1)  (-0.5, 2)  (-0.5, 30)  (0, 15)  (0, 30)  None\n",
       "A-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "A-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "A-tanh       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-tanh       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-tanh       NaN        NaN         NaN      NaN      NaN   NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_set     = [(0,1), (-.5,2),(-.5,30), (0,15),(0,30), None]\n",
    "act_set   = [\"linear\", \"relu\", \"tanh\"]\n",
    "arch_set  = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "\n",
    "r_test = pd.DataFrame(np.zeros((len(arch_set)*len(act_set), len(k_set)))*np.nan, \n",
    "                      index=[[a+\"-\"+b for a,b in itertools.product (arch_set, act_set)]],\n",
    "                      columns=[str(i) for i in k_set])\n",
    "r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a loop over the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 2.1628 - val_loss: 2.0286\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 1.8144 - val_loss: 1.7422\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 1.4334 - val_loss: 1.4213\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 1.0782 - val_loss: 1.1382\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.7991 - val_loss: 0.9647\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.6133 - val_loss: 0.7987\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.4673 - val_loss: 0.7720\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.3676 - val_loss: 0.6912\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.2952 - val_loss: 0.6616\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.2303 - val_loss: 0.6491\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.1894 - val_loss: 0.6486\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.1553 - val_loss: 0.6158\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.1255 - val_loss: 0.6321\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.1063 - val_loss: 0.6261\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.0847 - val_loss: 0.6183\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0717 - val_loss: 0.6123\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0602 - val_loss: 0.6350\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0517 - val_loss: 0.6211\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0428 - val_loss: 0.6249\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0372 - val_loss: 0.6324\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0322 - val_loss: 0.6294\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0280 - val_loss: 0.6309\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0248 - val_loss: 0.6417\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0225 - val_loss: 0.6433\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0198 - val_loss: 0.6374\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0178 - val_loss: 0.6495\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0164 - val_loss: 0.6546\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0146 - val_loss: 0.6544\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.0134 - val_loss: 0.6548\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0122 - val_loss: 0.6642\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0113 - val_loss: 0.6635\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0105 - val_loss: 0.6697\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0097 - val_loss: 0.6746\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0091 - val_loss: 0.6814\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0084 - val_loss: 0.6788\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0079 - val_loss: 0.6829\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0074 - val_loss: 0.6843\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0069 - val_loss: 0.6944\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0064 - val_loss: 0.6935\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0061 - val_loss: 0.6973\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0058 - val_loss: 0.7073\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0055 - val_loss: 0.7007\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0051 - val_loss: 0.7083\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 0.0049 - val_loss: 0.7134\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0046 - val_loss: 0.7215\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0044 - val_loss: 0.7211\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.0042 - val_loss: 0.7189\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0040 - val_loss: 0.7210\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0038 - val_loss: 0.7253\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0037 - val_loss: 0.7373\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0035 - val_loss: 0.7272\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0034 - val_loss: 0.7339\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0032 - val_loss: 0.7365\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0031 - val_loss: 0.7412\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.0030 - val_loss: 0.7470\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0028 - val_loss: 0.7423\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.0027 - val_loss: 0.7450\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0026 - val_loss: 0.7488\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0025 - val_loss: 0.7516\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0024 - val_loss: 0.7555\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0024 - val_loss: 0.7571\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.0023 - val_loss: 0.7596\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0022 - val_loss: 0.7630\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0021 - val_loss: 0.7649\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0020 - val_loss: 0.7659\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0020 - val_loss: 0.7724\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.0019 - val_loss: 0.7773\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0019 - val_loss: 0.7731\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.7768\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0017 - val_loss: 0.7798\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0017 - val_loss: 0.7811\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0016 - val_loss: 0.7804\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0016 - val_loss: 0.7859\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.7867\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.7862\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.7898\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0014 - val_loss: 0.7932\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.0014 - val_loss: 0.7957\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0013 - val_loss: 0.7945\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0013 - val_loss: 0.7978\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0013 - val_loss: 0.8032\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0012 - val_loss: 0.8032\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.8010\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0012 - val_loss: 0.8017\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0011 - val_loss: 0.8055\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0011 - val_loss: 0.8047\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0011 - val_loss: 0.8072\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0011 - val_loss: 0.8129\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0010 - val_loss: 0.8148\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0010 - val_loss: 0.8164\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 9.8589e-04 - val_loss: 0.8175\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 9.6433e-04 - val_loss: 0.8174\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 9.4277e-04 - val_loss: 0.8182\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 9.2138e-04 - val_loss: 0.8202\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 9.0151e-04 - val_loss: 0.8224\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 8.8100e-04 - val_loss: 0.8232\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 8.6166e-04 - val_loss: 0.8252\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 8.4314e-04 - val_loss: 0.8287\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 8.2512e-04 - val_loss: 0.8292\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 8.0912e-04 - val_loss: 0.8272\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 7.9308e-04 - val_loss: 0.8330\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 7.7374e-04 - val_loss: 0.8319\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 7.5761e-04 - val_loss: 0.8332\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 7.4146e-04 - val_loss: 0.8355\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 7.2681e-04 - val_loss: 0.8374\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 7.1293e-04 - val_loss: 0.8379\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 6.9810e-04 - val_loss: 0.8417\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 6.8402e-04 - val_loss: 0.8427\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 6.7020e-04 - val_loss: 0.8437\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 6.5744e-04 - val_loss: 0.8450\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 6.4594e-04 - val_loss: 0.8473\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 6.3321e-04 - val_loss: 0.8482\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 6.2086e-04 - val_loss: 0.8488\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 6.0896e-04 - val_loss: 0.8516\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 5.9764e-04 - val_loss: 0.8526\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 5.8615e-04 - val_loss: 0.8539\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.7611e-04 - val_loss: 0.8560\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 5.6529e-04 - val_loss: 0.8560\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.5451e-04 - val_loss: 0.8561\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 5.4586e-04 - val_loss: 0.8567\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 5.3579e-04 - val_loss: 0.8592\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 5.2632e-04 - val_loss: 0.8620\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 5.1716e-04 - val_loss: 0.8610\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 5.0852e-04 - val_loss: 0.8626\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 4.9966e-04 - val_loss: 0.8661\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 4.9139e-04 - val_loss: 0.8673\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 4.8184e-04 - val_loss: 0.8660\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 4.7484e-04 - val_loss: 0.8684\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 4.6629e-04 - val_loss: 0.8684\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 4.5820e-04 - val_loss: 0.8705\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.5063e-04 - val_loss: 0.8708\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 4.4305e-04 - val_loss: 0.8708\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 4.3599e-04 - val_loss: 0.8737\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.2828e-04 - val_loss: 0.8754\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 4.2192e-04 - val_loss: 0.8755\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 4.1531e-04 - val_loss: 0.8766\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 246us/step - loss: 4.1002e-04 - val_loss: 0.8815\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 4.0238e-04 - val_loss: 0.8797\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 3.9601e-04 - val_loss: 0.8785\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 3.8969e-04 - val_loss: 0.8796\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.8397e-04 - val_loss: 0.8809\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.7772e-04 - val_loss: 0.8834\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 3.7197e-04 - val_loss: 0.8856\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.6672e-04 - val_loss: 0.8854\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.6051e-04 - val_loss: 0.8857\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 242us/step - loss: 3.5546e-04 - val_loss: 0.8858\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 3.5090e-04 - val_loss: 0.8859\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 3.4446e-04 - val_loss: 0.8891\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 3.3972e-04 - val_loss: 0.8921\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.3464e-04 - val_loss: 0.8943\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.2990e-04 - val_loss: 0.8938\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.2504e-04 - val_loss: 0.8954\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.2036e-04 - val_loss: 0.8957\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 3.1563e-04 - val_loss: 0.8963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 3.1117e-04 - val_loss: 0.8985\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 242us/step - loss: 3.0627e-04 - val_loss: 0.8991\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.0250e-04 - val_loss: 0.8983\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 2.9861e-04 - val_loss: 0.9004\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 2.9410e-04 - val_loss: 0.9032\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8987e-04 - val_loss: 0.9046\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8619e-04 - val_loss: 0.9050\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8195e-04 - val_loss: 0.9051\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 2.7775e-04 - val_loss: 0.9065\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.7412e-04 - val_loss: 0.9075\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 2.7059e-04 - val_loss: 0.9087\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 2.6681e-04 - val_loss: 0.9089\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.6348e-04 - val_loss: 0.9101\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 2.5977e-04 - val_loss: 0.9118\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 2.5643e-04 - val_loss: 0.9121\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.5313e-04 - val_loss: 0.9129\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 2.4986e-04 - val_loss: 0.9140\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 2.4613e-04 - val_loss: 0.9154\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 2.4314e-04 - val_loss: 0.9164\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.3973e-04 - val_loss: 0.9168\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.3669e-04 - val_loss: 0.9171\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 2.3357e-04 - val_loss: 0.9180\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.3050e-04 - val_loss: 0.9197\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 2.2790e-04 - val_loss: 0.9212\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 2.2492e-04 - val_loss: 0.9232\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 2.2207e-04 - val_loss: 0.9227\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 2.1914e-04 - val_loss: 0.9250\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.1641e-04 - val_loss: 0.9245\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.1366e-04 - val_loss: 0.9236\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.1097e-04 - val_loss: 0.9252\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 2.0832e-04 - val_loss: 0.9271\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.0592e-04 - val_loss: 0.9291\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 2.0340e-04 - val_loss: 0.9294\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0090e-04 - val_loss: 0.9289\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.9828e-04 - val_loss: 0.9309\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.9584e-04 - val_loss: 0.9320\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.9341e-04 - val_loss: 0.9325\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 1.9105e-04 - val_loss: 0.9328\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.8897e-04 - val_loss: 0.9332\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 1.8658e-04 - val_loss: 0.9351\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 1.8455e-04 - val_loss: 0.9358\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 1.8242e-04 - val_loss: 0.9357\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 1.8030e-04 - val_loss: 0.9379\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 1.7813e-04 - val_loss: 0.9388\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.7602e-04 - val_loss: 0.9391\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 1.7403e-04 - val_loss: 0.9393\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.1678 - val_loss: 2.0300\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.8791 - val_loss: 1.7863\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.5718 - val_loss: 1.5172\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.2772 - val_loss: 1.2950\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.0266 - val_loss: 1.1021\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.8242 - val_loss: 0.9455\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.6609 - val_loss: 0.8246\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.5254 - val_loss: 0.7563\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.4196 - val_loss: 0.7011\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.3393 - val_loss: 0.6703\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.2728 - val_loss: 0.6255\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.2322 - val_loss: 0.6270\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.1818 - val_loss: 0.5982\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.1460 - val_loss: 0.5912\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.1150 - val_loss: 0.5894\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0963 - val_loss: 0.6034\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0800 - val_loss: 0.5869\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0654 - val_loss: 0.5971\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0552 - val_loss: 0.5934\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0485 - val_loss: 0.5904\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0423 - val_loss: 0.6129\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0349 - val_loss: 0.5969\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0304 - val_loss: 0.6051\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0269 - val_loss: 0.6166\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0236 - val_loss: 0.6142\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0211 - val_loss: 0.6244\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0188 - val_loss: 0.6258\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0170 - val_loss: 0.6323\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0157 - val_loss: 0.6369\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0144 - val_loss: 0.6488\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0131 - val_loss: 0.6448\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0119 - val_loss: 0.6457\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0111 - val_loss: 0.6483\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0102 - val_loss: 0.6533\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0094 - val_loss: 0.6582\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0088 - val_loss: 0.6637\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0083 - val_loss: 0.6648\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0077 - val_loss: 0.6693\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0073 - val_loss: 0.6728\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0069 - val_loss: 0.6758\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0065 - val_loss: 0.6813\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0061 - val_loss: 0.6828\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0058 - val_loss: 0.6842\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0055 - val_loss: 0.6875\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0052 - val_loss: 0.6946\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.6983\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0047 - val_loss: 0.6997\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0045 - val_loss: 0.7021\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0043 - val_loss: 0.7099\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0041 - val_loss: 0.7111\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0039 - val_loss: 0.7145\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0037 - val_loss: 0.7160\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.0036 - val_loss: 0.7186\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0034 - val_loss: 0.7193\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0033 - val_loss: 0.7233\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0031 - val_loss: 0.7238\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0030 - val_loss: 0.7265\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0029 - val_loss: 0.7290\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0028 - val_loss: 0.7337\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0027 - val_loss: 0.7351\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0026 - val_loss: 0.7368\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0025 - val_loss: 0.7395\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0024 - val_loss: 0.7428\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0023 - val_loss: 0.7430\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0022 - val_loss: 0.7458\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0022 - val_loss: 0.7491\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0021 - val_loss: 0.7534\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0020 - val_loss: 0.7537\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0020 - val_loss: 0.7574\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0019 - val_loss: 0.7601\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0018 - val_loss: 0.7600\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0018 - val_loss: 0.7635\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0017 - val_loss: 0.7669\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0017 - val_loss: 0.7688\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0016 - val_loss: 0.7716\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0016 - val_loss: 0.7720\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0015 - val_loss: 0.7741\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0015 - val_loss: 0.7763\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0015 - val_loss: 0.7783\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0014 - val_loss: 0.7805\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0014 - val_loss: 0.7826\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.0013 - val_loss: 0.7851\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0013 - val_loss: 0.7852\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 0.0013 - val_loss: 0.7871\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0012 - val_loss: 0.7886\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0012 - val_loss: 0.7902\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0012 - val_loss: 0.7928\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0011 - val_loss: 0.7953\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0011 - val_loss: 0.7973\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0011 - val_loss: 0.8003\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0011 - val_loss: 0.8028\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0010 - val_loss: 0.8035\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0010 - val_loss: 0.8053\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 9.9486e-04 - val_loss: 0.8068\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 9.7258e-04 - val_loss: 0.8093\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 9.5151e-04 - val_loss: 0.8103\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 9.2757e-04 - val_loss: 0.8112\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 9.0697e-04 - val_loss: 0.8122\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 8.8935e-04 - val_loss: 0.8144\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 242us/step - loss: 8.7177e-04 - val_loss: 0.8138\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 8.4979e-04 - val_loss: 0.8151\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 8.2951e-04 - val_loss: 0.8163\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 8.1208e-04 - val_loss: 0.8178\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 7.9585e-04 - val_loss: 0.8190\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 7.8280e-04 - val_loss: 0.8233\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 7.6610e-04 - val_loss: 0.8259\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 7.4755e-04 - val_loss: 0.8260\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 7.3117e-04 - val_loss: 0.8271\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 201us/step - loss: 7.1721e-04 - val_loss: 0.8279\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 7.0158e-04 - val_loss: 0.8301\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 6.8735e-04 - val_loss: 0.8310\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 6.7377e-04 - val_loss: 0.8317\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 6.6084e-04 - val_loss: 0.8336\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 6.5008e-04 - val_loss: 0.8360\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 6.3853e-04 - val_loss: 0.8376\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 6.2604e-04 - val_loss: 0.8381\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 6.1357e-04 - val_loss: 0.8386\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 6.0321e-04 - val_loss: 0.8381\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 5.9261e-04 - val_loss: 0.8406\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 5.8028e-04 - val_loss: 0.8415\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.6960e-04 - val_loss: 0.8425\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.5972e-04 - val_loss: 0.8435\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.4944e-04 - val_loss: 0.8458\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 5.3922e-04 - val_loss: 0.8480\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 5.2914e-04 - val_loss: 0.8492\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 5.1986e-04 - val_loss: 0.8501\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 5.1108e-04 - val_loss: 0.8514\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 5.0262e-04 - val_loss: 0.8537\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 4.9314e-04 - val_loss: 0.8542\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 4.8433e-04 - val_loss: 0.8538\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 4.7636e-04 - val_loss: 0.8556\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 4.6837e-04 - val_loss: 0.8560\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.6101e-04 - val_loss: 0.8577\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 4.5322e-04 - val_loss: 0.8592\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.4484e-04 - val_loss: 0.8605\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 4.3816e-04 - val_loss: 0.8613\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.3114e-04 - val_loss: 0.8623\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 4.2415e-04 - val_loss: 0.8635\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 4.1838e-04 - val_loss: 0.8646\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.1068e-04 - val_loss: 0.8660\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.0398e-04 - val_loss: 0.8667\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.9821e-04 - val_loss: 0.8681\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 3.9185e-04 - val_loss: 0.8691\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 3.8543e-04 - val_loss: 0.8705\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 3.7977e-04 - val_loss: 0.8721\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.7381e-04 - val_loss: 0.8729\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.6883e-04 - val_loss: 0.8748\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.6219e-04 - val_loss: 0.8752\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.5791e-04 - val_loss: 0.8762\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.5183e-04 - val_loss: 0.8777\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 3.4669e-04 - val_loss: 0.8789\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.4193e-04 - val_loss: 0.8797\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 3.3661e-04 - val_loss: 0.8811\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.3219e-04 - val_loss: 0.8827\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.2676e-04 - val_loss: 0.8837\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.2229e-04 - val_loss: 0.8849\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 3.1832e-04 - val_loss: 0.8869\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.1321e-04 - val_loss: 0.8876\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 3.0876e-04 - val_loss: 0.8889\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 3.0478e-04 - val_loss: 0.8898\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 3.0025e-04 - val_loss: 0.8895\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.9604e-04 - val_loss: 0.8902\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 2.9201e-04 - val_loss: 0.8919\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 2.8791e-04 - val_loss: 0.8927\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 2.8426e-04 - val_loss: 0.8940\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 2.8066e-04 - val_loss: 0.8964\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 2.7631e-04 - val_loss: 0.8972\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 2.7271e-04 - val_loss: 0.8975\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 2.6861e-04 - val_loss: 0.8980\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 2.6505e-04 - val_loss: 0.8988\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.6163e-04 - val_loss: 0.8992\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 2.5821e-04 - val_loss: 0.9000\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.5488e-04 - val_loss: 0.9013\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 2.5155e-04 - val_loss: 0.9031\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 2.4799e-04 - val_loss: 0.9035\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 2.4499e-04 - val_loss: 0.9044\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 2.4200e-04 - val_loss: 0.9048\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 2.3890e-04 - val_loss: 0.9056\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 2.3573e-04 - val_loss: 0.9069\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.3282e-04 - val_loss: 0.9086\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 2.3037e-04 - val_loss: 0.9092\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 2.2724e-04 - val_loss: 0.9106\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 2.2455e-04 - val_loss: 0.9108\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 2.2164e-04 - val_loss: 0.9113\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 2.1898e-04 - val_loss: 0.9127\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 2.1635e-04 - val_loss: 0.9132\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 2.1361e-04 - val_loss: 0.9144\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 2.1122e-04 - val_loss: 0.9156\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 2.0866e-04 - val_loss: 0.9163\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 2.0587e-04 - val_loss: 0.9172\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 2.0364e-04 - val_loss: 0.9181\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 2.0094e-04 - val_loss: 0.9194\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 1.9858e-04 - val_loss: 0.9201\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 1.9630e-04 - val_loss: 0.9214\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 1.9397e-04 - val_loss: 0.9222\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.9191e-04 - val_loss: 0.9220\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 1.8986e-04 - val_loss: 0.9241\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 1.8712e-04 - val_loss: 0.9252\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 1.8490e-04 - val_loss: 0.9259\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 1.8273e-04 - val_loss: 0.9273\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.3698 - val_loss: 2.2698\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 243us/step - loss: 2.1899 - val_loss: 2.0824\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 1.9541 - val_loss: 1.8672\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 1.6933 - val_loss: 1.6515\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.4218 - val_loss: 1.4384\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.1695 - val_loss: 1.2598\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.9640 - val_loss: 1.1344\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.7955 - val_loss: 1.0159\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.6498 - val_loss: 0.9200\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.5317 - val_loss: 0.8451\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.4272 - val_loss: 0.7799\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.3454 - val_loss: 0.7517\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.2837 - val_loss: 0.7217\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.2266 - val_loss: 0.7031\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.1812 - val_loss: 0.6911\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.1558 - val_loss: 0.6825\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.1261 - val_loss: 0.6759\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.1036 - val_loss: 0.6896\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0835 - val_loss: 0.6813\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0713 - val_loss: 0.6879\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0596 - val_loss: 0.6942\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.0501 - val_loss: 0.6873\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.0426 - val_loss: 0.6933\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0370 - val_loss: 0.7011\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.0322 - val_loss: 0.6959\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0278 - val_loss: 0.7013\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0244 - val_loss: 0.7127\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0215 - val_loss: 0.7067\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0192 - val_loss: 0.7220\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.0171 - val_loss: 0.7178\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 0.0152 - val_loss: 0.7198\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.0139 - val_loss: 0.7262\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0125 - val_loss: 0.7295\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.0114 - val_loss: 0.7366\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0105 - val_loss: 0.7386\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0096 - val_loss: 0.7406\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0088 - val_loss: 0.7416\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0082 - val_loss: 0.7491\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0076 - val_loss: 0.7500\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0072 - val_loss: 0.7575\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0067 - val_loss: 0.7564\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0063 - val_loss: 0.7598\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0059 - val_loss: 0.7672\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0056 - val_loss: 0.7667\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0053 - val_loss: 0.7703\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0050 - val_loss: 0.7753\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0047 - val_loss: 0.7766\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0045 - val_loss: 0.7823\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0043 - val_loss: 0.7785\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0040 - val_loss: 0.7826\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0038 - val_loss: 0.7912\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0037 - val_loss: 0.7929\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0035 - val_loss: 0.7880\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0033 - val_loss: 0.7976\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0032 - val_loss: 0.8006\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0030 - val_loss: 0.8025\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0029 - val_loss: 0.8064\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0028 - val_loss: 0.8075\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.0027 - val_loss: 0.8092\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0026 - val_loss: 0.8090\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 240us/step - loss: 0.0025 - val_loss: 0.8156\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.0024 - val_loss: 0.8190\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0023 - val_loss: 0.8180\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0022 - val_loss: 0.8224\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0021 - val_loss: 0.8237\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0020 - val_loss: 0.8266\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0020 - val_loss: 0.8292\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0019 - val_loss: 0.8310\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 0.0018 - val_loss: 0.8312\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0018 - val_loss: 0.8342\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0017 - val_loss: 0.8392\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0016 - val_loss: 0.8412\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0016 - val_loss: 0.8419\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0015 - val_loss: 0.8457\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0015 - val_loss: 0.8481\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0014 - val_loss: 0.8516\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0014 - val_loss: 0.8525\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0014 - val_loss: 0.8566\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0013 - val_loss: 0.8543\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0013 - val_loss: 0.8573\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0012 - val_loss: 0.8627\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0012 - val_loss: 0.8630\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0012 - val_loss: 0.8665\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0011 - val_loss: 0.8672\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0011 - val_loss: 0.8698\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0011 - val_loss: 0.8690\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0011 - val_loss: 0.8723\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0010 - val_loss: 0.8731\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 9.9879e-04 - val_loss: 0.8755\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 9.7547e-04 - val_loss: 0.8776\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 9.5017e-04 - val_loss: 0.8817\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 9.2820e-04 - val_loss: 0.8846\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 9.0358e-04 - val_loss: 0.8865\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 8.8445e-04 - val_loss: 0.8870\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 8.6216e-04 - val_loss: 0.8874\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 8.4221e-04 - val_loss: 0.8895\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 8.2109e-04 - val_loss: 0.8914\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 8.0476e-04 - val_loss: 0.8976\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 7.8810e-04 - val_loss: 0.9001\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 7.6711e-04 - val_loss: 0.8977\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 7.4962e-04 - val_loss: 0.9010\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 7.3237e-04 - val_loss: 0.9032\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 7.1690e-04 - val_loss: 0.9050\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 7.0075e-04 - val_loss: 0.9063\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 6.8613e-04 - val_loss: 0.9050\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 6.7155e-04 - val_loss: 0.9062\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 6.5768e-04 - val_loss: 0.9073\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 6.4510e-04 - val_loss: 0.9117\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 6.3053e-04 - val_loss: 0.9125\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 6.1717e-04 - val_loss: 0.9141\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 6.0484e-04 - val_loss: 0.9175\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 5.9081e-04 - val_loss: 0.9171\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.7989e-04 - val_loss: 0.9192\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 5.6696e-04 - val_loss: 0.9224\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 5.6149e-04 - val_loss: 0.9262\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 5.4657e-04 - val_loss: 0.9230\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 5.3536e-04 - val_loss: 0.9231\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 5.2653e-04 - val_loss: 0.9239\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 5.1593e-04 - val_loss: 0.9265\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 5.0618e-04 - val_loss: 0.9275\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 4.9867e-04 - val_loss: 0.9300\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.8757e-04 - val_loss: 0.9305\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 4.7957e-04 - val_loss: 0.9315\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.7164e-04 - val_loss: 0.9319\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 4.6339e-04 - val_loss: 0.9333\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.5472e-04 - val_loss: 0.9353\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.4594e-04 - val_loss: 0.9366\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.3878e-04 - val_loss: 0.9389\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.3128e-04 - val_loss: 0.9392\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 4.2514e-04 - val_loss: 0.9394\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 4.1697e-04 - val_loss: 0.9417\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 4.0975e-04 - val_loss: 0.9438\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.0305e-04 - val_loss: 0.9443\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 3.9635e-04 - val_loss: 0.9463\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.8938e-04 - val_loss: 0.9470\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.8393e-04 - val_loss: 0.9507\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 3.7742e-04 - val_loss: 0.9512\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 3.7067e-04 - val_loss: 0.9516\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 3.6518e-04 - val_loss: 0.9516\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 3.5909e-04 - val_loss: 0.9539\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 3.5369e-04 - val_loss: 0.9557\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 3.4775e-04 - val_loss: 0.9573\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.4254e-04 - val_loss: 0.9585\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.3693e-04 - val_loss: 0.9587\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 3.3150e-04 - val_loss: 0.9601\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 3.2698e-04 - val_loss: 0.9622\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 3.2138e-04 - val_loss: 0.9622\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.1673e-04 - val_loss: 0.9622\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.1239e-04 - val_loss: 0.9622\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 3.0752e-04 - val_loss: 0.9631\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 3.0260e-04 - val_loss: 0.9663\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 2.9813e-04 - val_loss: 0.9683\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 2.9399e-04 - val_loss: 0.9707\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.8926e-04 - val_loss: 0.9724\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.8498e-04 - val_loss: 0.9722\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 2.8042e-04 - val_loss: 0.9727\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7660e-04 - val_loss: 0.9743\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7294e-04 - val_loss: 0.9754\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 2.6912e-04 - val_loss: 0.9762\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 2.6513e-04 - val_loss: 0.9780\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 2.6135e-04 - val_loss: 0.9789\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 2.5745e-04 - val_loss: 0.9797\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.5418e-04 - val_loss: 0.9813\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.5043e-04 - val_loss: 0.9822\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.4658e-04 - val_loss: 0.9837\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 2.4356e-04 - val_loss: 0.9847\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 2.4036e-04 - val_loss: 0.9862\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.3711e-04 - val_loss: 0.9877\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.3362e-04 - val_loss: 0.9883\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.3043e-04 - val_loss: 0.9882\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 2.2748e-04 - val_loss: 0.9895\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.2450e-04 - val_loss: 0.9907\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.2126e-04 - val_loss: 0.9918\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.1846e-04 - val_loss: 0.9926\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.1575e-04 - val_loss: 0.9933\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 2.1306e-04 - val_loss: 0.9942\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 2.0996e-04 - val_loss: 0.9956\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 2.0716e-04 - val_loss: 0.9968\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 2.0474e-04 - val_loss: 0.9968\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 2.0209e-04 - val_loss: 0.9974\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 1.9943e-04 - val_loss: 0.9998\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 1.9665e-04 - val_loss: 1.0008\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 1.9451e-04 - val_loss: 1.0015\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 1.9201e-04 - val_loss: 1.0019\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 1.8946e-04 - val_loss: 1.0033\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.7789e-0 - 0s 295us/step - loss: 1.8685e-04 - val_loss: 1.0039\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.8490e-04 - val_loss: 1.0044\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 1.8277e-04 - val_loss: 1.0064\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 1.8006e-04 - val_loss: 1.0084\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 1.7811e-04 - val_loss: 1.0096\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 1.7585e-04 - val_loss: 1.0109\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 1.7356e-04 - val_loss: 1.0115\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 1.7164e-04 - val_loss: 1.0119\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 1.6932e-04 - val_loss: 1.0121\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 1.6748e-04 - val_loss: 1.0130\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 1.6548e-04 - val_loss: 1.0139\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 1.6348e-04 - val_loss: 1.0151\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 1.6136e-04 - val_loss: 1.0160\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 1.5953e-04 - val_loss: 1.0163\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 1.5775e-04 - val_loss: 1.0179\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.3289 - val_loss: 2.2325\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 2.1328 - val_loss: 2.1014\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 1.9619 - val_loss: 1.9681\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 1.7939 - val_loss: 1.8291\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 1.6254 - val_loss: 1.6865\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 1.4485 - val_loss: 1.5221\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.2706 - val_loss: 1.3838\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 1.0868 - val_loss: 1.2513\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 242us/step - loss: 0.9171 - val_loss: 1.1299\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.7645 - val_loss: 1.0205\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.6415 - val_loss: 0.9245\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 230us/step - loss: 0.5185 - val_loss: 0.8176\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.4187 - val_loss: 0.7540\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.3255 - val_loss: 0.6967\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.2529 - val_loss: 0.6534\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.2040 - val_loss: 0.6388\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.1673 - val_loss: 0.6166\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.1374 - val_loss: 0.6214\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.1193 - val_loss: 0.6124\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0988 - val_loss: 0.6017\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0830 - val_loss: 0.6137\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0710 - val_loss: 0.6244\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0617 - val_loss: 0.6102\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0535 - val_loss: 0.6352\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0454 - val_loss: 0.6166\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0415 - val_loss: 0.6324\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0339 - val_loss: 0.6285\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0302 - val_loss: 0.6446\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0278 - val_loss: 0.6384\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0238 - val_loss: 0.6475\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0216 - val_loss: 0.6674\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0195 - val_loss: 0.6596\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0173 - val_loss: 0.6575\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0158 - val_loss: 0.6725\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0143 - val_loss: 0.6724\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0131 - val_loss: 0.6804\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.0121 - val_loss: 0.6879\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0113 - val_loss: 0.6929\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0104 - val_loss: 0.6986\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0096 - val_loss: 0.7006\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0090 - val_loss: 0.7091\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0084 - val_loss: 0.7050\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0078 - val_loss: 0.7144\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0073 - val_loss: 0.7084\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0069 - val_loss: 0.7191\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0065 - val_loss: 0.7233\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0061 - val_loss: 0.7294\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0058 - val_loss: 0.7310\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0055 - val_loss: 0.7306\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0053 - val_loss: 0.7370\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0049 - val_loss: 0.7423\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0047 - val_loss: 0.7447\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0045 - val_loss: 0.7452\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0043 - val_loss: 0.7505\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0041 - val_loss: 0.7597\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.7534\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0038 - val_loss: 0.7577\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0036 - val_loss: 0.7704\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 0.0035 - val_loss: 0.7692\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0033 - val_loss: 0.7711\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0032 - val_loss: 0.7690\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0031 - val_loss: 0.7727\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7843\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0028 - val_loss: 0.7800\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0027 - val_loss: 0.7859\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0026 - val_loss: 0.7911\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0026 - val_loss: 0.7849\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0025 - val_loss: 0.7927\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0024 - val_loss: 0.8004\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0023 - val_loss: 0.8019\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0022 - val_loss: 0.8002\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0021 - val_loss: 0.8053\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0021 - val_loss: 0.8060\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0020 - val_loss: 0.8080\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0020 - val_loss: 0.8058\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0019 - val_loss: 0.8133\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.8139\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.8166\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0017 - val_loss: 0.8207\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0017 - val_loss: 0.8242\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0016 - val_loss: 0.8244\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0016 - val_loss: 0.8250\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0015 - val_loss: 0.8276\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0015 - val_loss: 0.8308\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0015 - val_loss: 0.8333\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0014 - val_loss: 0.8316\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0014 - val_loss: 0.8396\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0013 - val_loss: 0.8436\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0013 - val_loss: 0.8432\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0013 - val_loss: 0.8430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0012 - val_loss: 0.8446\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.8484\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 0.0012 - val_loss: 0.8502\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0012 - val_loss: 0.8508\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0011 - val_loss: 0.8549\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0011 - val_loss: 0.8606\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0011 - val_loss: 0.8616\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0010 - val_loss: 0.8615\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0010 - val_loss: 0.8597\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0010 - val_loss: 0.8645\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 9.8217e-04 - val_loss: 0.8645\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 9.5812e-04 - val_loss: 0.8674\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.3929e-04 - val_loss: 0.8692\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 9.1645e-04 - val_loss: 0.8701\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.9719e-04 - val_loss: 0.8697\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.7835e-04 - val_loss: 0.8717\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 8.5916e-04 - val_loss: 0.8738\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 8.4468e-04 - val_loss: 0.8738\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 8.2500e-04 - val_loss: 0.8766\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 8.0780e-04 - val_loss: 0.8814\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 7.8941e-04 - val_loss: 0.8832\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 7.7245e-04 - val_loss: 0.8832\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 7.5868e-04 - val_loss: 0.8840\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 7.4207e-04 - val_loss: 0.8866\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 7.2725e-04 - val_loss: 0.8902\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 7.1399e-04 - val_loss: 0.8916\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 7.0047e-04 - val_loss: 0.8917\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 6.8778e-04 - val_loss: 0.8945\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 6.7385e-04 - val_loss: 0.8962\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 6.6347e-04 - val_loss: 0.8970\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 6.4950e-04 - val_loss: 0.8989\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 6.3696e-04 - val_loss: 0.9002\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 6.2529e-04 - val_loss: 0.9024\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 6.1472e-04 - val_loss: 0.9031\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 6.0271e-04 - val_loss: 0.9058\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 5.9246e-04 - val_loss: 0.9061\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 5.8058e-04 - val_loss: 0.9078\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 188us/step - loss: 5.7026e-04 - val_loss: 0.9093\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 5.6018e-04 - val_loss: 0.9099\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5042e-04 - val_loss: 0.9106\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.4093e-04 - val_loss: 0.9146\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 5.3187e-04 - val_loss: 0.9157\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 5.2221e-04 - val_loss: 0.9167\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 5.1540e-04 - val_loss: 0.9155\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 5.0494e-04 - val_loss: 0.9191\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 4.9672e-04 - val_loss: 0.9204\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.8906e-04 - val_loss: 0.9207\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 4.8072e-04 - val_loss: 0.9233\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 4.7217e-04 - val_loss: 0.9265\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 4.6487e-04 - val_loss: 0.9279\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.5731e-04 - val_loss: 0.9288\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 4.4958e-04 - val_loss: 0.9275\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.4321e-04 - val_loss: 0.9295\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.3585e-04 - val_loss: 0.9312\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.2917e-04 - val_loss: 0.9324\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 4.2268e-04 - val_loss: 0.9342\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.1656e-04 - val_loss: 0.9340\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 4.0962e-04 - val_loss: 0.9369\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 4.0291e-04 - val_loss: 0.9384\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.9651e-04 - val_loss: 0.9392\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.9131e-04 - val_loss: 0.9399\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 3.8543e-04 - val_loss: 0.9432\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 3.7941e-04 - val_loss: 0.9426\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.7373e-04 - val_loss: 0.9430\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 3.6844e-04 - val_loss: 0.9438\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 3.6267e-04 - val_loss: 0.9466\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 3.5694e-04 - val_loss: 0.9451\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 3.5280e-04 - val_loss: 0.9472\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 3.4751e-04 - val_loss: 0.9498\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 3.4293e-04 - val_loss: 0.9527\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 3.3709e-04 - val_loss: 0.9524\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 3.3234e-04 - val_loss: 0.9541\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 243us/step - loss: 3.2792e-04 - val_loss: 0.9549\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 3.2333e-04 - val_loss: 0.9579\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 3.1903e-04 - val_loss: 0.9588\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 3.1409e-04 - val_loss: 0.9620\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.0986e-04 - val_loss: 0.9627\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 3.0562e-04 - val_loss: 0.9625\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 3.0120e-04 - val_loss: 0.9642\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 2.9729e-04 - val_loss: 0.9653\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 2.9291e-04 - val_loss: 0.9661\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 2.8905e-04 - val_loss: 0.9675\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 2.8550e-04 - val_loss: 0.9683\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 2.8133e-04 - val_loss: 0.9688\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7758e-04 - val_loss: 0.9704\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 2.7384e-04 - val_loss: 0.9712\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.7003e-04 - val_loss: 0.9734\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.6688e-04 - val_loss: 0.9747\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.6333e-04 - val_loss: 0.9763\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 2.5991e-04 - val_loss: 0.9754\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5627e-04 - val_loss: 0.9764\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.5301e-04 - val_loss: 0.9779\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.4963e-04 - val_loss: 0.9785\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.4714e-04 - val_loss: 0.9810\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 2.4370e-04 - val_loss: 0.9811\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 2.4029e-04 - val_loss: 0.9803\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 2.3713e-04 - val_loss: 0.9813\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 2.3448e-04 - val_loss: 0.9835\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 2.3176e-04 - val_loss: 0.9844\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 2.2848e-04 - val_loss: 0.9865\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 2.2562e-04 - val_loss: 0.9876\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 2.2303e-04 - val_loss: 0.9896\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 2.2015e-04 - val_loss: 0.9889\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 2.1769e-04 - val_loss: 0.9902\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.1490e-04 - val_loss: 0.9896\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.1248e-04 - val_loss: 0.9923\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.0977e-04 - val_loss: 0.9933\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.0749e-04 - val_loss: 0.9941\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.0481e-04 - val_loss: 0.9950\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.0239e-04 - val_loss: 0.9956\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 2.3698 - val_loss: 2.2404\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 2.0463 - val_loss: 1.9890\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 1.7529 - val_loss: 1.7372\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 1.4976 - val_loss: 1.5481\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 1.2855 - val_loss: 1.3891\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 1.0916 - val_loss: 1.2433\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.9417 - val_loss: 1.1362\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.8182 - val_loss: 1.0474\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.7115 - val_loss: 0.9836\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.6255 - val_loss: 0.9401\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.5472 - val_loss: 0.8982\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.4849 - val_loss: 0.8567\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.4365 - val_loss: 0.8369\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.3850 - val_loss: 0.7944\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 0.3395 - val_loss: 0.7844\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.3036 - val_loss: 0.7654\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.2727 - val_loss: 0.7466\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.2462 - val_loss: 0.7330\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.2212 - val_loss: 0.7314\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.1974 - val_loss: 0.7199\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.1804 - val_loss: 0.7090\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.1651 - val_loss: 0.7055\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.1486 - val_loss: 0.6951\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.1362 - val_loss: 0.7054\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.1239 - val_loss: 0.6801\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.1139 - val_loss: 0.6876\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.1052 - val_loss: 0.6776\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0974 - val_loss: 0.6752\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0904 - val_loss: 0.6714\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0840 - val_loss: 0.6739\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0786 - val_loss: 0.6682\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0735 - val_loss: 0.6708\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0690 - val_loss: 0.6706\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0647 - val_loss: 0.6597\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0612 - val_loss: 0.6689\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0576 - val_loss: 0.6688\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0542 - val_loss: 0.6694\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0513 - val_loss: 0.6700\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0488 - val_loss: 0.6664\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0465 - val_loss: 0.6661\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0441 - val_loss: 0.6642\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0420 - val_loss: 0.6712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0401 - val_loss: 0.6686\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.0383 - val_loss: 0.6673\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0367 - val_loss: 0.6683\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0351 - val_loss: 0.6705\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0337 - val_loss: 0.6673\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0324 - val_loss: 0.6673\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.0311 - val_loss: 0.6706\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0299 - val_loss: 0.6708\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0289 - val_loss: 0.6703\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0277 - val_loss: 0.6747\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0268 - val_loss: 0.6738\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0259 - val_loss: 0.6745\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.0250 - val_loss: 0.6753\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0242 - val_loss: 0.6751\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0234 - val_loss: 0.6765\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0227 - val_loss: 0.6800\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0220 - val_loss: 0.6813\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0213 - val_loss: 0.6821\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0207 - val_loss: 0.6840\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0201 - val_loss: 0.6816\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0195 - val_loss: 0.6843\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0189 - val_loss: 0.6841\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0184 - val_loss: 0.6858\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0179 - val_loss: 0.6859\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0175 - val_loss: 0.6901\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0170 - val_loss: 0.6908\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0166 - val_loss: 0.6898\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0161 - val_loss: 0.6896\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0158 - val_loss: 0.6944\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0154 - val_loss: 0.6940\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0150 - val_loss: 0.6948\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0146 - val_loss: 0.6990\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0143 - val_loss: 0.6995\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0140 - val_loss: 0.6976\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.0136 - val_loss: 0.7005\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0133 - val_loss: 0.7010\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0130 - val_loss: 0.7038\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0128 - val_loss: 0.7033\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 242us/step - loss: 0.0125 - val_loss: 0.7031\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0122 - val_loss: 0.7045\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0120 - val_loss: 0.7073\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0117 - val_loss: 0.7063\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0115 - val_loss: 0.7084\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0112 - val_loss: 0.7107\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0110 - val_loss: 0.7116\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0108 - val_loss: 0.7108\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0106 - val_loss: 0.7148\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0104 - val_loss: 0.7132\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0102 - val_loss: 0.7165\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0100 - val_loss: 0.7171\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 0.0098 - val_loss: 0.7180\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.0096 - val_loss: 0.7181\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0094 - val_loss: 0.7222\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0093 - val_loss: 0.7205\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0091 - val_loss: 0.7194\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0089 - val_loss: 0.7191\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0088 - val_loss: 0.7230\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0086 - val_loss: 0.7237\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0085 - val_loss: 0.7254\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0083 - val_loss: 0.7285\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0082 - val_loss: 0.7289\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0081 - val_loss: 0.7282\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0079 - val_loss: 0.7295\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.7316\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.7301\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0075 - val_loss: 0.7328\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0074 - val_loss: 0.7307\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0073 - val_loss: 0.7344\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0072 - val_loss: 0.7349\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0071 - val_loss: 0.7350\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.0069 - val_loss: 0.7369\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0068 - val_loss: 0.7383\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0067 - val_loss: 0.7379\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0066 - val_loss: 0.7382\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0065 - val_loss: 0.7393\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0064 - val_loss: 0.7412\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0063 - val_loss: 0.7434\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0062 - val_loss: 0.7427\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0062 - val_loss: 0.7449\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.7454\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.7452\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.7448\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0058 - val_loss: 0.7454\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0057 - val_loss: 0.7476\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0057 - val_loss: 0.7487\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.7479\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.7505\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0054 - val_loss: 0.7504\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0054 - val_loss: 0.7517\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.7528\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.7544\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.7561\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.7564\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0050 - val_loss: 0.7554\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.7560\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.7573\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.7575\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.7587\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.7598\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0046 - val_loss: 0.7606\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.7614\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.7620\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.7630\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.7630\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.7641\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.7657\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.7662\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.7684\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.7682\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0041 - val_loss: 0.7686\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0041 - val_loss: 0.7692\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.7693\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.7696\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.7713\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0039 - val_loss: 0.7712\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0038 - val_loss: 0.7724\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.7731\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7745\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.7755\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0037 - val_loss: 0.7765\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0036 - val_loss: 0.7776\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.7792\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0035 - val_loss: 0.7785\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0035 - val_loss: 0.7787\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.7808\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0034 - val_loss: 0.7808\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7827\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7825\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.7824\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.7827\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.7849\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.0032 - val_loss: 0.7857\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0032 - val_loss: 0.7852\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0031 - val_loss: 0.7851\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0031 - val_loss: 0.7884\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0031 - val_loss: 0.7883\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.7888\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.7911\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.0030 - val_loss: 0.7915\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0030 - val_loss: 0.7924\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0029 - val_loss: 0.7928\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0029 - val_loss: 0.7934\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.0029 - val_loss: 0.7929\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0028 - val_loss: 0.7943\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0028 - val_loss: 0.7956\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.0028 - val_loss: 0.7955\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.7959\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.7971\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0027 - val_loss: 0.7974\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.7974\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.7980\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.7995\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8003\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8011\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.8014\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.8028\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.8034\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.8048\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.1364 - val_loss: 2.0096\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8412 - val_loss: 1.7643\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.5436 - val_loss: 1.5192\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2892 - val_loss: 1.3478\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.0807 - val_loss: 1.1850\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9189 - val_loss: 1.0903\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7877 - val_loss: 0.9935\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6904 - val_loss: 0.9339\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6006 - val_loss: 0.8868\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5331 - val_loss: 0.8383\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4635 - val_loss: 0.8077\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4101 - val_loss: 0.7817\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3598 - val_loss: 0.7500\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 0.3203 - val_loss: 0.7387\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2848 - val_loss: 0.7171\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2544 - val_loss: 0.7125\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2285 - val_loss: 0.6904\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2077 - val_loss: 0.6894\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1859 - val_loss: 0.6749\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1682 - val_loss: 0.6804\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1517 - val_loss: 0.6613\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1370 - val_loss: 0.6686\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1253 - val_loss: 0.6633\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1151 - val_loss: 0.6569\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1055 - val_loss: 0.6620\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0966 - val_loss: 0.6516\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0902 - val_loss: 0.6584\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0847 - val_loss: 0.6603\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0779 - val_loss: 0.6425\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0736 - val_loss: 0.6583\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0684 - val_loss: 0.6520\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0643 - val_loss: 0.6452\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0606 - val_loss: 0.6594\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0570 - val_loss: 0.6524\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0540 - val_loss: 0.6558\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0511 - val_loss: 0.6552\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0485 - val_loss: 0.6560\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0464 - val_loss: 0.6588\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0440 - val_loss: 0.6517\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0419 - val_loss: 0.6598\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0400 - val_loss: 0.6570\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0380 - val_loss: 0.6576\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0365 - val_loss: 0.6578\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0349 - val_loss: 0.6655\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0335 - val_loss: 0.6622\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0321 - val_loss: 0.6614\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0309 - val_loss: 0.6652\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0297 - val_loss: 0.6681\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0286 - val_loss: 0.6665\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0276 - val_loss: 0.6658\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0266 - val_loss: 0.6685\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0257 - val_loss: 0.6744\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0248 - val_loss: 0.6674\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0240 - val_loss: 0.6711\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0232 - val_loss: 0.6740\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0224 - val_loss: 0.6762\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0217 - val_loss: 0.6706\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0211 - val_loss: 0.6765\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0204 - val_loss: 0.6741\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0198 - val_loss: 0.6780\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0192 - val_loss: 0.6759\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0186 - val_loss: 0.6797\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0181 - val_loss: 0.6817\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0176 - val_loss: 0.6838\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0171 - val_loss: 0.6863\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0166 - val_loss: 0.6813\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0162 - val_loss: 0.6853\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0158 - val_loss: 0.6915\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0154 - val_loss: 0.6911\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0150 - val_loss: 0.6891\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0146 - val_loss: 0.6930\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.6928\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0139 - val_loss: 0.6938\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0136 - val_loss: 0.6967\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0133 - val_loss: 0.6991\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0130 - val_loss: 0.6967\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.7005\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0124 - val_loss: 0.6987\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.6983\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 0.0118 - val_loss: 0.7005\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.7025\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0113 - val_loss: 0.7054\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0111 - val_loss: 0.7049\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0108 - val_loss: 0.7050\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0106 - val_loss: 0.7085\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.7064\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0102 - val_loss: 0.7098\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0100 - val_loss: 0.7098\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0098 - val_loss: 0.7103\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0096 - val_loss: 0.7091\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0094 - val_loss: 0.7136\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0092 - val_loss: 0.7155\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.7143\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.7159\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.7175\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.7213\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0084 - val_loss: 0.7222\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.7186\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.7230\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0080 - val_loss: 0.7260\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.7245\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.7288\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.7265\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0074 - val_loss: 0.7269\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.7288\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.7308\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0071 - val_loss: 0.7332\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0070 - val_loss: 0.7304\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.7354\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.7370\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.7362\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.7384\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0064 - val_loss: 0.7377\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.7381\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.7396\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.7420\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.7437\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.7443\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.7443\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0058 - val_loss: 0.7475\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.7477\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.7468\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.7488\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.7482\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0054 - val_loss: 0.7505\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.7510\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.7516\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0052 - val_loss: 0.7532\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0051 - val_loss: 0.7546\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0050 - val_loss: 0.7555\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0049 - val_loss: 0.7559\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.7587\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.7583\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.7593\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0047 - val_loss: 0.7595\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.7603\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.7629\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.7612\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.7626\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.7627\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.7672\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.7677\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.7665\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.7664\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.7712\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0041 - val_loss: 0.7716\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.0040 - val_loss: 0.7697\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.7695\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.7745\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.7738\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.7727\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.7739\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7764\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7753\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.7769\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.7777\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.7798\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.7788\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.7785\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.7796\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7827\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7835\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.7833\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0033 - val_loss: 0.7853\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.7851\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.7869\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.7876\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.7881\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.7892\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.7910\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7909\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.7919\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7942\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7947\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.7946\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.7940\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.7953\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.7969\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.7982\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.7975\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0027 - val_loss: 0.7983\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.7992\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.8001\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.7997\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8016\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8035\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.8036\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0026 - val_loss: 0.8039\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0025 - val_loss: 0.8057\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.8068\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0025 - val_loss: 0.8075\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.0025 - val_loss: 0.8068\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.8097\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0024 - val_loss: 0.8106\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0024 - val_loss: 0.8110\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.8114\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0023 - val_loss: 0.8119\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0023 - val_loss: 0.8132\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.8122\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.8146\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.4479 - val_loss: 2.3468\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1313 - val_loss: 2.0930\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8102 - val_loss: 1.7930\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.4916 - val_loss: 1.5226\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1998 - val_loss: 1.2689\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.9391 - val_loss: 1.0701\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7296 - val_loss: 0.9204\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5709 - val_loss: 0.8338\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4529 - val_loss: 0.7705\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3717 - val_loss: 0.7160\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3108 - val_loss: 0.7058\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.2447 - val_loss: 0.6564\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1905 - val_loss: 0.6595\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1589 - val_loss: 0.6525\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1262 - val_loss: 0.6194\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1058 - val_loss: 0.6274\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0876 - val_loss: 0.6162\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0730 - val_loss: 0.6175\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0643 - val_loss: 0.6163\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0563 - val_loss: 0.6248\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0482 - val_loss: 0.6294\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0410 - val_loss: 0.6082\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0344 - val_loss: 0.6321\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.6236\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0268 - val_loss: 0.6292\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0242 - val_loss: 0.6299\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0218 - val_loss: 0.6335\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0199 - val_loss: 0.6396\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0183 - val_loss: 0.6387\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0164 - val_loss: 0.6445\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0153 - val_loss: 0.6468\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0141 - val_loss: 0.6492\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 260us/step - loss: 0.0131 - val_loss: 0.6522\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0121 - val_loss: 0.6535\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0112 - val_loss: 0.6606\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0104 - val_loss: 0.6621\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0097 - val_loss: 0.6674\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0091 - val_loss: 0.6648\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0087 - val_loss: 0.6658\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0081 - val_loss: 0.6732\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0076 - val_loss: 0.6745\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.6761\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0068 - val_loss: 0.6846\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.6836\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.6829\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.6891\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.6918\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.6932\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0050 - val_loss: 0.6981\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.6988\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.7009\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.7061\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.7054\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.7068\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.7104\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7143\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.7144\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7158\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.7182\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0032 - val_loss: 0.7219\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.7257\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.7254\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.7268\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.7283\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.7300\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.7342\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.7353\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.7374\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.7402\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 156us/step - loss: 0.0022 - val_loss: 0.7399\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.7415\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.7466\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.7495\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.7484\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.7512\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0019 - val_loss: 0.7526\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.7552\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.7579\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.7603\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.7633\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.7623\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.7645\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.7645\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.7674\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.7680\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.7694\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.7700\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.7735\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.7755\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.7771\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.7790\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.7814\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0012 - val_loss: 0.7816\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.7834\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7839\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.7866\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.7884\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7886\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.7897\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.7894\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.9544e-04 - val_loss: 0.7919\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.7416e-04 - val_loss: 0.7946\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.5312e-04 - val_loss: 0.7974\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.3415e-04 - val_loss: 0.7989\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.1449e-04 - val_loss: 0.7994\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.9493e-04 - val_loss: 0.8021\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.7667e-04 - val_loss: 0.8033\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.5866e-04 - val_loss: 0.8042\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 8.4113e-04 - val_loss: 0.8054\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.2591e-04 - val_loss: 0.8055\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.0803e-04 - val_loss: 0.8069\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.9410e-04 - val_loss: 0.8080\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.7885e-04 - val_loss: 0.8098\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.6263e-04 - val_loss: 0.8118\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5011e-04 - val_loss: 0.8135\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.3459e-04 - val_loss: 0.8129\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.1902e-04 - val_loss: 0.8144\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.0922e-04 - val_loss: 0.8153\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.9231e-04 - val_loss: 0.8174\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.7943e-04 - val_loss: 0.8194\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.6728e-04 - val_loss: 0.8206\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5650e-04 - val_loss: 0.8220\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4395e-04 - val_loss: 0.8232\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3205e-04 - val_loss: 0.8232\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.1985e-04 - val_loss: 0.8246\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 6.0941e-04 - val_loss: 0.8273\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9809e-04 - val_loss: 0.8286\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.8774e-04 - val_loss: 0.8297\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.7887e-04 - val_loss: 0.8298\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6898e-04 - val_loss: 0.8310\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5918e-04 - val_loss: 0.8328\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4988e-04 - val_loss: 0.8329\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.3990e-04 - val_loss: 0.8339\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.3220e-04 - val_loss: 0.8355\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2237e-04 - val_loss: 0.8365\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1281e-04 - val_loss: 0.8385\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.0533e-04 - val_loss: 0.8399\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.9705e-04 - val_loss: 0.8422\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.8957e-04 - val_loss: 0.8425\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8164e-04 - val_loss: 0.8432\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7406e-04 - val_loss: 0.8448\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6773e-04 - val_loss: 0.8463\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 4.6014e-04 - val_loss: 0.8466\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5193e-04 - val_loss: 0.8490\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4567e-04 - val_loss: 0.8496\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3916e-04 - val_loss: 0.8513\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3172e-04 - val_loss: 0.8515\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2523e-04 - val_loss: 0.8533\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1889e-04 - val_loss: 0.8542\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1225e-04 - val_loss: 0.8544\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0618e-04 - val_loss: 0.8549\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9991e-04 - val_loss: 0.8561\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9370e-04 - val_loss: 0.8578\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8807e-04 - val_loss: 0.8586\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8255e-04 - val_loss: 0.8594\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7714e-04 - val_loss: 0.8602\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7165e-04 - val_loss: 0.8617\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.6661e-04 - val_loss: 0.8629\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 3.6153e-04 - val_loss: 0.8640\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5596e-04 - val_loss: 0.8648\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5114e-04 - val_loss: 0.8669\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4649e-04 - val_loss: 0.8676\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4122e-04 - val_loss: 0.8679\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3624e-04 - val_loss: 0.8689\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.3157e-04 - val_loss: 0.8701\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2717e-04 - val_loss: 0.8707\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2242e-04 - val_loss: 0.8714\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1836e-04 - val_loss: 0.8722\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1413e-04 - val_loss: 0.8738\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0996e-04 - val_loss: 0.8752\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0565e-04 - val_loss: 0.8755\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0157e-04 - val_loss: 0.8754\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9764e-04 - val_loss: 0.8771\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9370e-04 - val_loss: 0.8779\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8968e-04 - val_loss: 0.8799\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.8612e-04 - val_loss: 0.8809\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8224e-04 - val_loss: 0.8822\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.4289e-0 - 0s 156us/step - loss: 2.7851e-04 - val_loss: 0.8833\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7530e-04 - val_loss: 0.8837\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7147e-04 - val_loss: 0.8849\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6823e-04 - val_loss: 0.8856\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6484e-04 - val_loss: 0.8859\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6132e-04 - val_loss: 0.8866\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5813e-04 - val_loss: 0.8876\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5505e-04 - val_loss: 0.8883\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 2.5177e-04 - val_loss: 0.8897\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4878e-04 - val_loss: 0.8900\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4590e-04 - val_loss: 0.8910\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4272e-04 - val_loss: 0.8917\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3959e-04 - val_loss: 0.8927\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3675e-04 - val_loss: 0.8941\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.3386e-04 - val_loss: 0.8952\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 2.3105e-04 - val_loss: 0.8961\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2829e-04 - val_loss: 0.8969\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2566e-04 - val_loss: 0.8975\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.3166e-0 - 0s 156us/step - loss: 2.2281e-04 - val_loss: 0.8983\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2026e-04 - val_loss: 0.8994\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1766e-04 - val_loss: 0.9010\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1480e-04 - val_loss: 0.9019\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1250e-04 - val_loss: 0.9022\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.1133 - val_loss: 1.9375\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.7932 - val_loss: 1.6582\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 1.4812 - val_loss: 1.4138\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.1781 - val_loss: 1.1841\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.8893 - val_loss: 0.9981\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6696 - val_loss: 0.8593\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5148 - val_loss: 0.7634\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3917 - val_loss: 0.7179\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3213 - val_loss: 0.6478\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2550 - val_loss: 0.6341\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2020 - val_loss: 0.5947\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1638 - val_loss: 0.5894\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1326 - val_loss: 0.5733\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1081 - val_loss: 0.5815\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0916 - val_loss: 0.5590\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0768 - val_loss: 0.5666\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0633 - val_loss: 0.5584\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0525 - val_loss: 0.5648\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0456 - val_loss: 0.5624\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0394 - val_loss: 0.5587\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0337 - val_loss: 0.5602\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0296 - val_loss: 0.5742\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0258 - val_loss: 0.5678\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0230 - val_loss: 0.5699\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0207 - val_loss: 0.5801\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0185 - val_loss: 0.5753\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0166 - val_loss: 0.5764\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0153 - val_loss: 0.5823\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0139 - val_loss: 0.5870\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0128 - val_loss: 0.5907\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.5916\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.5993\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0101 - val_loss: 0.5980\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0094 - val_loss: 0.6065\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0088 - val_loss: 0.6082\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0082 - val_loss: 0.6094\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.6108\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.6170\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0069 - val_loss: 0.6203\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.6242\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.6254\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0057 - val_loss: 0.6304\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.6317\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.6366\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.6366\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.6401\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.6429\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.006 - 0s 156us/step - loss: 0.0042 - val_loss: 0.6459\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.6461\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.6490\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.6529\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0035 - val_loss: 0.6568\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.0034 - val_loss: 0.6569\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.6596\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.6649\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.6640\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.6662\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.6684\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.6718\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.6734\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.6737\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.6772\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.6800\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.6823\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.6844\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.6852\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.6892\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.6901\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0019 - val_loss: 0.6922\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 0.6936\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.6959\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.6979\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.7004\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.7016\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0016 - val_loss: 0.7033\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0015 - val_loss: 0.7050\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.7094\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0015 - val_loss: 0.7122\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0014 - val_loss: 0.7119\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.7123\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0014 - val_loss: 0.7137\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0013 - val_loss: 0.7166\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 0.0013 - val_loss: 0.7179\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0013 - val_loss: 0.7204\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.7226\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.7246\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.7254\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7276\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.7294\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7302\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7335\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.7356\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.7369\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.9008e-04 - val_loss: 0.7365\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.6320e-04 - val_loss: 0.7385\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.4096e-04 - val_loss: 0.7393\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.2189e-04 - val_loss: 0.7400\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.0045e-04 - val_loss: 0.7407\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.8443e-04 - val_loss: 0.7440\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 8.6204e-04 - val_loss: 0.7456\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 8.4358e-04 - val_loss: 0.7473\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.2932e-04 - val_loss: 0.7478\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.1042e-04 - val_loss: 0.7510\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.9277e-04 - val_loss: 0.7526\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 7.7745e-04 - val_loss: 0.7528\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.6021e-04 - val_loss: 0.7540\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.4459e-04 - val_loss: 0.7554\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.2990e-04 - val_loss: 0.7567\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.1664e-04 - val_loss: 0.7571\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.0281e-04 - val_loss: 0.7583\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.8905e-04 - val_loss: 0.7612\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.7585e-04 - val_loss: 0.7628\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.6176e-04 - val_loss: 0.7641\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.5034e-04 - val_loss: 0.7651\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3823e-04 - val_loss: 0.7672\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.2685e-04 - val_loss: 0.7684\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 6.1436e-04 - val_loss: 0.7699\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 135us/step - loss: 6.0323e-04 - val_loss: 0.7716\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9249e-04 - val_loss: 0.7725\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.8204e-04 - val_loss: 0.7741\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.7218e-04 - val_loss: 0.7750\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6139e-04 - val_loss: 0.7763\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5103e-04 - val_loss: 0.7774\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.4173e-04 - val_loss: 0.7799\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.3190e-04 - val_loss: 0.7817\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2358e-04 - val_loss: 0.7821\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.1394e-04 - val_loss: 0.7835\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0554e-04 - val_loss: 0.7851\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9756e-04 - val_loss: 0.7864\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.8880e-04 - val_loss: 0.7874\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8123e-04 - val_loss: 0.7887\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7321e-04 - val_loss: 0.7897\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6494e-04 - val_loss: 0.7916\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5766e-04 - val_loss: 0.7928\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 4.5005e-04 - val_loss: 0.7933\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4225e-04 - val_loss: 0.7942\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3568e-04 - val_loss: 0.7957\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.2891e-04 - val_loss: 0.7958\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 4.2215e-04 - val_loss: 0.7970\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1511e-04 - val_loss: 0.7987\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0916e-04 - val_loss: 0.7994\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0250e-04 - val_loss: 0.8000\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9711e-04 - val_loss: 0.8027\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9069e-04 - val_loss: 0.8042\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8395e-04 - val_loss: 0.8057\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7851e-04 - val_loss: 0.8066\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.7298e-04 - val_loss: 0.8076\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.6740e-04 - val_loss: 0.8091\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6124e-04 - val_loss: 0.8094\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.5552e-04 - val_loss: 0.8102\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.5108e-04 - val_loss: 0.8119\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 3.4577e-04 - val_loss: 0.8127\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.4056e-04 - val_loss: 0.8134\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.3597e-04 - val_loss: 0.8148\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3073e-04 - val_loss: 0.8158\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2626e-04 - val_loss: 0.8172\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2209e-04 - val_loss: 0.8182\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.1690e-04 - val_loss: 0.8186\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.1249e-04 - val_loss: 0.8198\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0843e-04 - val_loss: 0.8205\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0389e-04 - val_loss: 0.8227\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9971e-04 - val_loss: 0.8239\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9581e-04 - val_loss: 0.8247\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9146e-04 - val_loss: 0.8259\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8715e-04 - val_loss: 0.8265\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8389e-04 - val_loss: 0.8282\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7931e-04 - val_loss: 0.8281\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 2.7554e-04 - val_loss: 0.8283\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 2.7194e-04 - val_loss: 0.8283\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6948e-04 - val_loss: 0.8294\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6484e-04 - val_loss: 0.8319\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6107e-04 - val_loss: 0.8332\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5771e-04 - val_loss: 0.8344\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5408e-04 - val_loss: 0.8360\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5078e-04 - val_loss: 0.8375\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4767e-04 - val_loss: 0.8382\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4451e-04 - val_loss: 0.8396\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4144e-04 - val_loss: 0.8399\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.3848e-04 - val_loss: 0.8407\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3529e-04 - val_loss: 0.8415\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3230e-04 - val_loss: 0.8425\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2942e-04 - val_loss: 0.8441\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2634e-04 - val_loss: 0.8449\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2365e-04 - val_loss: 0.8457\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 2.2111e-04 - val_loss: 0.8461\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.1827e-04 - val_loss: 0.8466\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1552e-04 - val_loss: 0.8479\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1283e-04 - val_loss: 0.8486\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1047e-04 - val_loss: 0.8495\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0769e-04 - val_loss: 0.8505\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0539e-04 - val_loss: 0.8516\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0341e-04 - val_loss: 0.8533\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0025e-04 - val_loss: 0.8531\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.9815e-04 - val_loss: 0.8536\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.9547e-04 - val_loss: 0.8545\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9329e-04 - val_loss: 0.8555\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.9104e-04 - val_loss: 0.8568\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.8858e-04 - val_loss: 0.8577\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8649e-04 - val_loss: 0.8589\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8429e-04 - val_loss: 0.8594\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.1770 - val_loss: 2.1097\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9541 - val_loss: 1.9480\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.7469 - val_loss: 1.7867\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.5516 - val_loss: 1.6208\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3530 - val_loss: 1.4431\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1646 - val_loss: 1.2954\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9912 - val_loss: 1.1425\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.8181 - val_loss: 1.0051\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6557 - val_loss: 0.8695\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5151 - val_loss: 0.7954\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.4016 - val_loss: 0.7145\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3156 - val_loss: 0.6857\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2551 - val_loss: 0.6496\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2057 - val_loss: 0.6334\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.1662 - val_loss: 0.6397\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1445 - val_loss: 0.6153\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1202 - val_loss: 0.6323\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1010 - val_loss: 0.6153\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0878 - val_loss: 0.6301\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0718 - val_loss: 0.6270\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0613 - val_loss: 0.6202\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0520 - val_loss: 0.6215\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0426 - val_loss: 0.6409\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0365 - val_loss: 0.6316\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0327 - val_loss: 0.6333\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0279 - val_loss: 0.6474\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0253 - val_loss: 0.6572\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0226 - val_loss: 0.6522\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0206 - val_loss: 0.6582\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0184 - val_loss: 0.6637\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0167 - val_loss: 0.6753\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0153 - val_loss: 0.6786\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0141 - val_loss: 0.6795\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0130 - val_loss: 0.6849\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0120 - val_loss: 0.6883\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0112 - val_loss: 0.6983\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0104 - val_loss: 0.7041\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0097 - val_loss: 0.7011\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0090 - val_loss: 0.7140\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.7194\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0079 - val_loss: 0.7187\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0074 - val_loss: 0.7250\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0070 - val_loss: 0.7247\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.7316\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.7384\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.7332\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.7386\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.7468\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0051 - val_loss: 0.7537\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.7571\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.7600\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.7603\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.7652\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.7711\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.7731\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7774\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.7774\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7813\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.7892\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.7872\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7888\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.7916\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.7991\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.8012\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8024\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0025 - val_loss: 0.8044\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.8115\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.8129\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.8143\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.8180\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.8199\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.8243\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.8256\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.8278\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.8265\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.8283\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8353\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8360\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.8386\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.8395\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.8448\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.8456\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0015 - val_loss: 0.8467\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.8499\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.8538\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.8553\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.8561\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.8610\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.8625\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.8630\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.8658\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.8688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.8692\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.8719\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.8721\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.8791\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.8803\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.8802\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 9.8711e-04 - val_loss: 0.8816\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.6779e-04 - val_loss: 0.8809\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.4298e-04 - val_loss: 0.8839\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.2478e-04 - val_loss: 0.8877\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.0306e-04 - val_loss: 0.8892\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.8252e-04 - val_loss: 0.8906\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.6406e-04 - val_loss: 0.8926\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.4681e-04 - val_loss: 0.8927\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.2908e-04 - val_loss: 0.8946\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.1293e-04 - val_loss: 0.8955\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.9663e-04 - val_loss: 0.8977\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.8087e-04 - val_loss: 0.9000\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.6431e-04 - val_loss: 0.9018\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5166e-04 - val_loss: 0.9019\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.3653e-04 - val_loss: 0.9049\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.2164e-04 - val_loss: 0.9066\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.0799e-04 - val_loss: 0.9086\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 6.9454e-04 - val_loss: 0.9103\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.8075e-04 - val_loss: 0.9129\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.6788e-04 - val_loss: 0.9164\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5520e-04 - val_loss: 0.9183\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4383e-04 - val_loss: 0.9199\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 6.3241e-04 - val_loss: 0.9215\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 6.2025e-04 - val_loss: 0.9216\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1068e-04 - val_loss: 0.9218\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 5.9927e-04 - val_loss: 0.9233\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 5.8802e-04 - val_loss: 0.9245\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.7769e-04 - val_loss: 0.9257\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6745e-04 - val_loss: 0.9281\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 5.5860e-04 - val_loss: 0.9274\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 5.4796e-04 - val_loss: 0.9310\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 5.3922e-04 - val_loss: 0.9329\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 5.2903e-04 - val_loss: 0.9336\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.2081e-04 - val_loss: 0.9352\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1286e-04 - val_loss: 0.9367\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.0415e-04 - val_loss: 0.9389\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9493e-04 - val_loss: 0.9384\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.8796e-04 - val_loss: 0.9403\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.7976e-04 - val_loss: 0.9429\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7200e-04 - val_loss: 0.9441\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.6495e-04 - val_loss: 0.9463\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5676e-04 - val_loss: 0.9485\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4934e-04 - val_loss: 0.9490\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.4216e-04 - val_loss: 0.9506\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3545e-04 - val_loss: 0.9510\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2877e-04 - val_loss: 0.9517\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.2192e-04 - val_loss: 0.9534\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1536e-04 - val_loss: 0.9555\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 4.1019e-04 - val_loss: 0.9580\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0357e-04 - val_loss: 0.9574\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9657e-04 - val_loss: 0.9587\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9113e-04 - val_loss: 0.9606\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8557e-04 - val_loss: 0.9617\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7988e-04 - val_loss: 0.9637\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7452e-04 - val_loss: 0.9651\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6887e-04 - val_loss: 0.9665\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6411e-04 - val_loss: 0.9673\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5801e-04 - val_loss: 0.9688\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5316e-04 - val_loss: 0.9711\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4817e-04 - val_loss: 0.9729\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4319e-04 - val_loss: 0.9727\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3762e-04 - val_loss: 0.9735\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3419e-04 - val_loss: 0.9734\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.2914e-04 - val_loss: 0.9755\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2443e-04 - val_loss: 0.9769\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1961e-04 - val_loss: 0.9783\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1543e-04 - val_loss: 0.9797\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.1073e-04 - val_loss: 0.9810\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 3.0690e-04 - val_loss: 0.9819\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0298e-04 - val_loss: 0.9846\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9859e-04 - val_loss: 0.9837\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9439e-04 - val_loss: 0.9862\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9023e-04 - val_loss: 0.9862\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8657e-04 - val_loss: 0.9863\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8246e-04 - val_loss: 0.9873\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.7874e-04 - val_loss: 0.9891\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7560e-04 - val_loss: 0.9899\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7198e-04 - val_loss: 0.9913\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6880e-04 - val_loss: 0.9926\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6454e-04 - val_loss: 0.9940\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6159e-04 - val_loss: 0.9947\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.5806e-04 - val_loss: 0.9959\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5486e-04 - val_loss: 0.9953\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5136e-04 - val_loss: 0.9969\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4847e-04 - val_loss: 0.9993\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4499e-04 - val_loss: 1.0002\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4158e-04 - val_loss: 0.9992\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3911e-04 - val_loss: 1.0004\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3609e-04 - val_loss: 1.0033\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3347e-04 - val_loss: 1.0030\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.3047e-04 - val_loss: 1.0047\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2697e-04 - val_loss: 1.0064\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2412e-04 - val_loss: 1.0088\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2151e-04 - val_loss: 1.0090\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.1907e-04 - val_loss: 1.0086\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1625e-04 - val_loss: 1.0100\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1346e-04 - val_loss: 1.0110\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 2.1087e-04 - val_loss: 1.0126\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 2.0850e-04 - val_loss: 1.0137\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.0579e-04 - val_loss: 1.0143\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.0358e-04 - val_loss: 1.0158\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 2.0135e-04 - val_loss: 1.0161\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.2950 - val_loss: 2.1374\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.0932 - val_loss: 2.0284\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9405 - val_loss: 1.8726\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.7391 - val_loss: 1.6860\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.5017 - val_loss: 1.5070\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2842 - val_loss: 1.3449\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.0953 - val_loss: 1.2060\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9293 - val_loss: 1.0707\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7693 - val_loss: 0.9332\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.6303 - val_loss: 0.8424\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5133 - val_loss: 0.7435\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4174 - val_loss: 0.6767\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3378 - val_loss: 0.6326\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2791 - val_loss: 0.5985\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2410 - val_loss: 0.5750\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1990 - val_loss: 0.5586\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1662 - val_loss: 0.5450\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1385 - val_loss: 0.5320\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1196 - val_loss: 0.5393\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1057 - val_loss: 0.5298\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0901 - val_loss: 0.5388\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0773 - val_loss: 0.5315\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0687 - val_loss: 0.5284\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0584 - val_loss: 0.5388\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0512 - val_loss: 0.5323\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0447 - val_loss: 0.5485\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0381 - val_loss: 0.5474\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0342 - val_loss: 0.5455\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0305 - val_loss: 0.5545\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0282 - val_loss: 0.5586\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0249 - val_loss: 0.5641\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0224 - val_loss: 0.5615\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0207 - val_loss: 0.5653\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0188 - val_loss: 0.5728\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0174 - val_loss: 0.5844\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.007 - 0s 156us/step - loss: 0.0160 - val_loss: 0.5934\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.5928\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.5885\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0129 - val_loss: 0.5968\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0121 - val_loss: 0.6013\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0113 - val_loss: 0.6014\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0105 - val_loss: 0.6083\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0099 - val_loss: 0.6140\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.0093 - val_loss: 0.6161\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0088 - val_loss: 0.6152\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0083 - val_loss: 0.6233\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.6311\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0074 - val_loss: 0.6301\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0070 - val_loss: 0.6333\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0067 - val_loss: 0.6355\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0063 - val_loss: 0.6430\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.6430\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0058 - val_loss: 0.6473\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.6497\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0052 - val_loss: 0.6531\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0050 - val_loss: 0.6571\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0048 - val_loss: 0.6609\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.6615\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.003 - 0s 155us/step - loss: 0.0044 - val_loss: 0.6612\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.004 - 0s 156us/step - loss: 0.0043 - val_loss: 0.6662\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0041 - val_loss: 0.6647\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0039 - val_loss: 0.6672\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.6737\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.004 - 0s 156us/step - loss: 0.0036 - val_loss: 0.6788\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.6819\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.6823\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.6836\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.6900\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.6932\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.6910\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.003 - 0s 156us/step - loss: 0.0028 - val_loss: 0.6972\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.7023\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.7058\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.7022\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.7074\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.0024 - val_loss: 0.7104\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.7107\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.7149\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.7190\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.7190\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.7209\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.7215\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.7257\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.7256\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.7297\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.7310\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.7339\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.7366\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.7365\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.7388\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.7394\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.7433\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0015 - val_loss: 0.7458\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.7466\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.7460\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0014 - val_loss: 0.7451\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.7451\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.7549\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.7607\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.7565\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.7585\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.7624\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.7641\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.7650\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.7656\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7678\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7670\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.7695\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.7718\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.7726\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.7736\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.9264e-04 - val_loss: 0.7750\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 9.7265e-04 - val_loss: 0.7760\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.5429e-04 - val_loss: 0.7771\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.3724e-04 - val_loss: 0.7786\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.1488e-04 - val_loss: 0.7803\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.0493e-04 - val_loss: 0.7822\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.8327e-04 - val_loss: 0.7835\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.6800e-04 - val_loss: 0.7868\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.4897e-04 - val_loss: 0.7904\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.3436e-04 - val_loss: 0.7895\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.1703e-04 - val_loss: 0.7885\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.0213e-04 - val_loss: 0.7897\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.8878e-04 - val_loss: 0.7929\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.7452e-04 - val_loss: 0.7937\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 7.6046e-04 - val_loss: 0.7966\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.4611e-04 - val_loss: 0.7974\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.3406e-04 - val_loss: 0.7966\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.1998e-04 - val_loss: 0.8000\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.0809e-04 - val_loss: 0.8014\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.9411e-04 - val_loss: 0.8035\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.8298e-04 - val_loss: 0.8037\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.7088e-04 - val_loss: 0.8060\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5849e-04 - val_loss: 0.8085\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4772e-04 - val_loss: 0.8100\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3775e-04 - val_loss: 0.8120\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.2593e-04 - val_loss: 0.8120\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1599e-04 - val_loss: 0.8133\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.0534e-04 - val_loss: 0.8140\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.9583e-04 - val_loss: 0.8152\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.8682e-04 - val_loss: 0.8162\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 5.7766e-04 - val_loss: 0.8167\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6897e-04 - val_loss: 0.8183\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5980e-04 - val_loss: 0.8163\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5064e-04 - val_loss: 0.8188\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4179e-04 - val_loss: 0.8212\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.3449e-04 - val_loss: 0.8231\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2562e-04 - val_loss: 0.8231\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.1768e-04 - val_loss: 0.8249\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0983e-04 - val_loss: 0.8251\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0309e-04 - val_loss: 0.8297\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9468e-04 - val_loss: 0.8313\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8726e-04 - val_loss: 0.8318\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.7941e-04 - val_loss: 0.8343\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7249e-04 - val_loss: 0.8342\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.6572e-04 - val_loss: 0.8353\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5878e-04 - val_loss: 0.8366\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 4.5209e-04 - val_loss: 0.8372\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 4.4620e-04 - val_loss: 0.8364\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.3898e-04 - val_loss: 0.8389\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3314e-04 - val_loss: 0.8413\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2753e-04 - val_loss: 0.8428\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.2176e-04 - val_loss: 0.8423\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.1466e-04 - val_loss: 0.8439\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1028e-04 - val_loss: 0.8451\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.0473e-04 - val_loss: 0.8459\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9848e-04 - val_loss: 0.8472\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.9248e-04 - val_loss: 0.8486\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.8789e-04 - val_loss: 0.8484\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8165e-04 - val_loss: 0.8486\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7755e-04 - val_loss: 0.8482\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.7184e-04 - val_loss: 0.8513\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 3.6674e-04 - val_loss: 0.8527\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6215e-04 - val_loss: 0.8547\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.5735e-04 - val_loss: 0.8566\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5275e-04 - val_loss: 0.8584\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4806e-04 - val_loss: 0.8583\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4319e-04 - val_loss: 0.8600\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.3898e-04 - val_loss: 0.8607\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3455e-04 - val_loss: 0.8613\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3036e-04 - val_loss: 0.8616\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2645e-04 - val_loss: 0.8638\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.2158e-04 - val_loss: 0.8649\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1892e-04 - val_loss: 0.8623\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1434e-04 - val_loss: 0.8667\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0971e-04 - val_loss: 0.8684\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0628e-04 - val_loss: 0.8689\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0193e-04 - val_loss: 0.8689\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.6765e-0 - 0s 168us/step - loss: 2.9841e-04 - val_loss: 0.8697\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9449e-04 - val_loss: 0.8697\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9077e-04 - val_loss: 0.8712\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8746e-04 - val_loss: 0.8746\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8359e-04 - val_loss: 0.8747\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8003e-04 - val_loss: 0.8752\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7646e-04 - val_loss: 0.8760\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 2.7350e-04 - val_loss: 0.8773\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7005e-04 - val_loss: 0.8771\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6662e-04 - val_loss: 0.8786\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6330e-04 - val_loss: 0.8779\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6076e-04 - val_loss: 0.8788\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.3515 - val_loss: 2.2396\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0655 - val_loss: 2.0301\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8019 - val_loss: 1.8160\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.5509 - val_loss: 1.6345\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.3168 - val_loss: 1.4717\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1227 - val_loss: 1.3483\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9492 - val_loss: 1.2257\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.8102 - val_loss: 1.1446\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.6873 - val_loss: 1.0732\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.5898 - val_loss: 1.0267\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5050 - val_loss: 0.9781\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4351 - val_loss: 0.9440\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3861 - val_loss: 0.9087\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3306 - val_loss: 0.8823\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.2903 - val_loss: 0.8762\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2513 - val_loss: 0.8542\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2200 - val_loss: 0.8371\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1944 - val_loss: 0.8316\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1735 - val_loss: 0.8147\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1565 - val_loss: 0.8096\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1398 - val_loss: 0.8039\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1261 - val_loss: 0.8031\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1140 - val_loss: 0.7947\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1039 - val_loss: 0.7987\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0952 - val_loss: 0.7886\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0881 - val_loss: 0.7887\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0809 - val_loss: 0.7889\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0752 - val_loss: 0.7839\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0703 - val_loss: 0.7829\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0655 - val_loss: 0.7779\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0618 - val_loss: 0.7847\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0575 - val_loss: 0.7790\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0540 - val_loss: 0.7835\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0510 - val_loss: 0.7783\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0481 - val_loss: 0.7805\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0457 - val_loss: 0.7775\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0432 - val_loss: 0.7816\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0410 - val_loss: 0.7794\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0391 - val_loss: 0.7847\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0372 - val_loss: 0.7796\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0355 - val_loss: 0.7820\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0339 - val_loss: 0.7838\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0325 - val_loss: 0.7821\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0311 - val_loss: 0.7854\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0298 - val_loss: 0.7854\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0287 - val_loss: 0.7869\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0274 - val_loss: 0.7864\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0265 - val_loss: 0.7875\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0255 - val_loss: 0.7874\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.7895\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0237 - val_loss: 0.7948\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0229 - val_loss: 0.7933\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0221 - val_loss: 0.7926\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0213 - val_loss: 0.7915\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0206 - val_loss: 0.7964\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0200 - val_loss: 0.7985\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0193 - val_loss: 0.7997\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0187 - val_loss: 0.7988\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0181 - val_loss: 0.8011\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0176 - val_loss: 0.8010\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0170 - val_loss: 0.8025\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0165 - val_loss: 0.8043\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0161 - val_loss: 0.8045\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0156 - val_loss: 0.8066\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0152 - val_loss: 0.8094\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.0148 - val_loss: 0.8085\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.8110\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0140 - val_loss: 0.8116\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0137 - val_loss: 0.8124\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0133 - val_loss: 0.8136\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0130 - val_loss: 0.8169\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0127 - val_loss: 0.8168\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0124 - val_loss: 0.8177\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.0121 - val_loss: 0.8190\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0118 - val_loss: 0.8206\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0115 - val_loss: 0.8211\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0112 - val_loss: 0.8216\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.8241\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0108 - val_loss: 0.8259\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0105 - val_loss: 0.8255\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0103 - val_loss: 0.8266\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0101 - val_loss: 0.8279\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0099 - val_loss: 0.8295\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0096 - val_loss: 0.8298\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 0.0094 - val_loss: 0.8313\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0093 - val_loss: 0.8314\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.8338\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0089 - val_loss: 0.8340\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0087 - val_loss: 0.8353\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.8366\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0084 - val_loss: 0.8381\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0082 - val_loss: 0.8384\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.8407\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.8412\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.8411\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0076 - val_loss: 0.8434\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0075 - val_loss: 0.8454\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.8460\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.8470\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0071 - val_loss: 0.8486\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0070 - val_loss: 0.8483\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.8489\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0067 - val_loss: 0.8520\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.8523\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.8519\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0064 - val_loss: 0.8543\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.8549\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0062 - val_loss: 0.8573\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.8588\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.8583\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.8591\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.8607\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0057 - val_loss: 0.8616\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.8617\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.8625\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.8643\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0054 - val_loss: 0.8657\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.8659\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.8659\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.8669\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.8672\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.8688\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.8693\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.8694\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.8711\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0047 - val_loss: 0.8720\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.8732\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.8728\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.8735\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.8749\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.8761\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.8768\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.8776\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0042 - val_loss: 0.8789\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.8792\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.8799\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0041 - val_loss: 0.8796\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.8813\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.8823\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.8827\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.8842\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.8845\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.8854\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.8855\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.8872\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.8874\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.8883\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.8899\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.8900\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.8906\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0034 - val_loss: 0.8911\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.8913\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.8921\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.8935\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.8944\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.8958\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.8959\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.8967\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 156us/step - loss: 0.0031 - val_loss: 0.8977\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.8986\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.8995\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.8996\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.9009\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.9015\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.9020\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.9031\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.9037\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0028 - val_loss: 0.9048\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.9052\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.9064\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.9071\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.9077\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.9085\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.9095\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.9100\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.9108\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 156us/step - loss: 0.0026 - val_loss: 0.9119\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.9123\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.9131\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.9145\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.9153\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.9157\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.9163\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0024 - val_loss: 0.9169\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0024 - val_loss: 0.9173\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.9187\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.9194\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.9199\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.9202\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.9210\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 156us/step - loss: 0.0022 - val_loss: 0.9214\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.9222\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.9233\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.9234\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.9239\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.9246\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.9254\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.9260\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.9271\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.9279\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 2.4038 - val_loss: 2.1820\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0238 - val_loss: 1.9302\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.7311 - val_loss: 1.7196\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.4705 - val_loss: 1.4988\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2337 - val_loss: 1.3273\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.0440 - val_loss: 1.1810\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.8829 - val_loss: 1.0799\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7498 - val_loss: 0.9840\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6402 - val_loss: 0.9141\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.5609 - val_loss: 0.8758\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.4856 - val_loss: 0.8200\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.4269 - val_loss: 0.7996\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3776 - val_loss: 0.7639\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3339 - val_loss: 0.7460\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2972 - val_loss: 0.7262\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2672 - val_loss: 0.7126\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2419 - val_loss: 0.7035\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2176 - val_loss: 0.6875\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1978 - val_loss: 0.6752\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1796 - val_loss: 0.6813\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1630 - val_loss: 0.6677\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1501 - val_loss: 0.6536\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1365 - val_loss: 0.6637\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1263 - val_loss: 0.6472\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1162 - val_loss: 0.6536\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1078 - val_loss: 0.6423\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.0997 - val_loss: 0.6437\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0927 - val_loss: 0.6389\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0858 - val_loss: 0.6499\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0800 - val_loss: 0.6398\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0740 - val_loss: 0.6397\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0692 - val_loss: 0.6403\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0648 - val_loss: 0.6330\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0608 - val_loss: 0.6362\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0574 - val_loss: 0.6359\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0543 - val_loss: 0.6339\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0514 - val_loss: 0.6289\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0488 - val_loss: 0.6393\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0463 - val_loss: 0.6321\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0441 - val_loss: 0.6345\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0422 - val_loss: 0.6342\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0400 - val_loss: 0.6350\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0384 - val_loss: 0.6309\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0368 - val_loss: 0.6366\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0352 - val_loss: 0.6345\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0337 - val_loss: 0.6364\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0324 - val_loss: 0.6371\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0312 - val_loss: 0.6377\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0301 - val_loss: 0.6348\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0290 - val_loss: 0.6405\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0280 - val_loss: 0.6399\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0270 - val_loss: 0.6377\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0262 - val_loss: 0.6407\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0253 - val_loss: 0.6410\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0245 - val_loss: 0.6453\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0238 - val_loss: 0.6423\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0230 - val_loss: 0.6426\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0223 - val_loss: 0.6474\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0217 - val_loss: 0.6496\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0211 - val_loss: 0.6491\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0205 - val_loss: 0.6481\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0199 - val_loss: 0.6518\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0194 - val_loss: 0.6491\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0189 - val_loss: 0.6493\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0183 - val_loss: 0.6545\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0179 - val_loss: 0.6515\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0174 - val_loss: 0.6563\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0170 - val_loss: 0.6554\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0166 - val_loss: 0.6552\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0162 - val_loss: 0.6570\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0158 - val_loss: 0.6608\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0154 - val_loss: 0.6590\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.6606\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0147 - val_loss: 0.6603\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0144 - val_loss: 0.6608\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0141 - val_loss: 0.6609\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0138 - val_loss: 0.6686\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0135 - val_loss: 0.6649\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.6676\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0129 - val_loss: 0.6693\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0126 - val_loss: 0.6663\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0124 - val_loss: 0.6718\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0121 - val_loss: 0.6716\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0119 - val_loss: 0.6700\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.6728\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.6758\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.6753\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0110 - val_loss: 0.6732\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0107 - val_loss: 0.6762\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0105 - val_loss: 0.6782\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.6786\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.6793\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0100 - val_loss: 0.6793\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0098 - val_loss: 0.6813\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0096 - val_loss: 0.6816\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0094 - val_loss: 0.6819\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0093 - val_loss: 0.6830\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.6827\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.6837\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0088 - val_loss: 0.6873\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.6877\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.6905\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0083 - val_loss: 0.6876\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0082 - val_loss: 0.6926\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.6911\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0079 - val_loss: 0.6935\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.6913\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0075 - val_loss: 0.6929\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0074 - val_loss: 0.6959\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0073 - val_loss: 0.6992\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0072 - val_loss: 0.6993\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0071 - val_loss: 0.6964\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.6978\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0069 - val_loss: 0.7000\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.7004\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.0067 - val_loss: 0.7015\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0066 - val_loss: 0.7011\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.7039\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0064 - val_loss: 0.7069\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.7062\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0062 - val_loss: 0.7061\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.7068\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.7061\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.7090\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.7105\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0058 - val_loss: 0.7095\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0057 - val_loss: 0.7116\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.7122\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.7105\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.7126\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.7139\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.7146\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.7158\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0052 - val_loss: 0.7179\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.7177\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.7180\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0050 - val_loss: 0.7194\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.7208\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.7207\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.7209\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.7224\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.7241\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.0046 - val_loss: 0.7228\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.7232\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.7239\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0045 - val_loss: 0.7249\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.7273\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0044 - val_loss: 0.7283\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.7287\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.7296\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.7303\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0041 - val_loss: 0.7316\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.7324\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.7325\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.7326\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.7331\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.7344\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.7346\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0038 - val_loss: 0.7355\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0038 - val_loss: 0.7369\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7393\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.7405\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.7387\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.7375\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.7408\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.7420\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.7420\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.7429\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7419\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.7425\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.7434\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.7450\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.7440\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.7461\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.7469\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.7477\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0031 - val_loss: 0.7479\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.7473\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.7497\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7510\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7496\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7519\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.7512\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.7531\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.7530\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.7547\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.7551\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.7555\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.7564\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.7573\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 246us/step - loss: 0.0027 - val_loss: 0.7573\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.7578\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0027 - val_loss: 0.7579\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0026 - val_loss: 0.7590\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.7598\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.7611\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.7622\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.7631\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.7630\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 9.2842 - val_loss: 8.4864\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.6248 - val_loss: 7.0426\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.2002 - val_loss: 5.8272\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 5.511 - 0s 156us/step - loss: 5.1830 - val_loss: 5.1023\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.4679 - val_loss: 4.4486\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8628 - val_loss: 3.8350\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2321 - val_loss: 3.3086\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 2.7039 - val_loss: 2.9569\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 2.2998 - val_loss: 2.6959\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9761 - val_loss: 2.5416\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.7675 - val_loss: 2.4432\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6352 - val_loss: 2.3819\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.5392 - val_loss: 2.3616\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.4743 - val_loss: 2.3411\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.4218 - val_loss: 2.3425\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3878 - val_loss: 2.3150\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.3532 - val_loss: 2.3204\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3312 - val_loss: 2.3114\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3139 - val_loss: 2.3029\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3033 - val_loss: 2.2921\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2907 - val_loss: 2.2821\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2835 - val_loss: 2.2891\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2761 - val_loss: 2.2873\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2717 - val_loss: 2.2694\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 1.2676 - val_loss: 2.2813\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2637 - val_loss: 2.2802\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2605 - val_loss: 2.2693\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2585 - val_loss: 2.2722\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2562 - val_loss: 2.2669\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.2548 - val_loss: 2.2744\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.2530 - val_loss: 2.2673\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2518 - val_loss: 2.2645\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2503 - val_loss: 2.2681\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.2494 - val_loss: 2.2579\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.2483 - val_loss: 2.2673\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2475 - val_loss: 2.2663\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.2467 - val_loss: 2.2627\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.2461 - val_loss: 2.2600\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 1.2455 - val_loss: 2.2627\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 1.2451 - val_loss: 2.2628\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2444 - val_loss: 2.2574\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2440 - val_loss: 2.2591\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2435 - val_loss: 2.2642\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2432 - val_loss: 2.2619\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2428 - val_loss: 2.2625\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2425 - val_loss: 2.2586\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2422 - val_loss: 2.2609\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2419 - val_loss: 2.2639\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2416 - val_loss: 2.2627\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2413 - val_loss: 2.2628\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2411 - val_loss: 2.2592\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2409 - val_loss: 2.2638\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2407 - val_loss: 2.2628\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2405 - val_loss: 2.2582\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.012 - 0s 156us/step - loss: 1.2403 - val_loss: 2.2612\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 1.2401 - val_loss: 2.2661\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2399 - val_loss: 2.2670\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2398 - val_loss: 2.2654\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2396 - val_loss: 2.2629\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2395 - val_loss: 2.2598\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2393 - val_loss: 2.2621\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2392 - val_loss: 2.2658\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2391 - val_loss: 2.2647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2390 - val_loss: 2.2622\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2389 - val_loss: 2.2643\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2388 - val_loss: 2.2626\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2387 - val_loss: 2.2621\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2386 - val_loss: 2.2622\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2385 - val_loss: 2.2635\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2384 - val_loss: 2.2640\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2383 - val_loss: 2.2659\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2383 - val_loss: 2.2676\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 1.2382 - val_loss: 2.2657\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 133us/step - loss: 1.2381 - val_loss: 2.2663\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2381 - val_loss: 2.2653\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2380 - val_loss: 2.2673\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2379 - val_loss: 2.2682\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2379 - val_loss: 2.2675\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2378 - val_loss: 2.2670\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2378 - val_loss: 2.2680\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2377 - val_loss: 2.2674\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2377 - val_loss: 2.2676\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2376 - val_loss: 2.2694\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.506 - 0s 156us/step - loss: 1.2376 - val_loss: 2.2696\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2375 - val_loss: 2.2706\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2375 - val_loss: 2.2698\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2374 - val_loss: 2.2724\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2374 - val_loss: 2.2719\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2374 - val_loss: 2.2709\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 1.2373 - val_loss: 2.2678\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2373 - val_loss: 2.2712\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2373 - val_loss: 2.2726\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2372 - val_loss: 2.2716\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2372 - val_loss: 2.2723\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2372 - val_loss: 2.2729\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2371 - val_loss: 2.2742\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2371 - val_loss: 2.2733\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2371 - val_loss: 2.2730\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2370 - val_loss: 2.2730\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2370 - val_loss: 2.2734\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2370 - val_loss: 2.2743\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2370 - val_loss: 2.2747\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2369 - val_loss: 2.2769\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2369 - val_loss: 2.2763\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2369 - val_loss: 2.2776\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2369 - val_loss: 2.2772\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 1.2368 - val_loss: 2.2758\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2368 - val_loss: 2.2771\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2368 - val_loss: 2.2773\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2368 - val_loss: 2.2763\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2368 - val_loss: 2.2763\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2367 - val_loss: 2.2767\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2367 - val_loss: 2.2754\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2367 - val_loss: 2.2768\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2367 - val_loss: 2.2777\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2367 - val_loss: 2.2785\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2367 - val_loss: 2.2794\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2366 - val_loss: 2.2785\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2366 - val_loss: 2.2802\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2366 - val_loss: 2.2815\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2366 - val_loss: 2.2815\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2366 - val_loss: 2.2800\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2366 - val_loss: 2.2812\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 1.2366 - val_loss: 2.2808\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2365 - val_loss: 2.2806\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2365 - val_loss: 2.2818\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2365 - val_loss: 2.2814\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2365 - val_loss: 2.2826\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2365 - val_loss: 2.2817\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2365 - val_loss: 2.2828\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2365 - val_loss: 2.2822\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2365 - val_loss: 2.2817\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2364 - val_loss: 2.2819\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2364 - val_loss: 2.2824\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2364 - val_loss: 2.2824\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2364 - val_loss: 2.2827\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2364 - val_loss: 2.2820\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2364 - val_loss: 2.2839\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2364 - val_loss: 2.2845\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 1.2364 - val_loss: 2.2857\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 1.2364 - val_loss: 2.2863\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2363 - val_loss: 2.2857\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 1.2363 - val_loss: 2.2869\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 246us/step - loss: 1.2363 - val_loss: 2.2861\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2363 - val_loss: 2.2860\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 1.2363 - val_loss: 2.2868\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 1.2363 - val_loss: 2.2865\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2363 - val_loss: 2.2875\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.2363 - val_loss: 2.2877\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.2363 - val_loss: 2.2878\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2363 - val_loss: 2.2886\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2363 - val_loss: 2.2892\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2363 - val_loss: 2.2902\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2906\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2897\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2903\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 1.2362 - val_loss: 2.2899\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2906\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2362 - val_loss: 2.2904\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2362 - val_loss: 2.2906\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2911\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2909\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2927\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2925\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2931\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2362 - val_loss: 2.2929\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2362 - val_loss: 2.2925\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2362 - val_loss: 2.2936\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2362 - val_loss: 2.2936\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2941\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2943\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2948\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.2361 - val_loss: 2.2939\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2944\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2361 - val_loss: 2.2942\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2361 - val_loss: 2.2941\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2936\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2955\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2957\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2967\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2979\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2361 - val_loss: 2.2981\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2361 - val_loss: 2.2982\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2996\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2989\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2986\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2993\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2361 - val_loss: 2.2986\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 1.2361 - val_loss: 2.2983\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2361 - val_loss: 2.2990\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 1.2361 - val_loss: 2.2990\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2360 - val_loss: 2.2996\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 1.2360 - val_loss: 2.2998\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 1.2360 - val_loss: 2.2998\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2360 - val_loss: 2.3001\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2360 - val_loss: 2.3007\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2360 - val_loss: 2.3018\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2360 - val_loss: 2.3012\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2360 - val_loss: 2.3020\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2360 - val_loss: 2.3023\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 4.6443 - val_loss: 3.9644\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2646 - val_loss: 2.7868\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2425 - val_loss: 1.9982\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.5825 - val_loss: 1.5522\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2243 - val_loss: 1.2907\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9726 - val_loss: 1.0660\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7592 - val_loss: 0.8982\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5845 - val_loss: 0.7436\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.4598 - val_loss: 0.6477\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3661 - val_loss: 0.5914\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2975 - val_loss: 0.5502\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2406 - val_loss: 0.5038\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2091 - val_loss: 0.4853\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1734 - val_loss: 0.4669\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.1394 - val_loss: 0.4593\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1186 - val_loss: 0.4520\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0965 - val_loss: 0.4340\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.093 - 0s 156us/step - loss: 0.0812 - val_loss: 0.4287\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0692 - val_loss: 0.4265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0589 - val_loss: 0.4242\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0506 - val_loss: 0.4156\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0438 - val_loss: 0.4152\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0382 - val_loss: 0.4106\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0334 - val_loss: 0.4135\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0294 - val_loss: 0.4164\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0262 - val_loss: 0.4069\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0235 - val_loss: 0.4103\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0211 - val_loss: 0.4113\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0190 - val_loss: 0.4117\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0174 - val_loss: 0.4119\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0156 - val_loss: 0.4126\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0145 - val_loss: 0.4120\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0132 - val_loss: 0.4116\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0122 - val_loss: 0.4137\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0111 - val_loss: 0.4151\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0104 - val_loss: 0.4187\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0096 - val_loss: 0.4169\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0091 - val_loss: 0.4124\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.4177\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0080 - val_loss: 0.4225\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0074 - val_loss: 0.4202\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0070 - val_loss: 0.4222\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.4234\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.4239\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.4254\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.4251\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.4259\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.4284\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0048 - val_loss: 0.4300\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0046 - val_loss: 0.4294\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.4316\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.4316\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.4329\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.4328\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.4333\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.4344\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.004 - 0s 156us/step - loss: 0.0034 - val_loss: 0.4361\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.4371\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.4381\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.4380\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.4394\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.4401\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.4410\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.4423\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.4449\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0024 - val_loss: 0.4457\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.4448\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.4454\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.4455\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0021 - val_loss: 0.4458\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.4466\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.4486\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0019 - val_loss: 0.4478\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0019 - val_loss: 0.4491\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0018 - val_loss: 0.4508\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.4505\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.4525\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0017 - val_loss: 0.4536\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0016 - val_loss: 0.4545\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0016 - val_loss: 0.4547\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0015 - val_loss: 0.4544\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.4569\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.4563\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0014 - val_loss: 0.4569\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0014 - val_loss: 0.4575\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.4586\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.4597\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.4600\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.4610\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.4608\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.4607\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.4618\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.4632\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.4638\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.4651\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0010 - val_loss: 0.4661\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.4662\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.9945e-04 - val_loss: 0.4665\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.7737e-04 - val_loss: 0.4666\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.5606e-04 - val_loss: 0.4672\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.3570e-04 - val_loss: 0.4676\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.1610e-04 - val_loss: 0.4679\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.9859e-04 - val_loss: 0.4693\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.7739e-04 - val_loss: 0.4695\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.6046e-04 - val_loss: 0.4697\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.4286e-04 - val_loss: 0.4709\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.2660e-04 - val_loss: 0.4719\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.0898e-04 - val_loss: 0.4718\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.9305e-04 - val_loss: 0.4728\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.7923e-04 - val_loss: 0.4729\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.6427e-04 - val_loss: 0.4748\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 7.4978e-04 - val_loss: 0.4753\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.3247e-04 - val_loss: 0.4759\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.1843e-04 - val_loss: 0.4772\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.0580e-04 - val_loss: 0.4769\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.9174e-04 - val_loss: 0.4771\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.7937e-04 - val_loss: 0.4778\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.6691e-04 - val_loss: 0.4785\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5377e-04 - val_loss: 0.4797\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.4189e-04 - val_loss: 0.4801\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3063e-04 - val_loss: 0.4808\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1852e-04 - val_loss: 0.4811\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.0890e-04 - val_loss: 0.4811\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9739e-04 - val_loss: 0.4818\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.8666e-04 - val_loss: 0.4822\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.7600e-04 - val_loss: 0.4825\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6596e-04 - val_loss: 0.4829\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5662e-04 - val_loss: 0.4832\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 5.4546e-04 - val_loss: 0.4833\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.3683e-04 - val_loss: 0.4835\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2767e-04 - val_loss: 0.4840\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1908e-04 - val_loss: 0.4844\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1023e-04 - val_loss: 0.4860\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0107e-04 - val_loss: 0.4862\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.9375e-04 - val_loss: 0.4854\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.8481e-04 - val_loss: 0.4867\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7781e-04 - val_loss: 0.4871\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6949e-04 - val_loss: 0.4877\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6215e-04 - val_loss: 0.4884\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.5339e-04 - val_loss: 0.4887\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.4721e-04 - val_loss: 0.4890\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3967e-04 - val_loss: 0.4899\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3220e-04 - val_loss: 0.4904\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2559e-04 - val_loss: 0.4908\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 4.1961e-04 - val_loss: 0.4914\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1302e-04 - val_loss: 0.4913\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0648e-04 - val_loss: 0.4917\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0033e-04 - val_loss: 0.4925\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9417e-04 - val_loss: 0.4931\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8831e-04 - val_loss: 0.4935\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8244e-04 - val_loss: 0.4936\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7696e-04 - val_loss: 0.4943\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7126e-04 - val_loss: 0.4942\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6516e-04 - val_loss: 0.4947\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.6098e-04 - val_loss: 0.4950\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5546e-04 - val_loss: 0.4958\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5052e-04 - val_loss: 0.4952\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4501e-04 - val_loss: 0.4962\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.4013e-04 - val_loss: 0.4966\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.3557e-04 - val_loss: 0.4970\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3114e-04 - val_loss: 0.4970\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.2606e-04 - val_loss: 0.4975\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2143e-04 - val_loss: 0.4979\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1691e-04 - val_loss: 0.4985\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1243e-04 - val_loss: 0.4987\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 3.0831e-04 - val_loss: 0.4996\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 3.0427e-04 - val_loss: 0.4998\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0003e-04 - val_loss: 0.4999\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 2.9564e-04 - val_loss: 0.5003\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 2.9197e-04 - val_loss: 0.5012\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8787e-04 - val_loss: 0.5013\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 2.8392e-04 - val_loss: 0.5019\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 2.8010e-04 - val_loss: 0.5018\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7637e-04 - val_loss: 0.5026\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7272e-04 - val_loss: 0.5030\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6931e-04 - val_loss: 0.5034\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6580e-04 - val_loss: 0.5041\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 2.6209e-04 - val_loss: 0.5046\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.5867e-04 - val_loss: 0.5042\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5543e-04 - val_loss: 0.5043\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5195e-04 - val_loss: 0.5054\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4879e-04 - val_loss: 0.5054\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4556e-04 - val_loss: 0.5063\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4260e-04 - val_loss: 0.5063\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3908e-04 - val_loss: 0.5073\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3617e-04 - val_loss: 0.5077\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3333e-04 - val_loss: 0.5075\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3009e-04 - val_loss: 0.5077\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2737e-04 - val_loss: 0.5084\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2438e-04 - val_loss: 0.5086\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2138e-04 - val_loss: 0.5091\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.1868e-04 - val_loss: 0.5095\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.1613e-04 - val_loss: 0.5097\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1334e-04 - val_loss: 0.5100\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 2.1083e-04 - val_loss: 0.5107\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.0837e-04 - val_loss: 0.5111\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0576e-04 - val_loss: 0.5115\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0340e-04 - val_loss: 0.5122\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0109e-04 - val_loss: 0.5124\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9903e-04 - val_loss: 0.5123\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 6.3220 - val_loss: 5.7442\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2531 - val_loss: 4.8687\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4840 - val_loss: 4.2609\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8217 - val_loss: 3.6897\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2090 - val_loss: 3.1658\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6399 - val_loss: 2.6738\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1090 - val_loss: 2.2482\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 1.6432 - val_loss: 1.8537\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2138 - val_loss: 1.5447\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.8743 - val_loss: 1.3225\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6509 - val_loss: 1.1675\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5189 - val_loss: 1.0830\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4057 - val_loss: 1.0003\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3470 - val_loss: 0.9486\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2810 - val_loss: 0.9090\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2364 - val_loss: 0.8784\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1865 - val_loss: 0.8581\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1518 - val_loss: 0.8272\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1247 - val_loss: 0.8274\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1027 - val_loss: 0.8302\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0906 - val_loss: 0.8047\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0779 - val_loss: 0.8034\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0661 - val_loss: 0.8238\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0558 - val_loss: 0.8037\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0499 - val_loss: 0.8075\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0443 - val_loss: 0.8178\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0381 - val_loss: 0.8100\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0345 - val_loss: 0.8142\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0307 - val_loss: 0.8324\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0274 - val_loss: 0.8185\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0244 - val_loss: 0.8132\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0220 - val_loss: 0.8218\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0200 - val_loss: 0.8239\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0183 - val_loss: 0.8190\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0166 - val_loss: 0.8302\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0155 - val_loss: 0.8232\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0141 - val_loss: 0.8317\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0131 - val_loss: 0.8326\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0121 - val_loss: 0.8330\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0112 - val_loss: 0.8316\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0106 - val_loss: 0.8347\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0098 - val_loss: 0.8342\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0092 - val_loss: 0.8401\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0087 - val_loss: 0.8389\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0082 - val_loss: 0.8343\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.8332\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.8414\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.8474\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.8472\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0062 - val_loss: 0.8474\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.8502\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0057 - val_loss: 0.8385\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.8481\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.004 - 0s 156us/step - loss: 0.0051 - val_loss: 0.8563\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.8565\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0047 - val_loss: 0.8540\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.8580\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.8580\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.004 - 0s 156us/step - loss: 0.0041 - val_loss: 0.8602\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.8637\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.8668\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.8590\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.8647\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.8661\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.8680\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.8687\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.8694\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.8693\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0028 - val_loss: 0.8714\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.8743\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.8782\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0026 - val_loss: 0.8760\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.8766\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.8803\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.8799\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.8813\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.8829\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.8836\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.8777\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.8791\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.8872\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.8876\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.8902\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.8894\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.8899\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8895\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8923\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0016 - val_loss: 0.8917\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.8916\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.8919\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.8969\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.8925\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.8948\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.8995\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.8992\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.8980\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.9004\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.9010\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.9012\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.9036\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.9040\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.9037\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.9053\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0011 - val_loss: 0.9093\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.9081\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.9101\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.9099\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.9102\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0010 - val_loss: 0.9103\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.8746e-04 - val_loss: 0.9108\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.6433e-04 - val_loss: 0.9102\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 9.4378e-04 - val_loss: 0.9086\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 9.2774e-04 - val_loss: 0.9101\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 9.0760e-04 - val_loss: 0.9107\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.9125e-04 - val_loss: 0.9110\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.7322e-04 - val_loss: 0.9129\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.5733e-04 - val_loss: 0.9180\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.4099e-04 - val_loss: 0.9182\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 8.2554e-04 - val_loss: 0.9175\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.1037e-04 - val_loss: 0.9165\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.9540e-04 - val_loss: 0.9167\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.8121e-04 - val_loss: 0.9172\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.6833e-04 - val_loss: 0.9186\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5473e-04 - val_loss: 0.9170\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.4069e-04 - val_loss: 0.9196\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.2688e-04 - val_loss: 0.9208\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 7.1541e-04 - val_loss: 0.9211\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.0267e-04 - val_loss: 0.9220\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.8907e-04 - val_loss: 0.9222\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.7849e-04 - val_loss: 0.9228\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 6.6704e-04 - val_loss: 0.9248\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5565e-04 - val_loss: 0.9259\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4587e-04 - val_loss: 0.9243\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.3554e-04 - val_loss: 0.9249\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 6.2419e-04 - val_loss: 0.9249\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1392e-04 - val_loss: 0.9254\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.0344e-04 - val_loss: 0.9270\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9301e-04 - val_loss: 0.9293\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.8438e-04 - val_loss: 0.9297\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.7632e-04 - val_loss: 0.9305\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6579e-04 - val_loss: 0.9314\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.5790e-04 - val_loss: 0.9313\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4812e-04 - val_loss: 0.9316\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4036e-04 - val_loss: 0.9321\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.3163e-04 - val_loss: 0.9330\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.2438e-04 - val_loss: 0.9341\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.1726e-04 - val_loss: 0.9353\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0905e-04 - val_loss: 0.9349\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0142e-04 - val_loss: 0.9367\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9343e-04 - val_loss: 0.9370\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8638e-04 - val_loss: 0.9359\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 4.8007e-04 - val_loss: 0.9372\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7189e-04 - val_loss: 0.9380\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6513e-04 - val_loss: 0.9396\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5882e-04 - val_loss: 0.9398\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5235e-04 - val_loss: 0.9399\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4639e-04 - val_loss: 0.9401\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.3979e-04 - val_loss: 0.9407\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.3349e-04 - val_loss: 0.9425\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2758e-04 - val_loss: 0.9439\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.2190e-04 - val_loss: 0.9418\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1564e-04 - val_loss: 0.9427\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1081e-04 - val_loss: 0.9427\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0479e-04 - val_loss: 0.9432\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9940e-04 - val_loss: 0.9432\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9355e-04 - val_loss: 0.9455\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8871e-04 - val_loss: 0.9473\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.8334e-04 - val_loss: 0.9461\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7831e-04 - val_loss: 0.9463\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7349e-04 - val_loss: 0.9460\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6880e-04 - val_loss: 0.9468\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6389e-04 - val_loss: 0.9473\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5919e-04 - val_loss: 0.9478\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 3.5444e-04 - val_loss: 0.9486\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 3.5035e-04 - val_loss: 0.9486\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4543e-04 - val_loss: 0.9504\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4111e-04 - val_loss: 0.9524\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3665e-04 - val_loss: 0.9529\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.3285e-04 - val_loss: 0.9527\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2813e-04 - val_loss: 0.9528\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 3.2474e-04 - val_loss: 0.9523\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2006e-04 - val_loss: 0.9528\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1638e-04 - val_loss: 0.9544\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.6254e-0 - 0s 160us/step - loss: 3.1246e-04 - val_loss: 0.9545\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0849e-04 - val_loss: 0.9543\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0470e-04 - val_loss: 0.9557\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0113e-04 - val_loss: 0.9556\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9767e-04 - val_loss: 0.9569\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9423e-04 - val_loss: 0.9573\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9086e-04 - val_loss: 0.9580\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 2.8706e-04 - val_loss: 0.9578\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 2.8355e-04 - val_loss: 0.9577\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8049e-04 - val_loss: 0.9586\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 2.7694e-04 - val_loss: 0.9596\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.7359e-04 - val_loss: 0.9614\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7030e-04 - val_loss: 0.9616\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 2.6752e-04 - val_loss: 0.9606\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 2.6436e-04 - val_loss: 0.9625\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6147e-04 - val_loss: 0.9625\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5866e-04 - val_loss: 0.9643\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 3.2258 - val_loss: 2.3686\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2656 - val_loss: 1.8516\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.7240 - val_loss: 1.5244\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.3704 - val_loss: 1.2864\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1306 - val_loss: 1.0999\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.9210 - val_loss: 0.9556\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.7590 - val_loss: 0.8412\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6380 - val_loss: 0.7448\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5310 - val_loss: 0.6931\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4431 - val_loss: 0.6261\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.3753 - val_loss: 0.5841\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.3175 - val_loss: 0.5540\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2631 - val_loss: 0.5228\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2305 - val_loss: 0.4973\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1956 - val_loss: 0.4950\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1644 - val_loss: 0.4869\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1378 - val_loss: 0.4506\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1140 - val_loss: 0.4667\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1003 - val_loss: 0.4568\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0848 - val_loss: 0.4417\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0731 - val_loss: 0.4346\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0649 - val_loss: 0.4289\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0536 - val_loss: 0.4344\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0479 - val_loss: 0.4225\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0428 - val_loss: 0.4301\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0367 - val_loss: 0.4236\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0330 - val_loss: 0.4233\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0288 - val_loss: 0.4179\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0260 - val_loss: 0.4206\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0237 - val_loss: 0.4159\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0212 - val_loss: 0.4165\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0191 - val_loss: 0.4199\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.4209\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0160 - val_loss: 0.4201\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0147 - val_loss: 0.4206\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0135 - val_loss: 0.4205\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0125 - val_loss: 0.4244\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0116 - val_loss: 0.4224\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0106 - val_loss: 0.4183\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0099 - val_loss: 0.4248\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0091 - val_loss: 0.4218\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0085 - val_loss: 0.4197\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.4233\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0073 - val_loss: 0.4228\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.4254\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.4263\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.4258\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0057 - val_loss: 0.4271\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.4277\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.4294\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.4310\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.4310\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.4335\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.4352\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.4360\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.4371\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.4399\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0034 - val_loss: 0.4400\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.4390\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.4394\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.4422\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.4425\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.4428\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.4438\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.4460\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.4481\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.4486\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.4502\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.4499\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.4511\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.4525\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.4543\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.4559\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.4548\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.4559\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.4571\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0017 - val_loss: 0.4598\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.4600\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.4613\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.4616\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.4623\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.4621\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.4649\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.4662\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.4676\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.4684\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.4679\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.4679\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.4682\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.4690\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.4710\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.0010 - val_loss: 0.4721\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.4714\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.9627e-04 - val_loss: 0.4722\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.7253e-04 - val_loss: 0.4734\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.5035e-04 - val_loss: 0.4737\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.2567e-04 - val_loss: 0.4745\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.0395e-04 - val_loss: 0.4758\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.8083e-04 - val_loss: 0.4777\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.6178e-04 - val_loss: 0.4788\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.4168e-04 - val_loss: 0.4792\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.2341e-04 - val_loss: 0.4785\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.0462e-04 - val_loss: 0.4796\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.8590e-04 - val_loss: 0.4800\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.7303e-04 - val_loss: 0.4817\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5469e-04 - val_loss: 0.4828\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.3785e-04 - val_loss: 0.4834\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.2327e-04 - val_loss: 0.4828\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 7.0600e-04 - val_loss: 0.4839\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.9186e-04 - val_loss: 0.4855\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.7730e-04 - val_loss: 0.4855\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.6461e-04 - val_loss: 0.4846\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5210e-04 - val_loss: 0.4847\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3881e-04 - val_loss: 0.4858\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.2611e-04 - val_loss: 0.4874\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1424e-04 - val_loss: 0.4882\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.0217e-04 - val_loss: 0.4892\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9150e-04 - val_loss: 0.4902\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.7970e-04 - val_loss: 0.4908\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6960e-04 - val_loss: 0.4909\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5920e-04 - val_loss: 0.4907\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4846e-04 - val_loss: 0.4902\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.3846e-04 - val_loss: 0.4913\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2955e-04 - val_loss: 0.4927\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 5.1908e-04 - val_loss: 0.4937\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1009e-04 - val_loss: 0.4948\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0173e-04 - val_loss: 0.4952\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9205e-04 - val_loss: 0.4958\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.8398e-04 - val_loss: 0.4960\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7562e-04 - val_loss: 0.4961\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6695e-04 - val_loss: 0.4973\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.5864e-04 - val_loss: 0.4981\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5150e-04 - val_loss: 0.4989\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4361e-04 - val_loss: 0.4995\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.3663e-04 - val_loss: 0.5004\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2974e-04 - val_loss: 0.5007\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2241e-04 - val_loss: 0.5011\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1638e-04 - val_loss: 0.5021\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1026e-04 - val_loss: 0.5030\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0278e-04 - val_loss: 0.5030\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9593e-04 - val_loss: 0.5036\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9015e-04 - val_loss: 0.5044\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 3.8473e-04 - val_loss: 0.5044\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.7851e-04 - val_loss: 0.5047\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7349e-04 - val_loss: 0.5051\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6680e-04 - val_loss: 0.5059\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6124e-04 - val_loss: 0.5068\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.5590e-04 - val_loss: 0.5079\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.4995e-04 - val_loss: 0.5085\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.4500e-04 - val_loss: 0.5090\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4052e-04 - val_loss: 0.5091\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3530e-04 - val_loss: 0.5100\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.3067e-04 - val_loss: 0.5110\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.2525e-04 - val_loss: 0.5110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.2014e-04 - val_loss: 0.5120\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1575e-04 - val_loss: 0.5125\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 3.1132e-04 - val_loss: 0.5131\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.0623e-04 - val_loss: 0.5129\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0202e-04 - val_loss: 0.5132\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9795e-04 - val_loss: 0.5139\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9309e-04 - val_loss: 0.5144\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8847e-04 - val_loss: 0.5149\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8434e-04 - val_loss: 0.5151\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8065e-04 - val_loss: 0.5159\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7696e-04 - val_loss: 0.5168\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7293e-04 - val_loss: 0.5175\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6918e-04 - val_loss: 0.5178\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6542e-04 - val_loss: 0.5184\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6203e-04 - val_loss: 0.5188\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5828e-04 - val_loss: 0.5189\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.5461e-04 - val_loss: 0.5200\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5137e-04 - val_loss: 0.5207\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4803e-04 - val_loss: 0.5209\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 136us/step - loss: 2.4482e-04 - val_loss: 0.5212\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4157e-04 - val_loss: 0.5215\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3830e-04 - val_loss: 0.5222\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3573e-04 - val_loss: 0.5221\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3254e-04 - val_loss: 0.5233\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2908e-04 - val_loss: 0.5238\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2649e-04 - val_loss: 0.5243\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2340e-04 - val_loss: 0.5250\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2072e-04 - val_loss: 0.5251\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1786e-04 - val_loss: 0.5255\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.1489e-04 - val_loss: 0.5264\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1230e-04 - val_loss: 0.5272\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0934e-04 - val_loss: 0.5277\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0723e-04 - val_loss: 0.5285\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0432e-04 - val_loss: 0.5284\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0197e-04 - val_loss: 0.5285\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9980e-04 - val_loss: 0.5300\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.9684e-04 - val_loss: 0.5309\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9457e-04 - val_loss: 0.5308\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.9190e-04 - val_loss: 0.5313\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8957e-04 - val_loss: 0.5313\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8807e-04 - val_loss: 0.5316\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8539e-04 - val_loss: 0.5323\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8296e-04 - val_loss: 0.5326\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8074e-04 - val_loss: 0.5332\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.7865e-04 - val_loss: 0.5338\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 10.1963 - val_loss: 9.1261\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.2377 - val_loss: 8.2418\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 8.4739 - val_loss: 7.6392\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 7.8711 - val_loss: 7.0799\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 7.2980 - val_loss: 6.4980\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.7827 - val_loss: 6.0426\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.3391 - val_loss: 5.5964\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9063 - val_loss: 5.1719\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4205 - val_loss: 4.7043\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8203 - val_loss: 4.2133\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2775 - val_loss: 3.7746\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7923 - val_loss: 3.3472\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3028 - val_loss: 2.9600\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8612 - val_loss: 2.6490\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5072 - val_loss: 2.3989\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2487 - val_loss: 2.2065\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.0161 - val_loss: 2.0441\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.8194 - val_loss: 1.9237\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6445 - val_loss: 1.8078\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.4842 - val_loss: 1.6872\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3512 - val_loss: 1.5928\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 1.2079 - val_loss: 1.5011\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.0864 - val_loss: 1.4173\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.9748 - val_loss: 1.3320\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.8659 - val_loss: 1.2748\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7701 - val_loss: 1.1981\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6731 - val_loss: 1.1413\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6015 - val_loss: 1.0814\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5434 - val_loss: 1.0422\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4930 - val_loss: 1.0027\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4479 - val_loss: 0.9773\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.4090 - val_loss: 0.9367\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3776 - val_loss: 0.9057\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3489 - val_loss: 0.8864\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3225 - val_loss: 0.8611\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2982 - val_loss: 0.8385\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2750 - val_loss: 0.8185\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.2482 - val_loss: 0.8036\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2248 - val_loss: 0.7869\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2065 - val_loss: 0.7746\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1895 - val_loss: 0.7521\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1762 - val_loss: 0.7392\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1674 - val_loss: 0.7322\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1590 - val_loss: 0.7202\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1510 - val_loss: 0.7114\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1432 - val_loss: 0.7050\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1359 - val_loss: 0.6974\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1268 - val_loss: 0.6971\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1183 - val_loss: 0.6795\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1120 - val_loss: 0.6723\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1050 - val_loss: 0.6654\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0998 - val_loss: 0.6597\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0952 - val_loss: 0.6566\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0907 - val_loss: 0.6438\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0868 - val_loss: 0.6387\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0826 - val_loss: 0.6326\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0788 - val_loss: 0.6277\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0744 - val_loss: 0.6233\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0711 - val_loss: 0.6242\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0683 - val_loss: 0.6208\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0658 - val_loss: 0.6138\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0635 - val_loss: 0.6163\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0614 - val_loss: 0.6110\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0595 - val_loss: 0.6065\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0576 - val_loss: 0.6049\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0558 - val_loss: 0.6044\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0540 - val_loss: 0.6002\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0522 - val_loss: 0.5985\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0505 - val_loss: 0.5948\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0488 - val_loss: 0.5954\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0473 - val_loss: 0.5924\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0459 - val_loss: 0.5897\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0445 - val_loss: 0.5882\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0433 - val_loss: 0.5870\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0422 - val_loss: 0.5840\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0410 - val_loss: 0.5842\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0400 - val_loss: 0.5816\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0390 - val_loss: 0.5825\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0381 - val_loss: 0.5805\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0373 - val_loss: 0.5802\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0363 - val_loss: 0.5779\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0356 - val_loss: 0.5743\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0348 - val_loss: 0.5768\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0340 - val_loss: 0.5763\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0333 - val_loss: 0.5763\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0326 - val_loss: 0.5751\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0319 - val_loss: 0.5736\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0313 - val_loss: 0.5722\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0307 - val_loss: 0.5746\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.025 - 0s 156us/step - loss: 0.0301 - val_loss: 0.5741\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0295 - val_loss: 0.5743\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0289 - val_loss: 0.5721\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0284 - val_loss: 0.5729\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0279 - val_loss: 0.5719\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0273 - val_loss: 0.5713\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0268 - val_loss: 0.5709\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0263 - val_loss: 0.5710\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0259 - val_loss: 0.5718\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0254 - val_loss: 0.5702\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0250 - val_loss: 0.5698\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0246 - val_loss: 0.5708\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0241 - val_loss: 0.5706\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0237 - val_loss: 0.5707\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0233 - val_loss: 0.5702\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0229 - val_loss: 0.5703\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0226 - val_loss: 0.5702\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0222 - val_loss: 0.5701\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0218 - val_loss: 0.5710\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0215 - val_loss: 0.5702\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.0211 - val_loss: 0.5708\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0208 - val_loss: 0.5699\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0205 - val_loss: 0.5695\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0201 - val_loss: 0.5700\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0197 - val_loss: 0.5703\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0194 - val_loss: 0.5700\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0191 - val_loss: 0.5707\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0187 - val_loss: 0.5704\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0184 - val_loss: 0.5706\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0181 - val_loss: 0.5709\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0178 - val_loss: 0.5696\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0175 - val_loss: 0.5706\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0172 - val_loss: 0.5700\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0169 - val_loss: 0.5704\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0167 - val_loss: 0.5719\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0164 - val_loss: 0.5708\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0161 - val_loss: 0.5703\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0159 - val_loss: 0.5716\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0156 - val_loss: 0.5726\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0154 - val_loss: 0.5708\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0152 - val_loss: 0.5712\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0149 - val_loss: 0.5718\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.5723\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.5705\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0143 - val_loss: 0.5716\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0141 - val_loss: 0.5719\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0139 - val_loss: 0.5690\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0137 - val_loss: 0.5706\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0135 - val_loss: 0.5709\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0133 - val_loss: 0.5711\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.5694\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0130 - val_loss: 0.5707\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0128 - val_loss: 0.5711\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0127 - val_loss: 0.5722\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0125 - val_loss: 0.5712\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0123 - val_loss: 0.5716\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0122 - val_loss: 0.5710\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0120 - val_loss: 0.5700\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0119 - val_loss: 0.5713\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0117 - val_loss: 0.5712\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0116 - val_loss: 0.5699\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0114 - val_loss: 0.5705\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0113 - val_loss: 0.5703\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.0111 - val_loss: 0.5692\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0110 - val_loss: 0.5705\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.5691\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0107 - val_loss: 0.5695\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0106 - val_loss: 0.5697\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0105 - val_loss: 0.5703\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0104 - val_loss: 0.5704\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0102 - val_loss: 0.5697\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0101 - val_loss: 0.5704\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0100 - val_loss: 0.5696\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0099 - val_loss: 0.5697\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0098 - val_loss: 0.5704\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0097 - val_loss: 0.5701\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0096 - val_loss: 0.5704\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.5698\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0094 - val_loss: 0.5691\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0093 - val_loss: 0.5692\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0092 - val_loss: 0.5701\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.5699\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0090 - val_loss: 0.5697\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0089 - val_loss: 0.5693\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0088 - val_loss: 0.5701\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0087 - val_loss: 0.5696\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.5709\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.5711\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0084 - val_loss: 0.5700\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0083 - val_loss: 0.5700\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0082 - val_loss: 0.5707\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0081 - val_loss: 0.5708\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0081 - val_loss: 0.5706\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0080 - val_loss: 0.5704\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0079 - val_loss: 0.5702\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.5713\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.5703\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0077 - val_loss: 0.5702\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0076 - val_loss: 0.5704\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0075 - val_loss: 0.5702\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.5705\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0074 - val_loss: 0.5706\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0073 - val_loss: 0.5707\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0072 - val_loss: 0.5717\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0071 - val_loss: 0.5710\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0071 - val_loss: 0.5707\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0070 - val_loss: 0.5703\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0069 - val_loss: 0.5698\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.5712\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0068 - val_loss: 0.5716\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0067 - val_loss: 0.5716\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.2820 - val_loss: 2.1294\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9555 - val_loss: 1.8581\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6775 - val_loss: 1.6237\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.4471 - val_loss: 1.4433\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.2534 - val_loss: 1.3056\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1040 - val_loss: 1.2111\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9750 - val_loss: 1.0979\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.8493 - val_loss: 1.0139\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7419 - val_loss: 0.9337\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6631 - val_loss: 0.8655\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5940 - val_loss: 0.8194\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5335 - val_loss: 0.7670\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4760 - val_loss: 0.7371\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 188us/step - loss: 0.4292 - val_loss: 0.6983\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3867 - val_loss: 0.6744\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3574 - val_loss: 0.6463\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3254 - val_loss: 0.6292\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2980 - val_loss: 0.6113\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2715 - val_loss: 0.5888\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2494 - val_loss: 0.5759\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2327 - val_loss: 0.5633\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2135 - val_loss: 0.5498\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1973 - val_loss: 0.5371\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1844 - val_loss: 0.5230\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.1719 - val_loss: 0.5117\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.1613 - val_loss: 0.5018\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1509 - val_loss: 0.4975\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 0.1420 - val_loss: 0.4894\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.1338 - val_loss: 0.4854\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1263 - val_loss: 0.4774\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.1193 - val_loss: 0.4701\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1125 - val_loss: 0.4638\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1063 - val_loss: 0.4615\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1012 - val_loss: 0.4540\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0959 - val_loss: 0.4520\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0909 - val_loss: 0.4476\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0867 - val_loss: 0.4471\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0830 - val_loss: 0.4412\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0794 - val_loss: 0.4394\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0762 - val_loss: 0.4387\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0731 - val_loss: 0.4351\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0703 - val_loss: 0.4363\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0676 - val_loss: 0.4327\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0651 - val_loss: 0.4313\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0625 - val_loss: 0.4288\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0602 - val_loss: 0.4285\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 0.0579 - val_loss: 0.4277\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0556 - val_loss: 0.4236\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0535 - val_loss: 0.4225\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0516 - val_loss: 0.4222\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0496 - val_loss: 0.4185\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0477 - val_loss: 0.4210\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0460 - val_loss: 0.4176\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0446 - val_loss: 0.4194\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0431 - val_loss: 0.4195\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0419 - val_loss: 0.4171\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0406 - val_loss: 0.4166\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0394 - val_loss: 0.4188\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0383 - val_loss: 0.4185\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0372 - val_loss: 0.4165\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0362 - val_loss: 0.4194\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0353 - val_loss: 0.4185\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0344 - val_loss: 0.4167\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0336 - val_loss: 0.4178\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0327 - val_loss: 0.4161\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 0.0319 - val_loss: 0.4183\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0312 - val_loss: 0.4178\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0304 - val_loss: 0.4170\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0298 - val_loss: 0.4173\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0291 - val_loss: 0.4192\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0284 - val_loss: 0.4202\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0278 - val_loss: 0.4190\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0272 - val_loss: 0.4193\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0266 - val_loss: 0.4194\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0260 - val_loss: 0.4195\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0255 - val_loss: 0.4199\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0249 - val_loss: 0.4209\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0244 - val_loss: 0.4203\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0239 - val_loss: 0.4207\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.021 - 0s 168us/step - loss: 0.0234 - val_loss: 0.4206\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.022 - 0s 156us/step - loss: 0.0229 - val_loss: 0.4214\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0224 - val_loss: 0.4233\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0220 - val_loss: 0.4230\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0216 - val_loss: 0.4236\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0211 - val_loss: 0.4243\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0206 - val_loss: 0.4248\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0201 - val_loss: 0.4241\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0196 - val_loss: 0.4253\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0191 - val_loss: 0.4264\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0187 - val_loss: 0.4273\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0184 - val_loss: 0.4279\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0180 - val_loss: 0.4291\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0177 - val_loss: 0.4297\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0174 - val_loss: 0.4297\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0170 - val_loss: 0.4305\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0167 - val_loss: 0.4311\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0165 - val_loss: 0.4317\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0162 - val_loss: 0.4337\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0159 - val_loss: 0.4335\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0156 - val_loss: 0.4333\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0154 - val_loss: 0.4344\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0151 - val_loss: 0.4337\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0149 - val_loss: 0.4357\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.4363\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0144 - val_loss: 0.4373\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0142 - val_loss: 0.4371\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.4378\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0138 - val_loss: 0.4387\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0136 - val_loss: 0.4389\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0134 - val_loss: 0.4404\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0132 - val_loss: 0.4414\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0130 - val_loss: 0.4416\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0128 - val_loss: 0.4417\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0126 - val_loss: 0.4425\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0124 - val_loss: 0.4430\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0122 - val_loss: 0.4430\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.4435\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0119 - val_loss: 0.4443\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0117 - val_loss: 0.4448\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0116 - val_loss: 0.4453\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.4455\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0112 - val_loss: 0.4458\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0111 - val_loss: 0.4471\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.4471\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0108 - val_loss: 0.4477\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0107 - val_loss: 0.4485\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0105 - val_loss: 0.4493\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0104 - val_loss: 0.4494\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0103 - val_loss: 0.4499\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0101 - val_loss: 0.4506\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0100 - val_loss: 0.4512\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0099 - val_loss: 0.4509\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0097 - val_loss: 0.4509\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0096 - val_loss: 0.4519\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.4527\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0094 - val_loss: 0.4523\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0093 - val_loss: 0.4519\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0091 - val_loss: 0.4523\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0090 - val_loss: 0.4537\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0089 - val_loss: 0.4548\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.4557\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0087 - val_loss: 0.4570\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.4579\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.4582\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0083 - val_loss: 0.4580\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0082 - val_loss: 0.4588\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0081 - val_loss: 0.4592\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 182us/step - loss: 0.0080 - val_loss: 0.4594\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0079 - val_loss: 0.4597\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0078 - val_loss: 0.4600\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.4609\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0077 - val_loss: 0.4603\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0076 - val_loss: 0.4608\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0075 - val_loss: 0.4616\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.4617\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.4626\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.4627\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.4637\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.4632\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0070 - val_loss: 0.4630\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.4634\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.4636\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0068 - val_loss: 0.4644\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0067 - val_loss: 0.4650\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0066 - val_loss: 0.4648\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.4655\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.4662\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.4669\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.4672\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.4678\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0062 - val_loss: 0.4682\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0062 - val_loss: 0.4687\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.4690\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.4689\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.4690\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.4698\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0059 - val_loss: 0.4703\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.4705\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0057 - val_loss: 0.4711\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0057 - val_loss: 0.4712\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 0.0056 - val_loss: 0.4724\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.4730\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.4734\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.4731\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0054 - val_loss: 0.4738\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 0.0054 - val_loss: 0.4748\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.4750\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.4751\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.4755\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0052 - val_loss: 0.4760\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.4762\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.4767\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.4774\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0050 - val_loss: 0.4776\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.4782\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.4790\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.4790\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0048 - val_loss: 0.4790\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0047 - val_loss: 0.4796\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0047 - val_loss: 0.4799\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 4.0556 - val_loss: 3.6598\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1305 - val_loss: 2.8328\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4675 - val_loss: 2.3405\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0365 - val_loss: 1.9905\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6135 - val_loss: 1.6356\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2166 - val_loss: 1.2943\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.8813 - val_loss: 1.0641\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.6399 - val_loss: 0.8815\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5153 - val_loss: 0.7646\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4055 - val_loss: 0.6934\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3273 - val_loss: 0.6370\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2651 - val_loss: 0.5868\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.2151 - val_loss: 0.5521\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1729 - val_loss: 0.5380\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1452 - val_loss: 0.5164\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1167 - val_loss: 0.5050\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1051 - val_loss: 0.4994\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0841 - val_loss: 0.4850\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0660 - val_loss: 0.4870\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0550 - val_loss: 0.4670\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0479 - val_loss: 0.4631\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 195us/step - loss: 0.0412 - val_loss: 0.4548\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0365 - val_loss: 0.4553\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0319 - val_loss: 0.4597\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0287 - val_loss: 0.4551\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0253 - val_loss: 0.4522\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0232 - val_loss: 0.4570\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0209 - val_loss: 0.4529\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0190 - val_loss: 0.4532\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0174 - val_loss: 0.4566\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0159 - val_loss: 0.4533\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0147 - val_loss: 0.4562\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0135 - val_loss: 0.4578\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0124 - val_loss: 0.4595\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.4586\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.4626\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0102 - val_loss: 0.4633\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0095 - val_loss: 0.4636\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 136us/step - loss: 0.0090 - val_loss: 0.4621\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.4629\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0079 - val_loss: 0.4662\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.4682\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0071 - val_loss: 0.4691\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0068 - val_loss: 0.4685\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0064 - val_loss: 0.4697\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0061 - val_loss: 0.4687\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0058 - val_loss: 0.4722\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.4733\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.4748\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.4744\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.4764\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0046 - val_loss: 0.4788\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.4800\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0042 - val_loss: 0.4812\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.0041 - val_loss: 0.4782\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0039 - val_loss: 0.4816\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.4867\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0036 - val_loss: 0.4858\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0035 - val_loss: 0.4869\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.4878\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.4888\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.4891\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.4966\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.4904\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.4898\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 156us/step - loss: 0.0027 - val_loss: 0.4938\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.4956\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.4977\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.4964\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.4985\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.4975\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.4990\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0022 - val_loss: 0.5001\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.5014\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0020 - val_loss: 0.5021\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.5026\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.5044\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.5055\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.5064\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.5087\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.5083\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.5098\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.5102\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.5123\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.5134\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.5137\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.5148\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.5153\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.5170\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.5173\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5182\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5182\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5190\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.5198\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.5201\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.5222\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.5216\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.5233\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.5238\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.5248\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.5257\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.5247\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.5246\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.5259\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.9180e-04 - val_loss: 0.5266\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.7175e-04 - val_loss: 0.5292\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 9.5294e-04 - val_loss: 0.5311\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.3514e-04 - val_loss: 0.5304\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.1393e-04 - val_loss: 0.5296\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.9727e-04 - val_loss: 0.5302\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.7988e-04 - val_loss: 0.5318\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.6238e-04 - val_loss: 0.5326\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.4622e-04 - val_loss: 0.5329\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.3054e-04 - val_loss: 0.5335\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.1511e-04 - val_loss: 0.5343\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.0023e-04 - val_loss: 0.5361\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.8653e-04 - val_loss: 0.5362\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.7175e-04 - val_loss: 0.5380\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5776e-04 - val_loss: 0.5368\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.4317e-04 - val_loss: 0.5373\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.2990e-04 - val_loss: 0.5376\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.1763e-04 - val_loss: 0.5393\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 7.0330e-04 - val_loss: 0.5409\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.9205e-04 - val_loss: 0.5434\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.7950e-04 - val_loss: 0.5431\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.6803e-04 - val_loss: 0.5432\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5606e-04 - val_loss: 0.5438\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4590e-04 - val_loss: 0.5445\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3440e-04 - val_loss: 0.5453\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.2356e-04 - val_loss: 0.5453\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.1367e-04 - val_loss: 0.5459\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.0397e-04 - val_loss: 0.5464\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9442e-04 - val_loss: 0.5479\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.8431e-04 - val_loss: 0.5481\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.7440e-04 - val_loss: 0.5491\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.6535e-04 - val_loss: 0.5499\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5576e-04 - val_loss: 0.5493\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4767e-04 - val_loss: 0.5492\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.3893e-04 - val_loss: 0.5506\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 5.3050e-04 - val_loss: 0.5515\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2230e-04 - val_loss: 0.5522\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.1417e-04 - val_loss: 0.5529\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.0651e-04 - val_loss: 0.5538\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9876e-04 - val_loss: 0.5547\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9115e-04 - val_loss: 0.5548\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8427e-04 - val_loss: 0.5547\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7703e-04 - val_loss: 0.5563\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.6940e-04 - val_loss: 0.5567\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.6271e-04 - val_loss: 0.5576\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.5612e-04 - val_loss: 0.5581\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.4963e-04 - val_loss: 0.5594\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.4277e-04 - val_loss: 0.5601\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.3717e-04 - val_loss: 0.5597\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.3046e-04 - val_loss: 0.5600\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2455e-04 - val_loss: 0.5607\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 4.1804e-04 - val_loss: 0.5616\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 136us/step - loss: 4.1229e-04 - val_loss: 0.5614\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.0657e-04 - val_loss: 0.5614\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0052e-04 - val_loss: 0.5618\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9495e-04 - val_loss: 0.5623\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.8950e-04 - val_loss: 0.5633\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8378e-04 - val_loss: 0.5639\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7881e-04 - val_loss: 0.5645\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.7307e-04 - val_loss: 0.5659\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6821e-04 - val_loss: 0.5670\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6403e-04 - val_loss: 0.5691\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5867e-04 - val_loss: 0.5684\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.5398e-04 - val_loss: 0.5681\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4903e-04 - val_loss: 0.5687\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4413e-04 - val_loss: 0.5695\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.3982e-04 - val_loss: 0.5703\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3516e-04 - val_loss: 0.5705\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3116e-04 - val_loss: 0.5712\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 3.2622e-04 - val_loss: 0.5714\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 3.2223e-04 - val_loss: 0.5717\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1805e-04 - val_loss: 0.5719\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1397e-04 - val_loss: 0.5729\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.1019e-04 - val_loss: 0.5733\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0596e-04 - val_loss: 0.5735\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0173e-04 - val_loss: 0.5738\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9812e-04 - val_loss: 0.5747\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9468e-04 - val_loss: 0.5757\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9043e-04 - val_loss: 0.5757\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8666e-04 - val_loss: 0.5758\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8302e-04 - val_loss: 0.5770\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7966e-04 - val_loss: 0.5776\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7631e-04 - val_loss: 0.5777\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7268e-04 - val_loss: 0.5777\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6949e-04 - val_loss: 0.5783\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6618e-04 - val_loss: 0.5787\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.6290e-04 - val_loss: 0.5788\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.5999e-04 - val_loss: 0.5800\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5668e-04 - val_loss: 0.5804\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5352e-04 - val_loss: 0.5813\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5057e-04 - val_loss: 0.5809\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4754e-04 - val_loss: 0.5808\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4515e-04 - val_loss: 0.5813\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4166e-04 - val_loss: 0.5826\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3883e-04 - val_loss: 0.5838\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3627e-04 - val_loss: 0.5847\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 5.6168 - val_loss: 4.5124\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3663 - val_loss: 3.4991\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2750 - val_loss: 2.5858\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3707 - val_loss: 1.9035\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.6366 - val_loss: 1.4035\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.0773 - val_loss: 1.1277\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7855 - val_loss: 0.9239\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6055 - val_loss: 0.7823\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.4792 - val_loss: 0.6829\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3838 - val_loss: 0.6195\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3088 - val_loss: 0.5794\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2458 - val_loss: 0.5338\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2056 - val_loss: 0.5050\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1721 - val_loss: 0.4921\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1495 - val_loss: 0.4782\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1242 - val_loss: 0.4670\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1038 - val_loss: 0.4668\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0881 - val_loss: 0.4457\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0748 - val_loss: 0.4456\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0647 - val_loss: 0.4403\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0569 - val_loss: 0.4385\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0499 - val_loss: 0.4321\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0439 - val_loss: 0.4389\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0387 - val_loss: 0.4318\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0346 - val_loss: 0.4326\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0313 - val_loss: 0.4344\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0281 - val_loss: 0.4325\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0254 - val_loss: 0.4340\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0232 - val_loss: 0.4368\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0213 - val_loss: 0.4396\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0196 - val_loss: 0.4378\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0180 - val_loss: 0.4422\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0167 - val_loss: 0.4406\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0154 - val_loss: 0.4392\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0146 - val_loss: 0.4405\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0135 - val_loss: 0.4496\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0126 - val_loss: 0.4453\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0118 - val_loss: 0.4440\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0109 - val_loss: 0.4533\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0103 - val_loss: 0.4500\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0097 - val_loss: 0.4517\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0091 - val_loss: 0.4521\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.4531\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0081 - val_loss: 0.4556\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.4563\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.4572\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.4596\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.4593\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.4627\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0060 - val_loss: 0.4672\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.4674\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0054 - val_loss: 0.4643\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.4684\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0049 - val_loss: 0.4687\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0047 - val_loss: 0.4679\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.4713\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0044 - val_loss: 0.4742\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0042 - val_loss: 0.4760\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.4775\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0039 - val_loss: 0.4769\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0037 - val_loss: 0.4791\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.4809\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0034 - val_loss: 0.4828\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.4838\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.4852\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0031 - val_loss: 0.4849\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.4858\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.4851\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0028 - val_loss: 0.4883\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0027 - val_loss: 0.4900\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.4923\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.4950\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.4946\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.4960\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.4980\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.5001\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.5013\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.5034\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.5049\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.5053\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.5099\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.5099\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.5120\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.5134\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0017 - val_loss: 0.5142\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0017 - val_loss: 0.5136\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.5167\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0016 - val_loss: 0.5191\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.5189\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0015 - val_loss: 0.5197\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0015 - val_loss: 0.5215\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.5246\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.5265\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.5265\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.5269\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.5297\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5312\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.5323\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.5346\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0012 - val_loss: 0.5339\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.5370\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.5371\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0011 - val_loss: 0.5384\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.5386\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.5408\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.5423\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.5463\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.5453\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.7952e-04 - val_loss: 0.5441\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.6122e-04 - val_loss: 0.5469\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.3912e-04 - val_loss: 0.5464\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.2392e-04 - val_loss: 0.5454\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.0436e-04 - val_loss: 0.5485\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.8539e-04 - val_loss: 0.5491\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.6832e-04 - val_loss: 0.5510\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.5111e-04 - val_loss: 0.5531\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.3409e-04 - val_loss: 0.5528\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.1929e-04 - val_loss: 0.5532\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.0383e-04 - val_loss: 0.5542\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.8869e-04 - val_loss: 0.5564\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 7.7423e-04 - val_loss: 0.5575\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5952e-04 - val_loss: 0.5587\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.4562e-04 - val_loss: 0.5612\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.3212e-04 - val_loss: 0.5618\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.1752e-04 - val_loss: 0.5642\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.0397e-04 - val_loss: 0.5653\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.9255e-04 - val_loss: 0.5663\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.8036e-04 - val_loss: 0.5662\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.6646e-04 - val_loss: 0.5682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5529e-04 - val_loss: 0.5700\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.4413e-04 - val_loss: 0.5699\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3159e-04 - val_loss: 0.5725\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.2058e-04 - val_loss: 0.5731\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1161e-04 - val_loss: 0.5760\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.0166e-04 - val_loss: 0.5748\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.9052e-04 - val_loss: 0.5748\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 5.7853e-04 - val_loss: 0.5771\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.6928e-04 - val_loss: 0.5784\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.6083e-04 - val_loss: 0.5800\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.5200e-04 - val_loss: 0.5800\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4308e-04 - val_loss: 0.5822\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.3389e-04 - val_loss: 0.5822\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.2425e-04 - val_loss: 0.5829\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1614e-04 - val_loss: 0.5833\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0820e-04 - val_loss: 0.5845\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.0066e-04 - val_loss: 0.5855\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9273e-04 - val_loss: 0.5856\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8543e-04 - val_loss: 0.5867\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.7769e-04 - val_loss: 0.5881\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.7056e-04 - val_loss: 0.5886\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6335e-04 - val_loss: 0.5895\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5569e-04 - val_loss: 0.5900\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4969e-04 - val_loss: 0.5904\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.4274e-04 - val_loss: 0.5918\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3580e-04 - val_loss: 0.5930\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2927e-04 - val_loss: 0.5936\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2285e-04 - val_loss: 0.5953\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1707e-04 - val_loss: 0.5960\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1106e-04 - val_loss: 0.5966\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0526e-04 - val_loss: 0.5965\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9879e-04 - val_loss: 0.5981\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9359e-04 - val_loss: 0.5999\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8752e-04 - val_loss: 0.6006\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8241e-04 - val_loss: 0.6006\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7693e-04 - val_loss: 0.6019\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7177e-04 - val_loss: 0.6014\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6578e-04 - val_loss: 0.6025\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.6239e-04 - val_loss: 0.6028\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.5750e-04 - val_loss: 0.6048\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 3.5073e-04 - val_loss: 0.6049\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 135us/step - loss: 3.4606e-04 - val_loss: 0.6057\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.4160e-04 - val_loss: 0.6070\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3720e-04 - val_loss: 0.6084\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.3220e-04 - val_loss: 0.6092\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2813e-04 - val_loss: 0.6086\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2335e-04 - val_loss: 0.6092\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.1957e-04 - val_loss: 0.6101\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1614e-04 - val_loss: 0.6126\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1093e-04 - val_loss: 0.6129\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.0681e-04 - val_loss: 0.6132\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0380e-04 - val_loss: 0.6130\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9891e-04 - val_loss: 0.6146\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9592e-04 - val_loss: 0.6165\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9134e-04 - val_loss: 0.6168\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8773e-04 - val_loss: 0.6162\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8521e-04 - val_loss: 0.6162\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8048e-04 - val_loss: 0.6191\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 2.7724e-04 - val_loss: 0.6201\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7356e-04 - val_loss: 0.6195\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7005e-04 - val_loss: 0.6202\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6663e-04 - val_loss: 0.6212\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6315e-04 - val_loss: 0.6230\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6030e-04 - val_loss: 0.6237\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5710e-04 - val_loss: 0.6240\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5427e-04 - val_loss: 0.6248\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5134e-04 - val_loss: 0.6253\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4802e-04 - val_loss: 0.6256\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4488e-04 - val_loss: 0.6266\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4228e-04 - val_loss: 0.6258\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3910e-04 - val_loss: 0.6271\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 3.8921 - val_loss: 3.8192\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1701 - val_loss: 3.1434\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5924 - val_loss: 2.6498\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 2.2675 - val_loss: 2.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9349 - val_loss: 2.0705\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6543 - val_loss: 1.8196\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.3857 - val_loss: 1.5840\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.1543 - val_loss: 1.4144\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.9566 - val_loss: 1.2331\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7858 - val_loss: 1.1409\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6389 - val_loss: 1.0135\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5242 - val_loss: 0.9911\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4479 - val_loss: 0.8861\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3693 - val_loss: 0.8829\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2927 - val_loss: 0.8050\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 0.2390 - val_loss: 0.8279\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1963 - val_loss: 0.7543\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1647 - val_loss: 0.7692\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1347 - val_loss: 0.7354\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1113 - val_loss: 0.7383\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0911 - val_loss: 0.7279\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0770 - val_loss: 0.7147\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0671 - val_loss: 0.7142\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0576 - val_loss: 0.7190\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0498 - val_loss: 0.7396\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0412 - val_loss: 0.7237\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0369 - val_loss: 0.7278\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0322 - val_loss: 0.7288\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0292 - val_loss: 0.7283\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0261 - val_loss: 0.7352\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0236 - val_loss: 0.7357\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0219 - val_loss: 0.7450\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0199 - val_loss: 0.7284\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0179 - val_loss: 0.7532\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0164 - val_loss: 0.7575\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0151 - val_loss: 0.7510\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0140 - val_loss: 0.7617\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0128 - val_loss: 0.7624\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0119 - val_loss: 0.7630\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0111 - val_loss: 0.7640\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0104 - val_loss: 0.7755\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0097 - val_loss: 0.7841\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0091 - val_loss: 0.7709\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.7789\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0081 - val_loss: 0.7869\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0076 - val_loss: 0.7944\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.7939\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0068 - val_loss: 0.7935\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0065 - val_loss: 0.8023\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.8055\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.8075\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.8097\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.8111\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0050 - val_loss: 0.8190\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.8185\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.8223\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.8262\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.8243\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0040 - val_loss: 0.8291\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0039 - val_loss: 0.8334\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.8407\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.8450\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.8447\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.8449\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0032 - val_loss: 0.8497\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 136us/step - loss: 0.0031 - val_loss: 0.8563\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.8544\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0028 - val_loss: 0.8554\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.8595\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8617\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.8664\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0025 - val_loss: 0.8646\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.8653\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.8701\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.8769\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.8772\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 156us/step - loss: 0.0021 - val_loss: 0.8803\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0020 - val_loss: 0.8814\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.8839\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.8859\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.8929\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0018 - val_loss: 0.8855\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8868\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8942\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.8970\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.8989\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.9004\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.9032\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.9058\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.9068\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.9068\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.9112\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.9112\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.9146\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.9190\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.9178\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.9214\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0011 - val_loss: 0.9235\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0011 - val_loss: 0.9253\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.9259\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.9300\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.9329\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0010 - val_loss: 0.9322\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 9.9349e-04 - val_loss: 0.9329\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.6996e-04 - val_loss: 0.9369\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 9.4555e-04 - val_loss: 0.9370\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 9.2431e-04 - val_loss: 0.9389\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.0020e-04 - val_loss: 0.9411\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.8290e-04 - val_loss: 0.9435\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.6541e-04 - val_loss: 0.9443\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.4305e-04 - val_loss: 0.9446\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.2692e-04 - val_loss: 0.9473\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 8.0918e-04 - val_loss: 0.9465\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 7.9284e-04 - val_loss: 0.9490\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.7369e-04 - val_loss: 0.9514\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 7.5738e-04 - val_loss: 0.9548\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.4116e-04 - val_loss: 0.9565\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 7.2760e-04 - val_loss: 0.9585\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 7.1177e-04 - val_loss: 0.9592\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.9733e-04 - val_loss: 0.9629\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.8355e-04 - val_loss: 0.9653\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.7049e-04 - val_loss: 0.9660\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.5677e-04 - val_loss: 0.9660\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4765e-04 - val_loss: 0.9689\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.3153e-04 - val_loss: 0.9698\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.2057e-04 - val_loss: 0.9699\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.0839e-04 - val_loss: 0.9705\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9717e-04 - val_loss: 0.9723\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 5.0693e-0 - 0s 183us/step - loss: 5.8534e-04 - val_loss: 0.9735\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 5.7816e-04 - val_loss: 0.9762\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.6406e-04 - val_loss: 0.9800\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.5423e-04 - val_loss: 0.9807\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4467e-04 - val_loss: 0.9815\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.3495e-04 - val_loss: 0.9832\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.2556e-04 - val_loss: 0.9877\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.1544e-04 - val_loss: 0.9884\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.0629e-04 - val_loss: 0.9889\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.9593e-04 - val_loss: 0.9890\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8838e-04 - val_loss: 0.9905\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.7959e-04 - val_loss: 0.9922\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.7228e-04 - val_loss: 0.9940\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6454e-04 - val_loss: 0.9919\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.5722e-04 - val_loss: 0.9945\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.4798e-04 - val_loss: 0.9975\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.4063e-04 - val_loss: 0.9988\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 4.3336e-04 - val_loss: 0.9998\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.2619e-04 - val_loss: 0.9994\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.1977e-04 - val_loss: 1.0009\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1319e-04 - val_loss: 1.0003\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.0727e-04 - val_loss: 1.0000\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9965e-04 - val_loss: 1.0040\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9322e-04 - val_loss: 1.0081\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.8727e-04 - val_loss: 1.0109\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8023e-04 - val_loss: 1.0103\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7345e-04 - val_loss: 1.0098\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6727e-04 - val_loss: 1.0106\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6153e-04 - val_loss: 1.0121\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.5670e-04 - val_loss: 1.0135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.5108e-04 - val_loss: 1.0173\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.4636e-04 - val_loss: 1.0175\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.4026e-04 - val_loss: 1.0172\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3546e-04 - val_loss: 1.0194\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 3.2969e-04 - val_loss: 1.0192\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.2496e-04 - val_loss: 1.0192\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.2029e-04 - val_loss: 1.0229\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.1525e-04 - val_loss: 1.0247\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1056e-04 - val_loss: 1.0256\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0700e-04 - val_loss: 1.0249\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0121e-04 - val_loss: 1.0277\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9723e-04 - val_loss: 1.0282\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9212e-04 - val_loss: 1.0309\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8886e-04 - val_loss: 1.0316\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8407e-04 - val_loss: 1.0325\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7978e-04 - val_loss: 1.0339\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7599e-04 - val_loss: 1.0336\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7165e-04 - val_loss: 1.0357\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 2.6837e-04 - val_loss: 1.0370\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.6494e-04 - val_loss: 1.0374\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.6082e-04 - val_loss: 1.0381\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.5812e-04 - val_loss: 1.0401\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.5379e-04 - val_loss: 1.0409\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.5068e-04 - val_loss: 1.0408\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4760e-04 - val_loss: 1.0423\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4487e-04 - val_loss: 1.0455\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4113e-04 - val_loss: 1.0455\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3780e-04 - val_loss: 1.0470\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3417e-04 - val_loss: 1.0480\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.3145e-04 - val_loss: 1.0481\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2832e-04 - val_loss: 1.0500\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.2494e-04 - val_loss: 1.0504\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2237e-04 - val_loss: 1.0503\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1965e-04 - val_loss: 1.0526\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1688e-04 - val_loss: 1.0521\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1393e-04 - val_loss: 1.0541\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.1135e-04 - val_loss: 1.0558\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 2.0844e-04 - val_loss: 1.0562\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0620e-04 - val_loss: 1.0585\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.0340e-04 - val_loss: 1.0590\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.0092e-04 - val_loss: 1.0607\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9825e-04 - val_loss: 1.0608\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 4.3385 - val_loss: 3.8281\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.2154 - val_loss: 2.8852\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4475 - val_loss: 2.4104\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.0367 - val_loss: 2.0265\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6915 - val_loss: 1.7150\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 1.4015 - val_loss: 1.4624\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1771 - val_loss: 1.2579\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.9722 - val_loss: 1.1038\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.8055 - val_loss: 0.9627\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.6744 - val_loss: 0.8503\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5667 - val_loss: 0.7690\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4784 - val_loss: 0.6867\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4150 - val_loss: 0.6351\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3501 - val_loss: 0.6109\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3041 - val_loss: 0.5569\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2619 - val_loss: 0.5387\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2252 - val_loss: 0.5302\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1929 - val_loss: 0.4955\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1637 - val_loss: 0.4914\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1407 - val_loss: 0.4717\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1212 - val_loss: 0.4559\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1025 - val_loss: 0.4727\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0892 - val_loss: 0.4510\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0766 - val_loss: 0.4482\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0672 - val_loss: 0.4431\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0581 - val_loss: 0.4487\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0508 - val_loss: 0.4365\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0444 - val_loss: 0.4471\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0395 - val_loss: 0.4469\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0351 - val_loss: 0.4461\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0319 - val_loss: 0.4388\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0284 - val_loss: 0.4420\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0258 - val_loss: 0.4468\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0235 - val_loss: 0.4432\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0216 - val_loss: 0.4449\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0199 - val_loss: 0.4567\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0185 - val_loss: 0.4524\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0169 - val_loss: 0.4488\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0157 - val_loss: 0.4482\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0145 - val_loss: 0.4541\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0134 - val_loss: 0.4574\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0125 - val_loss: 0.4599\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0118 - val_loss: 0.4606\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0110 - val_loss: 0.4605\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0102 - val_loss: 0.4626\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0097 - val_loss: 0.4634\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0091 - val_loss: 0.4662\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.4683\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0080 - val_loss: 0.4675\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.4721\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0072 - val_loss: 0.4741\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0068 - val_loss: 0.4730\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0065 - val_loss: 0.4718\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.4742\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.4803\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.4791\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 0.0053 - val_loss: 0.4794\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.4821\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.4830\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0046 - val_loss: 0.4856\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.4865\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0042 - val_loss: 0.4879\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.4911\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0039 - val_loss: 0.4911\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.4933\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.4972\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.4970\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.4969\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.003 - 0s 156us/step - loss: 0.0032 - val_loss: 0.5005\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0031 - val_loss: 0.4989\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.5031\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.5057\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0028 - val_loss: 0.5061\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.5068\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.5089\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.5112\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.5116\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0024 - val_loss: 0.5102\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0023 - val_loss: 0.5124\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.5160\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.5175\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0021 - val_loss: 0.5183\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.5185\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.5200\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.5233\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0019 - val_loss: 0.5234\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.5254\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.5264\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.5264\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.0017 - val_loss: 0.5272\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.5297\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.5284\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.5321\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0015 - val_loss: 0.5332\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.5347\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0014 - val_loss: 0.5368\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.5378\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5387\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5384\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0013 - val_loss: 0.5378\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.5395\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.5411\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.5393\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0012 - val_loss: 0.5418\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.5454\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0011 - val_loss: 0.5460\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0011 - val_loss: 0.5466\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.5478\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0010 - val_loss: 0.5480\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0010 - val_loss: 0.5489\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.9433e-04 - val_loss: 0.5495\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.7335e-04 - val_loss: 0.5507\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 9.5366e-04 - val_loss: 0.5504\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 9.3308e-04 - val_loss: 0.5514\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 9.1299e-04 - val_loss: 0.5524\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.9435e-04 - val_loss: 0.5539\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 8.7610e-04 - val_loss: 0.5556\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 8.5954e-04 - val_loss: 0.5558\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 8.4503e-04 - val_loss: 0.5563\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 8.2331e-04 - val_loss: 0.5581\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.0826e-04 - val_loss: 0.5592\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.9089e-04 - val_loss: 0.5603\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.7484e-04 - val_loss: 0.5607\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.5856e-04 - val_loss: 0.5613\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 7.4594e-04 - val_loss: 0.5637\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 7.3044e-04 - val_loss: 0.5637\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 7.1763e-04 - val_loss: 0.5642\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 7.0311e-04 - val_loss: 0.5636\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.9026e-04 - val_loss: 0.5630\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 6.7879e-04 - val_loss: 0.5649\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 6.6604e-04 - val_loss: 0.5656\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.5345e-04 - val_loss: 0.5676\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.4089e-04 - val_loss: 0.5680\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.3103e-04 - val_loss: 0.5684\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1964e-04 - val_loss: 0.5697\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 6.0906e-04 - val_loss: 0.5701\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 5.9758e-04 - val_loss: 0.5706\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.8729e-04 - val_loss: 0.5720\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.7734e-04 - val_loss: 0.5720\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 5.6788e-04 - val_loss: 0.5735\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 5.5841e-04 - val_loss: 0.5742\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4897e-04 - val_loss: 0.5754\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 5.3988e-04 - val_loss: 0.5767\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 5.3095e-04 - val_loss: 0.5775\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 5.2247e-04 - val_loss: 0.5779\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 5.1360e-04 - val_loss: 0.5792\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 5.0563e-04 - val_loss: 0.5801\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 4.9836e-04 - val_loss: 0.5802\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.8979e-04 - val_loss: 0.5805\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.8224e-04 - val_loss: 0.5812\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.7528e-04 - val_loss: 0.5820\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.6770e-04 - val_loss: 0.5820\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 4.5998e-04 - val_loss: 0.5822\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 4.5413e-04 - val_loss: 0.5830\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.4631e-04 - val_loss: 0.5835\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.4020e-04 - val_loss: 0.5835\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.3306e-04 - val_loss: 0.5848\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.2659e-04 - val_loss: 0.5855\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.2131e-04 - val_loss: 0.5872\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.1378e-04 - val_loss: 0.5871\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.0837e-04 - val_loss: 0.5875\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.0239e-04 - val_loss: 0.5885\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.9608e-04 - val_loss: 0.5893\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.9098e-04 - val_loss: 0.5898\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.8567e-04 - val_loss: 0.5911\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.7975e-04 - val_loss: 0.5918\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.7402e-04 - val_loss: 0.5927\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 3.6904e-04 - val_loss: 0.5923\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6316e-04 - val_loss: 0.5924\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.5762e-04 - val_loss: 0.5927\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.5381e-04 - val_loss: 0.5930\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.4760e-04 - val_loss: 0.5941\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.4267e-04 - val_loss: 0.5956\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 3.3816e-04 - val_loss: 0.5958\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 3.3288e-04 - val_loss: 0.5970\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.2812e-04 - val_loss: 0.5978\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.2405e-04 - val_loss: 0.5987\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1885e-04 - val_loss: 0.5987\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.1500e-04 - val_loss: 0.5987\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.1037e-04 - val_loss: 0.6003\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0620e-04 - val_loss: 0.6005\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0211e-04 - val_loss: 0.6012\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.9780e-04 - val_loss: 0.6019\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 2.9410e-04 - val_loss: 0.6032\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.8983e-04 - val_loss: 0.6040\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.8620e-04 - val_loss: 0.6045\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8241e-04 - val_loss: 0.6052\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7879e-04 - val_loss: 0.6052\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7485e-04 - val_loss: 0.6056\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7142e-04 - val_loss: 0.6069\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6794e-04 - val_loss: 0.6068\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.6455e-04 - val_loss: 0.6072\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.6117e-04 - val_loss: 0.6082\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 2.5768e-04 - val_loss: 0.6083\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 135us/step - loss: 2.5437e-04 - val_loss: 0.6090\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.5157e-04 - val_loss: 0.6096\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4832e-04 - val_loss: 0.6101\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.4501e-04 - val_loss: 0.6104\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.4187e-04 - val_loss: 0.6103\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.3909e-04 - val_loss: 0.6107\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 3.9526 - val_loss: 3.4929\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.3003 - val_loss: 2.9606\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7624 - val_loss: 2.5507\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.3311 - val_loss: 2.2201\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.9690 - val_loss: 1.9505\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.6704 - val_loss: 1.7175\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 1.4175 - val_loss: 1.5231\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 1.2110 - val_loss: 1.3716\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.0523 - val_loss: 1.2539\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.9120 - val_loss: 1.1255\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.7983 - val_loss: 1.0387\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6984 - val_loss: 0.9507\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.6216 - val_loss: 0.8786\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5430 - val_loss: 0.8267\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.4819 - val_loss: 0.7659\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4287 - val_loss: 0.7141\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3743 - val_loss: 0.6907\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3315 - val_loss: 0.6516\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2946 - val_loss: 0.6261\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2639 - val_loss: 0.6102\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.2389 - val_loss: 0.5888\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2159 - val_loss: 0.5806\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1968 - val_loss: 0.5569\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.1816 - val_loss: 0.5605\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.1663 - val_loss: 0.5488\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1538 - val_loss: 0.5398\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1433 - val_loss: 0.5301\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1304 - val_loss: 0.5291\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1220 - val_loss: 0.5191\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1111 - val_loss: 0.5159\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1029 - val_loss: 0.5141\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0947 - val_loss: 0.5082\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0883 - val_loss: 0.5029\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.085 - 0s 156us/step - loss: 0.0815 - val_loss: 0.5094\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0750 - val_loss: 0.4982\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0688 - val_loss: 0.4978\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0638 - val_loss: 0.4977\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0598 - val_loss: 0.4991\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0562 - val_loss: 0.4972\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0531 - val_loss: 0.4971\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0502 - val_loss: 0.4964\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.0478 - val_loss: 0.4923\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0453 - val_loss: 0.4966\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0432 - val_loss: 0.4950\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0412 - val_loss: 0.4923\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0394 - val_loss: 0.4949\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0379 - val_loss: 0.4925\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0361 - val_loss: 0.4929\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0347 - val_loss: 0.4944\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0332 - val_loss: 0.4924\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0320 - val_loss: 0.4925\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0309 - val_loss: 0.4940\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0297 - val_loss: 0.4911\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0287 - val_loss: 0.4942\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0278 - val_loss: 0.4957\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0268 - val_loss: 0.4944\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0261 - val_loss: 0.4949\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0251 - val_loss: 0.4967\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0244 - val_loss: 0.4946\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0236 - val_loss: 0.4956\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0228 - val_loss: 0.4975\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0222 - val_loss: 0.4965\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0215 - val_loss: 0.4940\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.0209 - val_loss: 0.4934\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.0203 - val_loss: 0.4955\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0198 - val_loss: 0.4957\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0192 - val_loss: 0.4960\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0186 - val_loss: 0.4951\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0181 - val_loss: 0.4961\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0175 - val_loss: 0.4980\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0170 - val_loss: 0.4951\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0165 - val_loss: 0.4967\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0160 - val_loss: 0.4966\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0156 - val_loss: 0.4967\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0152 - val_loss: 0.4961\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0148 - val_loss: 0.4965\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0145 - val_loss: 0.4961\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0141 - val_loss: 0.4984\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0138 - val_loss: 0.5005\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0134 - val_loss: 0.5020\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0131 - val_loss: 0.5004\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0128 - val_loss: 0.4997\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0126 - val_loss: 0.5020\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0123 - val_loss: 0.5019\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.0120 - val_loss: 0.5019\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.0118 - val_loss: 0.5052\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0115 - val_loss: 0.5050\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0113 - val_loss: 0.5023\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0110 - val_loss: 0.5023\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0108 - val_loss: 0.5035\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0106 - val_loss: 0.5050\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0104 - val_loss: 0.5048\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0102 - val_loss: 0.5035\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0100 - val_loss: 0.5056\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0098 - val_loss: 0.5080\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0096 - val_loss: 0.5082\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0094 - val_loss: 0.5075\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0092 - val_loss: 0.5079\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0091 - val_loss: 0.5072\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0089 - val_loss: 0.5086\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0088 - val_loss: 0.5086\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0086 - val_loss: 0.5090\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0085 - val_loss: 0.5090\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0083 - val_loss: 0.5090\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0082 - val_loss: 0.5108\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0080 - val_loss: 0.5114\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0079 - val_loss: 0.5104\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 0.0078 - val_loss: 0.5116\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0077 - val_loss: 0.5134\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0075 - val_loss: 0.5128\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0074 - val_loss: 0.5121\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0073 - val_loss: 0.5135\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.5131\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0071 - val_loss: 0.5145\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0070 - val_loss: 0.5145\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0069 - val_loss: 0.5162\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0068 - val_loss: 0.5160\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0067 - val_loss: 0.5160\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.5177\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0065 - val_loss: 0.5183\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0064 - val_loss: 0.5196\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.5177\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0062 - val_loss: 0.5184\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0061 - val_loss: 0.5191\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0060 - val_loss: 0.5204\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0059 - val_loss: 0.5226\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.5223\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0058 - val_loss: 0.5213\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0057 - val_loss: 0.5233\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0056 - val_loss: 0.5241\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0056 - val_loss: 0.5248\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0055 - val_loss: 0.5246\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0054 - val_loss: 0.5233\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0053 - val_loss: 0.5236\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.005 - 0s 260us/step - loss: 0.0053 - val_loss: 0.5238\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0052 - val_loss: 0.5255\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0051 - val_loss: 0.5260\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0051 - val_loss: 0.5277\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0050 - val_loss: 0.5276\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0049 - val_loss: 0.5274\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0049 - val_loss: 0.5273\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0048 - val_loss: 0.5279\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0047 - val_loss: 0.5286\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0047 - val_loss: 0.5294\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0046 - val_loss: 0.5299\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0045 - val_loss: 0.5300\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0045 - val_loss: 0.5298\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.5307\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0044 - val_loss: 0.5288\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0043 - val_loss: 0.5314\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0043 - val_loss: 0.5314\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0042 - val_loss: 0.5306\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0042 - val_loss: 0.5308\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0041 - val_loss: 0.5328\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0041 - val_loss: 0.5327\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0040 - val_loss: 0.5333\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0040 - val_loss: 0.5330\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0039 - val_loss: 0.5339\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0039 - val_loss: 0.5355\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0039 - val_loss: 0.5354\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0038 - val_loss: 0.5346\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0038 - val_loss: 0.5362\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0037 - val_loss: 0.5370\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0037 - val_loss: 0.5383\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0037 - val_loss: 0.5378\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0036 - val_loss: 0.5389\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0036 - val_loss: 0.5387\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.5391\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.5405\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0035 - val_loss: 0.5405\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0034 - val_loss: 0.5412\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0034 - val_loss: 0.5412\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0034 - val_loss: 0.5410\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0033 - val_loss: 0.5416\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.5423\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0033 - val_loss: 0.5430\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.5448\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.5449\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.5458\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.5457\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.5462\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.5469\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0031 - val_loss: 0.5466\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.5475\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0030 - val_loss: 0.5469\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0030 - val_loss: 0.5474\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0029 - val_loss: 0.5495\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.5498\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.5488\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0029 - val_loss: 0.5494\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.0028 - val_loss: 0.5507\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0028 - val_loss: 0.5521\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.5527\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.5523\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.5535\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.5537\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0027 - val_loss: 0.5543\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.5545\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.5553\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0026 - val_loss: 0.5550\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 2.5878 - val_loss: 2.2502\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.1274 - val_loss: 1.8931\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.7810 - val_loss: 1.5789\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.4511 - val_loss: 1.3792\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.2532 - val_loss: 1.2484\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 1.1230 - val_loss: 1.1649\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.0114 - val_loss: 1.0873\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.9167 - val_loss: 1.0230\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.8291 - val_loss: 0.9540\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.7595 - val_loss: 0.9004\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6976 - val_loss: 0.8563\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.6399 - val_loss: 0.8181\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5893 - val_loss: 0.7797\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5458 - val_loss: 0.7485\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.5062 - val_loss: 0.7210\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4655 - val_loss: 0.6885\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.4337 - val_loss: 0.6660\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.4017 - val_loss: 0.6362\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.3668 - val_loss: 0.6131\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.3370 - val_loss: 0.5891\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 208us/step - loss: 0.3119 - val_loss: 0.5769\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2884 - val_loss: 0.5601\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 0.2679 - val_loss: 0.5449\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.2495 - val_loss: 0.5318\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.2330 - val_loss: 0.5204\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2175 - val_loss: 0.5052\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.2026 - val_loss: 0.4870\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1880 - val_loss: 0.4836\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1746 - val_loss: 0.4709\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1637 - val_loss: 0.4522\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1538 - val_loss: 0.4479\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1453 - val_loss: 0.4446\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1376 - val_loss: 0.4304\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1307 - val_loss: 0.4263\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1244 - val_loss: 0.4254\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1181 - val_loss: 0.4139\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.1125 - val_loss: 0.4101\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.1070 - val_loss: 0.4096\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1017 - val_loss: 0.4040\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0971 - val_loss: 0.4008\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0928 - val_loss: 0.4010\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0885 - val_loss: 0.3939\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0850 - val_loss: 0.3910\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0816 - val_loss: 0.3897\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0785 - val_loss: 0.3877\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0754 - val_loss: 0.3878\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0728 - val_loss: 0.3833\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0700 - val_loss: 0.3831\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0676 - val_loss: 0.3818\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0654 - val_loss: 0.3770\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 0.0630 - val_loss: 0.3779\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0610 - val_loss: 0.3777\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0591 - val_loss: 0.3745\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0571 - val_loss: 0.3768\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0553 - val_loss: 0.3722\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0536 - val_loss: 0.3722\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0520 - val_loss: 0.3745\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0504 - val_loss: 0.3698\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0490 - val_loss: 0.3695\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0474 - val_loss: 0.3725\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0460 - val_loss: 0.3699\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0446 - val_loss: 0.3706\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0433 - val_loss: 0.3731\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0419 - val_loss: 0.3724\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0407 - val_loss: 0.3712\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0394 - val_loss: 0.3755\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0382 - val_loss: 0.3763\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0368 - val_loss: 0.3891\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0358 - val_loss: 0.3785\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0346 - val_loss: 0.3745\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0338 - val_loss: 0.3796\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0328 - val_loss: 0.3767\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0320 - val_loss: 0.3781\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0312 - val_loss: 0.3797\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0305 - val_loss: 0.3802\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0298 - val_loss: 0.3772\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0291 - val_loss: 0.3777\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0285 - val_loss: 0.3818\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0278 - val_loss: 0.3794\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0272 - val_loss: 0.3785\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0264 - val_loss: 0.3804\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0257 - val_loss: 0.3855\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0250 - val_loss: 0.3858\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0244 - val_loss: 0.3846\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0238 - val_loss: 0.3902\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0231 - val_loss: 0.3917\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0224 - val_loss: 0.3943\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0217 - val_loss: 0.3935\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0211 - val_loss: 0.3910\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0206 - val_loss: 0.3904\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0201 - val_loss: 0.3910\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0197 - val_loss: 0.3927\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0193 - val_loss: 0.3919\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0189 - val_loss: 0.3922\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0185 - val_loss: 0.3937\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0182 - val_loss: 0.3931\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0178 - val_loss: 0.3921\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0175 - val_loss: 0.3935\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0172 - val_loss: 0.3929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0169 - val_loss: 0.3913\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0166 - val_loss: 0.3920\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0163 - val_loss: 0.3937\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0160 - val_loss: 0.3941\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0158 - val_loss: 0.3925\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0155 - val_loss: 0.3927\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0152 - val_loss: 0.3941\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0150 - val_loss: 0.3940\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0148 - val_loss: 0.3938\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.3956\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0143 - val_loss: 0.3943\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0141 - val_loss: 0.3923\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0138 - val_loss: 0.3945\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0136 - val_loss: 0.3957\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0134 - val_loss: 0.3957\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0132 - val_loss: 0.3947\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0130 - val_loss: 0.3958\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0128 - val_loss: 0.3975\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0127 - val_loss: 0.3974\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0125 - val_loss: 0.3970\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.012 - 0s 156us/step - loss: 0.0123 - val_loss: 0.3962\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0121 - val_loss: 0.3966\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0120 - val_loss: 0.3989\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0118 - val_loss: 0.3982\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0117 - val_loss: 0.3969\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 188us/step - loss: 0.0115 - val_loss: 0.3974\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0113 - val_loss: 0.3988\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0112 - val_loss: 0.3993\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0111 - val_loss: 0.3994\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0109 - val_loss: 0.4000\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0108 - val_loss: 0.4005\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0106 - val_loss: 0.4008\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0105 - val_loss: 0.4000\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.0104 - val_loss: 0.4016\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 246us/step - loss: 0.0102 - val_loss: 0.4011\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0101 - val_loss: 0.4009\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0100 - val_loss: 0.4017\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0099 - val_loss: 0.4022\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0098 - val_loss: 0.4025\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0096 - val_loss: 0.4024\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0095 - val_loss: 0.4030\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0094 - val_loss: 0.4036\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0093 - val_loss: 0.4031\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0092 - val_loss: 0.4038\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0091 - val_loss: 0.4041\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0090 - val_loss: 0.4051\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0089 - val_loss: 0.4043\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0088 - val_loss: 0.4044\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0087 - val_loss: 0.4038\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0086 - val_loss: 0.4045\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0085 - val_loss: 0.4048\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0084 - val_loss: 0.4040\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0083 - val_loss: 0.4043\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0082 - val_loss: 0.4043\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0081 - val_loss: 0.4044\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0080 - val_loss: 0.4064\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0079 - val_loss: 0.4070\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0078 - val_loss: 0.4061\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0077 - val_loss: 0.4056\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0076 - val_loss: 0.4057\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0076 - val_loss: 0.4063\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0075 - val_loss: 0.4061\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0074 - val_loss: 0.4072\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0073 - val_loss: 0.4074\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0072 - val_loss: 0.4078\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0072 - val_loss: 0.4082\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0071 - val_loss: 0.4074\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0070 - val_loss: 0.4072\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0069 - val_loss: 0.4083\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0069 - val_loss: 0.4091\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0068 - val_loss: 0.4100\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0067 - val_loss: 0.4100\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0067 - val_loss: 0.4100\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0066 - val_loss: 0.4093\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0065 - val_loss: 0.4100\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0064 - val_loss: 0.4114\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0064 - val_loss: 0.4115\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.4122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0062 - val_loss: 0.4123\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.4126\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.4130\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.4129\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.4129\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.4143\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.4134\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0058 - val_loss: 0.4131\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.0058 - val_loss: 0.4135\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0057 - val_loss: 0.4139\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0056 - val_loss: 0.4144\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0056 - val_loss: 0.4156\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0055 - val_loss: 0.4163\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.4161\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.4162\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0054 - val_loss: 0.4164\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0053 - val_loss: 0.4171\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0053 - val_loss: 0.4177\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0052 - val_loss: 0.4175\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0052 - val_loss: 0.4181\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0051 - val_loss: 0.4186\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.4187\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 0.0050 - val_loss: 0.4184\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 10.4383 - val_loss: 9.8354\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 8.9946 - val_loss: 8.3451\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 7.2270 - val_loss: 7.0045\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 6.1367 - val_loss: 6.3061\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 5.4311 - val_loss: 5.4530\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.6708 - val_loss: 4.6690\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 4.0848 - val_loss: 4.1734\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.6031 - val_loss: 3.8859\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.3486 - val_loss: 3.7546\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 3.2124 - val_loss: 3.6906\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.1268 - val_loss: 3.6411\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0619 - val_loss: 3.6185\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 3.0158 - val_loss: 3.6024\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.9798 - val_loss: 3.6074\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.9420 - val_loss: 3.5953\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 2.9221 - val_loss: 3.5914\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 2.9034 - val_loss: 3.5955\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8842 - val_loss: 3.5849\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8709 - val_loss: 3.5864\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8587 - val_loss: 3.5741\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8450 - val_loss: 3.5755\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8385 - val_loss: 3.5768\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8315 - val_loss: 3.5757\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8247 - val_loss: 3.5792\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8202 - val_loss: 3.5780\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8171 - val_loss: 3.5768\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8132 - val_loss: 3.5755\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8110 - val_loss: 3.5763\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8091 - val_loss: 3.5773\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8078 - val_loss: 3.5783\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 2.8064 - val_loss: 3.5778\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8054 - val_loss: 3.5758\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8044 - val_loss: 3.5755\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8037 - val_loss: 3.5748\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.8031 - val_loss: 3.5769\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.8024 - val_loss: 3.5763\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8018 - val_loss: 3.5754\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.8013 - val_loss: 3.5774\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 2.8009 - val_loss: 3.5766\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 2.8004 - val_loss: 3.5774\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.8001 - val_loss: 3.5778\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.7998 - val_loss: 3.5785\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 2.7994 - val_loss: 3.5782\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7991 - val_loss: 3.5781\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 2.7989 - val_loss: 3.5784\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.7986 - val_loss: 3.5793\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.7984 - val_loss: 3.5801\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7982 - val_loss: 3.5804\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7980 - val_loss: 3.5804\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.7978 - val_loss: 3.5817\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 2.7976 - val_loss: 3.5820\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7975 - val_loss: 3.5819\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7973 - val_loss: 3.5830\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7972 - val_loss: 3.5835\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7970 - val_loss: 3.5849\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7969 - val_loss: 3.5841\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7968 - val_loss: 3.5844\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7967 - val_loss: 3.5851\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7966 - val_loss: 3.5861\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7965 - val_loss: 3.5871\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 2.7964 - val_loss: 3.5884\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7963 - val_loss: 3.5885\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7962 - val_loss: 3.5894\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7961 - val_loss: 3.5900\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7961 - val_loss: 3.5906\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7960 - val_loss: 3.5908\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7959 - val_loss: 3.5916\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7958 - val_loss: 3.5920\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7958 - val_loss: 3.5921\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7957 - val_loss: 3.5929\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 2.7957 - val_loss: 3.5934\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 2.7956 - val_loss: 3.5941\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 2.7956 - val_loss: 3.5948\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 2.7955 - val_loss: 3.5954\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 2.7955 - val_loss: 3.5958\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7954 - val_loss: 3.5963\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.7954 - val_loss: 3.5972\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.7953 - val_loss: 3.5976\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 2.7953 - val_loss: 3.5986\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.7953 - val_loss: 3.5988\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.7952 - val_loss: 3.5992\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.7952 - val_loss: 3.6000\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 2.7951 - val_loss: 3.6005\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7951 - val_loss: 3.6012\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 208us/step - loss: 2.7951 - val_loss: 3.6016\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7951 - val_loss: 3.6028\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 2.7950 - val_loss: 3.6030\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.7950 - val_loss: 3.6039\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.7950 - val_loss: 3.6046\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.7949 - val_loss: 3.6047\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7949 - val_loss: 3.6051\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7949 - val_loss: 3.6057\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 2.7949 - val_loss: 3.6060\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.7948 - val_loss: 3.6062\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7948 - val_loss: 3.6067\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 2.7948 - val_loss: 3.6071\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.7948 - val_loss: 3.6075\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 2.7948 - val_loss: 3.6084\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.7947 - val_loss: 3.6089\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7947 - val_loss: 3.6095\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.7947 - val_loss: 3.6100\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 2.7947 - val_loss: 3.6109\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.7947 - val_loss: 3.6114\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 2.7946 - val_loss: 3.6119\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.7946 - val_loss: 3.6123\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.7946 - val_loss: 3.6127\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.7946 - val_loss: 3.6134\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.7946 - val_loss: 3.6139\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.7946 - val_loss: 3.6143\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7946 - val_loss: 3.6146\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7945 - val_loss: 3.6150\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7945 - val_loss: 3.6151\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7945 - val_loss: 3.6156\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.7945 - val_loss: 3.6160\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.7945 - val_loss: 3.6166\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.7945 - val_loss: 3.6172\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.7945 - val_loss: 3.6175\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7944 - val_loss: 3.6181\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7944 - val_loss: 3.6189\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.7944 - val_loss: 3.6193\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7944 - val_loss: 3.6196\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.7944 - val_loss: 3.6199\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.7944 - val_loss: 3.6204\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 2.7944 - val_loss: 3.6212\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7944 - val_loss: 3.6216\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.7944 - val_loss: 3.6222\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.7944 - val_loss: 3.6227\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7943 - val_loss: 3.6230\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7943 - val_loss: 3.6232\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7943 - val_loss: 3.6240\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7943 - val_loss: 3.6245\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.7943 - val_loss: 3.6250\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7943 - val_loss: 3.6253\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 197us/step - loss: 2.7943 - val_loss: 3.6258\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7943 - val_loss: 3.6260\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7943 - val_loss: 3.6264\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 2.7943 - val_loss: 3.6265\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.7943 - val_loss: 3.6270\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.7943 - val_loss: 3.6279\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.7943 - val_loss: 3.6280\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.7942 - val_loss: 3.6283\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.7942 - val_loss: 3.6289\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 2.7942 - val_loss: 3.6296\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 2.7942 - val_loss: 3.6301\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.7942 - val_loss: 3.6303\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7942 - val_loss: 3.6307\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 2.7942 - val_loss: 3.6312\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.7942 - val_loss: 3.6316\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 2.7942 - val_loss: 3.6322\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 2.7942 - val_loss: 3.6326\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7942 - val_loss: 3.6329\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.7942 - val_loss: 3.6332\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 2.7942 - val_loss: 3.6336\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7942 - val_loss: 3.6339\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 2.7942 - val_loss: 3.6342\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 2.7942 - val_loss: 3.6347\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.7942 - val_loss: 3.6353\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.7941 - val_loss: 3.6360\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.7941 - val_loss: 3.6366\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7941 - val_loss: 3.6367\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7941 - val_loss: 3.6370\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7941 - val_loss: 3.6373\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7941 - val_loss: 3.6378\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7941 - val_loss: 3.6381\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.7941 - val_loss: 3.6385\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7941 - val_loss: 3.6390\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.7941 - val_loss: 3.6394\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7941 - val_loss: 3.6400\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7941 - val_loss: 3.6402\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7941 - val_loss: 3.6405\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.7941 - val_loss: 3.6410\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7941 - val_loss: 3.6413\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7941 - val_loss: 3.6417\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7941 - val_loss: 3.6419\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7941 - val_loss: 3.6423\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7941 - val_loss: 3.6427\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7941 - val_loss: 3.6433\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7941 - val_loss: 3.6437\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7941 - val_loss: 3.6441\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7941 - val_loss: 3.6446\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7941 - val_loss: 3.6449\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.518 - 0s 190us/step - loss: 2.7941 - val_loss: 3.6453\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 2.7941 - val_loss: 3.6455\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7941 - val_loss: 3.6456\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.7940 - val_loss: 3.6459\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 2.7940 - val_loss: 3.6463\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 2.7940 - val_loss: 3.6469\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.7940 - val_loss: 3.6473\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7940 - val_loss: 3.6475\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7940 - val_loss: 3.6478\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7940 - val_loss: 3.6482\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.7940 - val_loss: 3.6486\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.7940 - val_loss: 3.6490\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 2.7940 - val_loss: 3.6491\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7940 - val_loss: 3.6496\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.7940 - val_loss: 3.6499\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7940 - val_loss: 3.6506\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 2.7940 - val_loss: 3.6508\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7940 - val_loss: 3.6512\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.7940 - val_loss: 3.6518\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 5.9211 - val_loss: 4.9288\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 4.0656 - val_loss: 3.3132\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.4018 - val_loss: 1.8281\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 1.3728 - val_loss: 1.2805\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.9573 - val_loss: 1.0044\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.7386 - val_loss: 0.8721\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.6013 - val_loss: 0.7677\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.5063 - val_loss: 0.6968\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.4213 - val_loss: 0.6267\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.457 - 0s 294us/step - loss: 0.3641 - val_loss: 0.5880\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.3149 - val_loss: 0.5510\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.2591 - val_loss: 0.5193\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.2275 - val_loss: 0.5048\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.1909 - val_loss: 0.4764\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.1657 - val_loss: 0.4619\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.1418 - val_loss: 0.4671\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.1174 - val_loss: 0.4385\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.1014 - val_loss: 0.4347\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0860 - val_loss: 0.4339\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0756 - val_loss: 0.4371\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0650 - val_loss: 0.4236\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0569 - val_loss: 0.4241\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0514 - val_loss: 0.4275\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0446 - val_loss: 0.4265\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0398 - val_loss: 0.4192\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0347 - val_loss: 0.4244\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0312 - val_loss: 0.4253\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0281 - val_loss: 0.4286\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0257 - val_loss: 0.4245\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0226 - val_loss: 0.4295\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0209 - val_loss: 0.4305\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0191 - val_loss: 0.4273\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0171 - val_loss: 0.4351\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0155 - val_loss: 0.4381\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0150 - val_loss: 0.4420\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0133 - val_loss: 0.4353\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0122 - val_loss: 0.4469\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0115 - val_loss: 0.4421\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0104 - val_loss: 0.4467\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0097 - val_loss: 0.4476\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0088 - val_loss: 0.4506\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0082 - val_loss: 0.4519\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0076 - val_loss: 0.4571\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0070 - val_loss: 0.4524\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0067 - val_loss: 0.4529\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0063 - val_loss: 0.4606\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0058 - val_loss: 0.4583\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0054 - val_loss: 0.4625\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0051 - val_loss: 0.4643\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0048 - val_loss: 0.4665\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0046 - val_loss: 0.4697\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0043 - val_loss: 0.4707\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0041 - val_loss: 0.4703\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0039 - val_loss: 0.4734\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0037 - val_loss: 0.4777\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0035 - val_loss: 0.4784\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0034 - val_loss: 0.4776\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0032 - val_loss: 0.4814\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0031 - val_loss: 0.4830\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0029 - val_loss: 0.4852\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0028 - val_loss: 0.4854\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0027 - val_loss: 0.4876\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0026 - val_loss: 0.4890\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0025 - val_loss: 0.4943\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0024 - val_loss: 0.4946\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0023 - val_loss: 0.4929\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0022 - val_loss: 0.4941\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0021 - val_loss: 0.4974\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0021 - val_loss: 0.4996\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0020 - val_loss: 0.4987\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.4986\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0018 - val_loss: 0.4998\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0018 - val_loss: 0.5019\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0017 - val_loss: 0.5032\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0017 - val_loss: 0.5050\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0016 - val_loss: 0.5075\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0016 - val_loss: 0.5091\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.0015 - val_loss: 0.5091\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0015 - val_loss: 0.5118\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0014 - val_loss: 0.5140\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0014 - val_loss: 0.5135\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0014 - val_loss: 0.5135\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0013 - val_loss: 0.5133\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0013 - val_loss: 0.5154\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.5183\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0012 - val_loss: 0.5191\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0012 - val_loss: 0.5207\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.5207\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0011 - val_loss: 0.5218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.5228\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0011 - val_loss: 0.5251\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0010 - val_loss: 0.5246\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0010 - val_loss: 0.5252\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 9.8386e-04 - val_loss: 0.5253\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 9.6278e-04 - val_loss: 0.5281\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 9.3873e-04 - val_loss: 0.5289\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 9.1839e-04 - val_loss: 0.5321\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 8.9594e-04 - val_loss: 0.5320\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 8.7390e-04 - val_loss: 0.5324\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 8.5452e-04 - val_loss: 0.5332\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 8.3663e-04 - val_loss: 0.5343\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 8.1842e-04 - val_loss: 0.5358\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 8.0121e-04 - val_loss: 0.5366\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 7.8662e-04 - val_loss: 0.5377\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 7.6523e-04 - val_loss: 0.5377\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 7.4917e-04 - val_loss: 0.5388\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 7.3510e-04 - val_loss: 0.5399\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 7.1746e-04 - val_loss: 0.5421\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 7.0350e-04 - val_loss: 0.5439\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 6.8963e-04 - val_loss: 0.5437\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 6.7556e-04 - val_loss: 0.5433\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 6.6296e-04 - val_loss: 0.5451\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 6.4815e-04 - val_loss: 0.5449\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 6.3507e-04 - val_loss: 0.5468\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 6.2369e-04 - val_loss: 0.5462\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 6.1263e-04 - val_loss: 0.5473\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 5.9944e-04 - val_loss: 0.5480\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 5.8826e-04 - val_loss: 0.5490\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 5.7717e-04 - val_loss: 0.5497\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 5.6774e-04 - val_loss: 0.5487\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 5.5667e-04 - val_loss: 0.5515\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 5.4461e-04 - val_loss: 0.5521\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 5.3509e-04 - val_loss: 0.5529\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 5.2694e-04 - val_loss: 0.5545\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 5.1614e-04 - val_loss: 0.5560\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 5.0716e-04 - val_loss: 0.5576\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.9762e-04 - val_loss: 0.5585\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 4.9024e-04 - val_loss: 0.5588\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 4.8034e-04 - val_loss: 0.5608\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 4.7248e-04 - val_loss: 0.5614\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.6631e-04 - val_loss: 0.5607\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.5749e-04 - val_loss: 0.5613\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 4.4985e-04 - val_loss: 0.5606\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 4.4221e-04 - val_loss: 0.5623\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.3537e-04 - val_loss: 0.5634\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.2691e-04 - val_loss: 0.5643\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.2058e-04 - val_loss: 0.5649\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 4.1369e-04 - val_loss: 0.5656\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 4.0788e-04 - val_loss: 0.5651\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 4.0171e-04 - val_loss: 0.5673\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 3.9405e-04 - val_loss: 0.5680\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.8825e-04 - val_loss: 0.5688\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.8310e-04 - val_loss: 0.5692\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.7658e-04 - val_loss: 0.5694\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 3.7079e-04 - val_loss: 0.5702\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 3.6594e-04 - val_loss: 0.5714\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 3.6037e-04 - val_loss: 0.5719\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 3.5429e-04 - val_loss: 0.5729\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 3.4923e-04 - val_loss: 0.5738\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 3.4381e-04 - val_loss: 0.5743\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 3.3958e-04 - val_loss: 0.5751\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 3.3414e-04 - val_loss: 0.5759\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 3.3017e-04 - val_loss: 0.5749\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.2497e-04 - val_loss: 0.5753\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.2020e-04 - val_loss: 0.5764\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 3.1532e-04 - val_loss: 0.5769\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 3.1107e-04 - val_loss: 0.5782\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 3.0665e-04 - val_loss: 0.5796\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.0235e-04 - val_loss: 0.5801\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.9818e-04 - val_loss: 0.5807\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.9412e-04 - val_loss: 0.5818\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.8970e-04 - val_loss: 0.5825\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.8591e-04 - val_loss: 0.5828\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.8205e-04 - val_loss: 0.5840\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.7853e-04 - val_loss: 0.5838\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.7463e-04 - val_loss: 0.5854\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.7084e-04 - val_loss: 0.5855\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.6706e-04 - val_loss: 0.5851\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.6388e-04 - val_loss: 0.5853\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.6033e-04 - val_loss: 0.5855\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 2.5781e-04 - val_loss: 0.5882\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.5361e-04 - val_loss: 0.5880\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.5075e-04 - val_loss: 0.5885\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.4731e-04 - val_loss: 0.5898\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.4423e-04 - val_loss: 0.5905\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.4110e-04 - val_loss: 0.5903\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.3775e-04 - val_loss: 0.5912\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.3487e-04 - val_loss: 0.5919\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.3212e-04 - val_loss: 0.5914\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.2940e-04 - val_loss: 0.5923\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.2633e-04 - val_loss: 0.5935\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.2336e-04 - val_loss: 0.5946\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.2074e-04 - val_loss: 0.5944\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 2.1830e-04 - val_loss: 0.5967\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.1597e-04 - val_loss: 0.5968\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 2.1239e-04 - val_loss: 0.5975\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 2.1026e-04 - val_loss: 0.5974\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.0750e-04 - val_loss: 0.5979\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.0511e-04 - val_loss: 0.5982\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.0271e-04 - val_loss: 0.5987\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 2.0017e-04 - val_loss: 0.5992\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.9766e-04 - val_loss: 0.6001\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.9594e-04 - val_loss: 0.6007\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.9339e-04 - val_loss: 0.6001\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.9099e-04 - val_loss: 0.6016\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.8868e-04 - val_loss: 0.6019\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.8664e-04 - val_loss: 0.6028\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.8433e-04 - val_loss: 0.6034\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.8234e-04 - val_loss: 0.6038\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 1.8005e-04 - val_loss: 0.6050\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 12.1643 - val_loss: 11.8030\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 11.4172 - val_loss: 10.5700\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 9.3903 - val_loss: 7.8809\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 7.0879 - val_loss: 6.7125\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 6.0053 - val_loss: 5.5041\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 4.8076 - val_loss: 4.4373\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.7882 - val_loss: 3.4770\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.8095 - val_loss: 2.6104\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 2.1621 - val_loss: 2.2150\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.7126 - val_loss: 1.8713\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 1.3940 - val_loss: 1.6472\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.1516 - val_loss: 1.4757\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.9497 - val_loss: 1.3230\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.8116 - val_loss: 1.2284\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.6922 - val_loss: 1.1428\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.6074 - val_loss: 1.0672\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.5155 - val_loss: 1.0249\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.4508 - val_loss: 0.9878\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.3780 - val_loss: 0.9443\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.3275 - val_loss: 0.9202\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.2960 - val_loss: 0.9087\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.2519 - val_loss: 0.8904\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.2179 - val_loss: 0.8710\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.1861 - val_loss: 0.8579\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.1649 - val_loss: 0.8535\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.1468 - val_loss: 0.8357\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.1307 - val_loss: 0.8294\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.1133 - val_loss: 0.8282\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.1036 - val_loss: 0.8279\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0921 - val_loss: 0.8095\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0812 - val_loss: 0.8182\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0725 - val_loss: 0.8087\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0652 - val_loss: 0.8088\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0591 - val_loss: 0.8122\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0541 - val_loss: 0.7967\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0489 - val_loss: 0.7976\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0440 - val_loss: 0.8096\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0411 - val_loss: 0.8198\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0369 - val_loss: 0.8043\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0336 - val_loss: 0.8007\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0306 - val_loss: 0.7981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0285 - val_loss: 0.7931\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0262 - val_loss: 0.8064\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0244 - val_loss: 0.8057\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0228 - val_loss: 0.8011\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0212 - val_loss: 0.8062\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0199 - val_loss: 0.8071\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0186 - val_loss: 0.8101\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0176 - val_loss: 0.8132\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0166 - val_loss: 0.8116\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0155 - val_loss: 0.8099\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0147 - val_loss: 0.8132\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0139 - val_loss: 0.8169\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0132 - val_loss: 0.8222\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0124 - val_loss: 0.8223\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0118 - val_loss: 0.8206\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0112 - val_loss: 0.8251\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0106 - val_loss: 0.8276\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0100 - val_loss: 0.8296\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0096 - val_loss: 0.8313\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0092 - val_loss: 0.8343\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0087 - val_loss: 0.8340\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0083 - val_loss: 0.8385\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0080 - val_loss: 0.8434\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0075 - val_loss: 0.8417\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.009 - 0s 187us/step - loss: 0.0072 - val_loss: 0.8467\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0069 - val_loss: 0.8440\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0067 - val_loss: 0.8464\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0064 - val_loss: 0.8513\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0061 - val_loss: 0.8547\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0058 - val_loss: 0.8583\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0056 - val_loss: 0.8623\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0054 - val_loss: 0.8622\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0052 - val_loss: 0.8635\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0050 - val_loss: 0.8651\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0048 - val_loss: 0.8678\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0047 - val_loss: 0.8692\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0045 - val_loss: 0.8676\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0044 - val_loss: 0.8691\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0042 - val_loss: 0.8727\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0041 - val_loss: 0.8764\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0040 - val_loss: 0.8790\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0038 - val_loss: 0.8811\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0037 - val_loss: 0.8816\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0036 - val_loss: 0.8804\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0035 - val_loss: 0.8851\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0034 - val_loss: 0.8865\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0033 - val_loss: 0.8873\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0032 - val_loss: 0.8880\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0031 - val_loss: 0.8929\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0030 - val_loss: 0.8920\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0029 - val_loss: 0.8942\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0028 - val_loss: 0.8973\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0028 - val_loss: 0.8991\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0027 - val_loss: 0.8972\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0026 - val_loss: 0.8976\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0026 - val_loss: 0.8988\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0025 - val_loss: 0.9045\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0024 - val_loss: 0.9084\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0024 - val_loss: 0.9097\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0023 - val_loss: 0.9114\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0022 - val_loss: 0.9123\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0022 - val_loss: 0.9140\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0021 - val_loss: 0.9142\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0021 - val_loss: 0.9149\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0020 - val_loss: 0.9162\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0020 - val_loss: 0.9175\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0019 - val_loss: 0.9197\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0019 - val_loss: 0.9217\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0018 - val_loss: 0.9216\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.9225\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0017 - val_loss: 0.9252\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0017 - val_loss: 0.9277\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.9292\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0016 - val_loss: 0.9305\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0016 - val_loss: 0.9330\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0016 - val_loss: 0.9359\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0015 - val_loss: 0.9367\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0015 - val_loss: 0.9356\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0014 - val_loss: 0.9382\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0014 - val_loss: 0.9397\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0014 - val_loss: 0.9424\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0014 - val_loss: 0.9434\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0013 - val_loss: 0.9448\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0013 - val_loss: 0.9454\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0013 - val_loss: 0.9492\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0012 - val_loss: 0.9509\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0012 - val_loss: 0.9525\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0012 - val_loss: 0.9536\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0012 - val_loss: 0.9548\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0012 - val_loss: 0.9564\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0011 - val_loss: 0.9584\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0011 - val_loss: 0.9599\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0011 - val_loss: 0.9590\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0011 - val_loss: 0.9614\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0011 - val_loss: 0.9641\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0010 - val_loss: 0.9668\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0010 - val_loss: 0.9679\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 9.9642e-04 - val_loss: 0.9691\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 9.7837e-04 - val_loss: 0.9695\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 9.6363e-04 - val_loss: 0.9701\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 9.4847e-04 - val_loss: 0.9721\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 9.3514e-04 - val_loss: 0.9730\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 9.1592e-04 - val_loss: 0.9747\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 9.0361e-04 - val_loss: 0.9763\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 8.8631e-04 - val_loss: 0.9784\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 8.7195e-04 - val_loss: 0.9789\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 8.5599e-04 - val_loss: 0.9804\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 8.4279e-04 - val_loss: 0.9819\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 8.3012e-04 - val_loss: 0.9842\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 8.1599e-04 - val_loss: 0.9862\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 8.0333e-04 - val_loss: 0.9872\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 7.8923e-04 - val_loss: 0.9885\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 7.7694e-04 - val_loss: 0.9878\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 7.6446e-04 - val_loss: 0.9885\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 7.5252e-04 - val_loss: 0.9907\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 7.4063e-04 - val_loss: 0.9923\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 7.2908e-04 - val_loss: 0.9934\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 7.1810e-04 - val_loss: 0.9941\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 7.0753e-04 - val_loss: 0.9949\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 6.9690e-04 - val_loss: 0.9962\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 6.8591e-04 - val_loss: 0.9984\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 6.7811e-04 - val_loss: 0.9996\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 6.6688e-04 - val_loss: 1.0005\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 6.5936e-04 - val_loss: 1.0013\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 6.4827e-04 - val_loss: 1.0021\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 6.3967e-04 - val_loss: 1.0039\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 6.3061e-04 - val_loss: 1.0060\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 6.2040e-04 - val_loss: 1.0073\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 6.1151e-04 - val_loss: 1.0076\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 6.0262e-04 - val_loss: 1.0091\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 5.9448e-04 - val_loss: 1.0111\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 5.8597e-04 - val_loss: 1.0116\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 5.7869e-04 - val_loss: 1.0118\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 5.7061e-04 - val_loss: 1.0126\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 5.6323e-04 - val_loss: 1.0141\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 5.5464e-04 - val_loss: 1.0143\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 5.4843e-04 - val_loss: 1.0161\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 5.4055e-04 - val_loss: 1.0171\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 5.3330e-04 - val_loss: 1.0180\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 5.2679e-04 - val_loss: 1.0202\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 5.1937e-04 - val_loss: 1.0205\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 5.1181e-04 - val_loss: 1.0211\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 5.0483e-04 - val_loss: 1.0228\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.9819e-04 - val_loss: 1.0244\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 4.9053e-04 - val_loss: 1.0262\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 4.8489e-04 - val_loss: 1.0274\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 4.7882e-04 - val_loss: 1.0279\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 4.7129e-04 - val_loss: 1.0276\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 4.6503e-04 - val_loss: 1.0290\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.5858e-04 - val_loss: 1.0312\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.5286e-04 - val_loss: 1.0325\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.4715e-04 - val_loss: 1.0333\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 4.4114e-04 - val_loss: 1.0347\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 4.3674e-04 - val_loss: 1.0360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.3107e-04 - val_loss: 1.0370\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 4.2470e-04 - val_loss: 1.0383\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 4.1917e-04 - val_loss: 1.0401\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 4.1413e-04 - val_loss: 1.0412\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.0947e-04 - val_loss: 1.0418\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 4.0031 - val_loss: 3.5813\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.1228 - val_loss: 2.7828\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.3581 - val_loss: 2.1862\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.8282 - val_loss: 1.7443\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 1.4802 - val_loss: 1.5233\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 1.2619 - val_loss: 1.3549\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.0843 - val_loss: 1.2124\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.9374 - val_loss: 1.0961\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.8174 - val_loss: 0.9987\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.7215 - val_loss: 0.9185\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.6286 - val_loss: 0.8505\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.5535 - val_loss: 0.7888\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.4792 - val_loss: 0.7293\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.4114 - val_loss: 0.6904\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.3538 - val_loss: 0.6390\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.3039 - val_loss: 0.5986\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.2597 - val_loss: 0.5761\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.2224 - val_loss: 0.5466\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.1877 - val_loss: 0.5225\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.1606 - val_loss: 0.5066\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.1391 - val_loss: 0.5044\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.1190 - val_loss: 0.4918\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0992 - val_loss: 0.4760\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0856 - val_loss: 0.4779\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0746 - val_loss: 0.4735\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0652 - val_loss: 0.4725\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0568 - val_loss: 0.4696\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0508 - val_loss: 0.4633\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0451 - val_loss: 0.4675\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0402 - val_loss: 0.4661\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0361 - val_loss: 0.4774\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0325 - val_loss: 0.4702\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0292 - val_loss: 0.4639\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0269 - val_loss: 0.4814\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0243 - val_loss: 0.4698\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0220 - val_loss: 0.4737\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0203 - val_loss: 0.4785\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0185 - val_loss: 0.4785\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0171 - val_loss: 0.4820\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0159 - val_loss: 0.4822\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0147 - val_loss: 0.4863\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0138 - val_loss: 0.4871\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0128 - val_loss: 0.4914\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0120 - val_loss: 0.4945\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.0113 - val_loss: 0.4909\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0105 - val_loss: 0.4985\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0098 - val_loss: 0.4995\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0093 - val_loss: 0.4987\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0087 - val_loss: 0.5040\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0082 - val_loss: 0.5045\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0077 - val_loss: 0.5070\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0073 - val_loss: 0.5072\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0070 - val_loss: 0.5072\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0066 - val_loss: 0.5089\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0063 - val_loss: 0.5099\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.005 - 0s 213us/step - loss: 0.0060 - val_loss: 0.5102\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0057 - val_loss: 0.5168\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0054 - val_loss: 0.5145\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0052 - val_loss: 0.5135\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0050 - val_loss: 0.5172\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0047 - val_loss: 0.5154\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0045 - val_loss: 0.5166\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0044 - val_loss: 0.5206\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0042 - val_loss: 0.5206\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0040 - val_loss: 0.5222\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0039 - val_loss: 0.5243\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0037 - val_loss: 0.5251\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0036 - val_loss: 0.5268\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0035 - val_loss: 0.5298\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0033 - val_loss: 0.5308\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0032 - val_loss: 0.5302\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0031 - val_loss: 0.5313\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0030 - val_loss: 0.5334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0029 - val_loss: 0.5332\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0028 - val_loss: 0.5360\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0027 - val_loss: 0.5382\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0026 - val_loss: 0.5365\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0025 - val_loss: 0.5364\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0025 - val_loss: 0.5381\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0024 - val_loss: 0.5390\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0023 - val_loss: 0.5408\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0022 - val_loss: 0.5419\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0022 - val_loss: 0.5432\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0021 - val_loss: 0.5431\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0020 - val_loss: 0.5476\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0020 - val_loss: 0.5480\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0019 - val_loss: 0.5471\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0019 - val_loss: 0.5481\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0018 - val_loss: 0.5480\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0018 - val_loss: 0.5517\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0017 - val_loss: 0.5531\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0017 - val_loss: 0.5544\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.5521\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0016 - val_loss: 0.5541\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0016 - val_loss: 0.5553\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0015 - val_loss: 0.5557\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.5575\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0014 - val_loss: 0.5586\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0014 - val_loss: 0.5590\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0014 - val_loss: 0.5606\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0013 - val_loss: 0.5610\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0013 - val_loss: 0.5609\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0013 - val_loss: 0.5620\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0013 - val_loss: 0.5626\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0012 - val_loss: 0.5627\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0012 - val_loss: 0.5639\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0012 - val_loss: 0.5657\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0011 - val_loss: 0.5661\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0011 - val_loss: 0.5658\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0011 - val_loss: 0.5663\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0011 - val_loss: 0.5673\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0010 - val_loss: 0.5680\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0010 - val_loss: 0.5684\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0010 - val_loss: 0.5705\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 9.8687e-04 - val_loss: 0.5703\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 9.6633e-04 - val_loss: 0.5706\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 9.4637e-04 - val_loss: 0.5713\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 9.2746e-04 - val_loss: 0.5723\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 9.0923e-04 - val_loss: 0.5738\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 8.9106e-04 - val_loss: 0.5751\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 8.7285e-04 - val_loss: 0.5759\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 8.5706e-04 - val_loss: 0.5760\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 8.3897e-04 - val_loss: 0.5769\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 8.2224e-04 - val_loss: 0.5781\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 8.0833e-04 - val_loss: 0.5792\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 7.9357e-04 - val_loss: 0.5784\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 7.7809e-04 - val_loss: 0.5801\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 7.6312e-04 - val_loss: 0.5806\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 7.4854e-04 - val_loss: 0.5821\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 7.3470e-04 - val_loss: 0.5813\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 7.2063e-04 - val_loss: 0.5828\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 7.0899e-04 - val_loss: 0.5834\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 6.9602e-04 - val_loss: 0.5833\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 6.8511e-04 - val_loss: 0.5838\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 6.7273e-04 - val_loss: 0.5858\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 6.5978e-04 - val_loss: 0.5866\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 6.4945e-04 - val_loss: 0.5856\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 6.3570e-04 - val_loss: 0.5870\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 6.2571e-04 - val_loss: 0.5867\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 6.1536e-04 - val_loss: 0.5893\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 6.0528e-04 - val_loss: 0.5886\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 5.9497e-04 - val_loss: 0.5895\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 5.8521e-04 - val_loss: 0.5901\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 5.7613e-04 - val_loss: 0.5913\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 5.6600e-04 - val_loss: 0.5913\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 5.5749e-04 - val_loss: 0.5917\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 5.4846e-04 - val_loss: 0.5930\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 5.3961e-04 - val_loss: 0.5938\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 5.3113e-04 - val_loss: 0.5934\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 5.2298e-04 - val_loss: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 5.1494e-04 - val_loss: 0.5943\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 5.0631e-04 - val_loss: 0.5942\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.9913e-04 - val_loss: 0.5951\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 4.9063e-04 - val_loss: 0.5962\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 4.8365e-04 - val_loss: 0.5960\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 4.7602e-04 - val_loss: 0.5964\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 4.6928e-04 - val_loss: 0.5969\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 4.6244e-04 - val_loss: 0.5975\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.5560e-04 - val_loss: 0.5984\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 4.4878e-04 - val_loss: 0.5987\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 4.4235e-04 - val_loss: 0.5988\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.3528e-04 - val_loss: 0.5987\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 4.2968e-04 - val_loss: 0.5995\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 4.2277e-04 - val_loss: 0.6000\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.1716e-04 - val_loss: 0.6008\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 4.1131e-04 - val_loss: 0.6017\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 4.0597e-04 - val_loss: 0.6012\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 3.9990e-04 - val_loss: 0.6024\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 3.9413e-04 - val_loss: 0.6029\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.8894e-04 - val_loss: 0.6032\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 3.8358e-04 - val_loss: 0.6036\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 3.7831e-04 - val_loss: 0.6052\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.7292e-04 - val_loss: 0.6049\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 3.6776e-04 - val_loss: 0.6045\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.6242e-04 - val_loss: 0.6044\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.5714e-04 - val_loss: 0.6052\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.5271e-04 - val_loss: 0.6061\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 3.4749e-04 - val_loss: 0.6068\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 3.4297e-04 - val_loss: 0.6072\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.3833e-04 - val_loss: 0.6071\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 3.3336e-04 - val_loss: 0.6084\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.2925e-04 - val_loss: 0.6090\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 3.2495e-04 - val_loss: 0.6096\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.2072e-04 - val_loss: 0.6099\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 3.1631e-04 - val_loss: 0.6100\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.1216e-04 - val_loss: 0.6104\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 3.0836e-04 - val_loss: 0.6120\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 3.0370e-04 - val_loss: 0.6125\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 3.0006e-04 - val_loss: 0.6127\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.9598e-04 - val_loss: 0.6126\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.9242e-04 - val_loss: 0.6127\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.8923e-04 - val_loss: 0.6141\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.8550e-04 - val_loss: 0.6126\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 2.8156e-04 - val_loss: 0.6134\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 2.7840e-04 - val_loss: 0.6142\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.7445e-04 - val_loss: 0.6144\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.7088e-04 - val_loss: 0.6146\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.6760e-04 - val_loss: 0.6155\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.6438e-04 - val_loss: 0.6162\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.6086e-04 - val_loss: 0.6163\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 8.3923 - val_loss: 7.6396\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 7.3357 - val_loss: 6.6921\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 6.4867 - val_loss: 6.0290\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 5.8369 - val_loss: 5.4714\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 5.2729 - val_loss: 4.9755\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 4.7495 - val_loss: 4.5166\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 4.2969 - val_loss: 4.1304\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 3.8811 - val_loss: 3.7912\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.5083 - val_loss: 3.4755\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.1871 - val_loss: 3.1918\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 2.8888 - val_loss: 2.9809\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.6535 - val_loss: 2.7949\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 2.4674 - val_loss: 2.6721\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 2.3426 - val_loss: 2.5774\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 2.2388 - val_loss: 2.4967\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 2.1576 - val_loss: 2.4386\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.0971 - val_loss: 2.3990\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 2.0459 - val_loss: 2.3518\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 2.0009 - val_loss: 2.3374\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.9655 - val_loss: 2.3033\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.9300 - val_loss: 2.2939\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 1.8946 - val_loss: 2.2551\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 1.8573 - val_loss: 2.2412\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.8296 - val_loss: 2.2142\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.8011 - val_loss: 2.2250\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.7712 - val_loss: 2.2109\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 190us/step - loss: 1.7513 - val_loss: 2.1785\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.7325 - val_loss: 2.2152\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.7171 - val_loss: 2.1715\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.6997 - val_loss: 2.1894\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.6858 - val_loss: 2.1771\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.6745 - val_loss: 2.1702\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.6655 - val_loss: 2.1723\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.6542 - val_loss: 2.1766\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.6453 - val_loss: 2.1719\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 1.6369 - val_loss: 2.1580\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 1.6298 - val_loss: 2.1732\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.6219 - val_loss: 2.1586\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.6152 - val_loss: 2.1731\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.6091 - val_loss: 2.1678\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.6035 - val_loss: 2.1634\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5984 - val_loss: 2.1651\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5921 - val_loss: 2.1696\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5874 - val_loss: 2.1674\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5830 - val_loss: 2.1537\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5783 - val_loss: 2.1563\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5745 - val_loss: 2.1643\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5709 - val_loss: 2.1464\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5673 - val_loss: 2.1612\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5644 - val_loss: 2.1534\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5618 - val_loss: 2.1484\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.5592 - val_loss: 2.1566\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 1.5568 - val_loss: 2.1483\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5546 - val_loss: 2.1506\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5527 - val_loss: 2.1474\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5507 - val_loss: 2.1478\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5489 - val_loss: 2.1443\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5472 - val_loss: 2.1462\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5457 - val_loss: 2.1389\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5443 - val_loss: 2.1404\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5430 - val_loss: 2.1408\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5418 - val_loss: 2.1377\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5406 - val_loss: 2.1402\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5396 - val_loss: 2.1353\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5386 - val_loss: 2.1377\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5376 - val_loss: 2.1315\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5368 - val_loss: 2.1406\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5359 - val_loss: 2.1295\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5351 - val_loss: 2.1360\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5343 - val_loss: 2.1369\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5335 - val_loss: 2.1312\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.5328 - val_loss: 2.1320\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5320 - val_loss: 2.1262\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5314 - val_loss: 2.1351\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 1.5307 - val_loss: 2.1249\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5301 - val_loss: 2.1254\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5295 - val_loss: 2.1324\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5289 - val_loss: 2.1254\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5283 - val_loss: 2.1222\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5278 - val_loss: 2.1233\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5273 - val_loss: 2.1231\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5269 - val_loss: 2.1217\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5264 - val_loss: 2.1263\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5260 - val_loss: 2.1259\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5255 - val_loss: 2.1253\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5251 - val_loss: 2.1193\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 1.5247 - val_loss: 2.1224\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 1.5243 - val_loss: 2.1233\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5240 - val_loss: 2.1206\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5236 - val_loss: 2.1237\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5233 - val_loss: 2.1253\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5229 - val_loss: 2.1222\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5226 - val_loss: 2.1205\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5223 - val_loss: 2.1219\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5220 - val_loss: 2.1209\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5217 - val_loss: 2.1239\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5214 - val_loss: 2.1225\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5210 - val_loss: 2.1264\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5207 - val_loss: 2.1244\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5204 - val_loss: 2.1229\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 1.5200 - val_loss: 2.1254\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5196 - val_loss: 2.1265\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5193 - val_loss: 2.1219\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5190 - val_loss: 2.1255\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5187 - val_loss: 2.1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5184 - val_loss: 2.1288\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5182 - val_loss: 2.1272\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5179 - val_loss: 2.1274\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5177 - val_loss: 2.1248\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5175 - val_loss: 2.1271\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5173 - val_loss: 2.1263\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 1.5171 - val_loss: 2.1236\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5169 - val_loss: 2.1234\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5167 - val_loss: 2.1274\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5165 - val_loss: 2.1262\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5163 - val_loss: 2.1241\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5161 - val_loss: 2.1237\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5160 - val_loss: 2.1244\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5158 - val_loss: 2.1240\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5156 - val_loss: 2.1249\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5155 - val_loss: 2.1241\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5153 - val_loss: 2.1254\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5152 - val_loss: 2.1233\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5150 - val_loss: 2.1242\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5149 - val_loss: 2.1237\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5147 - val_loss: 2.1231\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5146 - val_loss: 2.1245\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5145 - val_loss: 2.1256\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 1.5143 - val_loss: 2.1234\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 1.5142 - val_loss: 2.1266\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5141 - val_loss: 2.1262\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5140 - val_loss: 2.1254\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5139 - val_loss: 2.1245\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5137 - val_loss: 2.1252\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5136 - val_loss: 2.1256\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5135 - val_loss: 2.1257\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5134 - val_loss: 2.1245\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5133 - val_loss: 2.1287\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5132 - val_loss: 2.1297\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5131 - val_loss: 2.1274\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5130 - val_loss: 2.1276\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5129 - val_loss: 2.1272\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5128 - val_loss: 2.1259\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5127 - val_loss: 2.1282\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 1.5126 - val_loss: 2.1292\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5125 - val_loss: 2.1293\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5124 - val_loss: 2.1282\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 1.5123 - val_loss: 2.1282\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5122 - val_loss: 2.1270\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5121 - val_loss: 2.1280\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5120 - val_loss: 2.1284\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5120 - val_loss: 2.1289\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5119 - val_loss: 2.1302\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5118 - val_loss: 2.1280\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5117 - val_loss: 2.1291\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5116 - val_loss: 2.1296\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 1.5115 - val_loss: 2.1296\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5115 - val_loss: 2.1293\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 1.5114 - val_loss: 2.1299\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.5113 - val_loss: 2.1296\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.5112 - val_loss: 2.1307\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5112 - val_loss: 2.1304\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 1.5111 - val_loss: 2.1289\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5110 - val_loss: 2.1296\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 1.5109 - val_loss: 2.1305\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.5109 - val_loss: 2.1316\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5108 - val_loss: 2.1303\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.5107 - val_loss: 2.1267\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 1.5106 - val_loss: 2.1294\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5106 - val_loss: 2.1311\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 1.5105 - val_loss: 2.1304\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.5104 - val_loss: 2.1304\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.5104 - val_loss: 2.1311\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.5103 - val_loss: 2.1304\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.5103 - val_loss: 2.1302\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5102 - val_loss: 2.1307\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5101 - val_loss: 2.1307\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 1.5101 - val_loss: 2.1309\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.5100 - val_loss: 2.1329\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5100 - val_loss: 2.1319\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5099 - val_loss: 2.1322\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5099 - val_loss: 2.1340\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 1.5098 - val_loss: 2.1335\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 220us/step - loss: 1.5098 - val_loss: 2.1339\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5097 - val_loss: 2.1331\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5097 - val_loss: 2.1346\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5096 - val_loss: 2.1341\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 1.5096 - val_loss: 2.1347\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5095 - val_loss: 2.1340\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5095 - val_loss: 2.1342\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 1.5094 - val_loss: 2.1346\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5094 - val_loss: 2.1344\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.5093 - val_loss: 2.1358\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.5093 - val_loss: 2.1350\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.5092 - val_loss: 2.1353\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5092 - val_loss: 2.1354\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5092 - val_loss: 2.1366\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 1.5091 - val_loss: 2.1362\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 1.5091 - val_loss: 2.1368\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 1.5090 - val_loss: 2.1379\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.7708 - val_loss: 2.5439\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 2.5578 - val_loss: 2.3652\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.3049 - val_loss: 2.1579\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.1061 - val_loss: 2.0353\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 1.9723 - val_loss: 1.9136\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 1.7830 - val_loss: 1.8024\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 1.6096 - val_loss: 1.5911\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 1.4227 - val_loss: 1.4708\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 1.2748 - val_loss: 1.3613\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 1.1488 - val_loss: 1.2520\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 1.0424 - val_loss: 1.1730\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.9618 - val_loss: 1.1143\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.8910 - val_loss: 1.0557\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.8246 - val_loss: 0.9988\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.7615 - val_loss: 0.9502\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.7062 - val_loss: 0.9054\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.6555 - val_loss: 0.8629\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.6073 - val_loss: 0.8399\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.5655 - val_loss: 0.7951\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.5171 - val_loss: 0.7715\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.4656 - val_loss: 0.7358\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.4280 - val_loss: 0.7041\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.3937 - val_loss: 0.6793\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.3649 - val_loss: 0.6642\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.3394 - val_loss: 0.6413\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.3165 - val_loss: 0.6253\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.2970 - val_loss: 0.6116\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.2786 - val_loss: 0.6024\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.2627 - val_loss: 0.5889\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.2483 - val_loss: 0.5825\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.2346 - val_loss: 0.5752\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.2213 - val_loss: 0.5580\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.2080 - val_loss: 0.5551\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.1968 - val_loss: 0.5468\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.1855 - val_loss: 0.5397\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.1761 - val_loss: 0.5339\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.1673 - val_loss: 0.5242\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.1592 - val_loss: 0.5225\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.1519 - val_loss: 0.5172\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.1452 - val_loss: 0.5120\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.1394 - val_loss: 0.5114\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.1339 - val_loss: 0.5040\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.1289 - val_loss: 0.5077\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.1233 - val_loss: 0.4986\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.1186 - val_loss: 0.4937\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.1143 - val_loss: 0.4931\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.1102 - val_loss: 0.4866\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.1063 - val_loss: 0.4818\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.1026 - val_loss: 0.4834\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0992 - val_loss: 0.4785\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0959 - val_loss: 0.4783\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0927 - val_loss: 0.4738\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 0.0897 - val_loss: 0.4732\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0868 - val_loss: 0.4721\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0842 - val_loss: 0.4723\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0817 - val_loss: 0.4682\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0792 - val_loss: 0.4661\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0769 - val_loss: 0.4681\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0747 - val_loss: 0.4672\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0726 - val_loss: 0.4668\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0706 - val_loss: 0.4662\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0686 - val_loss: 0.4650\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0668 - val_loss: 0.4640\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0649 - val_loss: 0.4651\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0633 - val_loss: 0.4649\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0617 - val_loss: 0.4636\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0601 - val_loss: 0.4626\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0586 - val_loss: 0.4623\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0571 - val_loss: 0.4642\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0557 - val_loss: 0.4646\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0544 - val_loss: 0.4640\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0531 - val_loss: 0.4635\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0518 - val_loss: 0.4648\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0505 - val_loss: 0.4651\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0493 - val_loss: 0.4671\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0482 - val_loss: 0.4660\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0471 - val_loss: 0.4653\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0460 - val_loss: 0.4670\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0450 - val_loss: 0.4681\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0440 - val_loss: 0.4685\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0430 - val_loss: 0.4676\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0420 - val_loss: 0.4709\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0411 - val_loss: 0.4704\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0402 - val_loss: 0.4706\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0393 - val_loss: 0.4685\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0385 - val_loss: 0.4690\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0377 - val_loss: 0.4697\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0370 - val_loss: 0.4703\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0362 - val_loss: 0.4718\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 0.0356 - val_loss: 0.4735\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0349 - val_loss: 0.4721\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0342 - val_loss: 0.4716\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0336 - val_loss: 0.4718\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0329 - val_loss: 0.4722\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0323 - val_loss: 0.4724\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0318 - val_loss: 0.4733\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0312 - val_loss: 0.4735\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0306 - val_loss: 0.4739\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0301 - val_loss: 0.4731\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0296 - val_loss: 0.4750\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0290 - val_loss: 0.4752\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0285 - val_loss: 0.4769\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0280 - val_loss: 0.4768\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0275 - val_loss: 0.4762\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0270 - val_loss: 0.4779\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0266 - val_loss: 0.4791\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0261 - val_loss: 0.4788\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0257 - val_loss: 0.4783\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0253 - val_loss: 0.4774\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0249 - val_loss: 0.4783\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0245 - val_loss: 0.4794\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0241 - val_loss: 0.4788\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0238 - val_loss: 0.4793\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0234 - val_loss: 0.4800\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0230 - val_loss: 0.4806\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0227 - val_loss: 0.4811\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0223 - val_loss: 0.4815\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0220 - val_loss: 0.4814\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0217 - val_loss: 0.4812\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0214 - val_loss: 0.4819\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0211 - val_loss: 0.4821\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0207 - val_loss: 0.4834\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0204 - val_loss: 0.4834\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0200 - val_loss: 0.4829\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0198 - val_loss: 0.4808\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0195 - val_loss: 0.4823\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0192 - val_loss: 0.4832\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0189 - val_loss: 0.4825\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0187 - val_loss: 0.4830\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 0.0184 - val_loss: 0.4841\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0182 - val_loss: 0.4857\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0179 - val_loss: 0.4857\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0177 - val_loss: 0.4860\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0175 - val_loss: 0.4865\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0172 - val_loss: 0.4868\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0170 - val_loss: 0.4866\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0168 - val_loss: 0.4869\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0166 - val_loss: 0.4874\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0164 - val_loss: 0.4872\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 300us/step - loss: 0.0162 - val_loss: 0.4887\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0160 - val_loss: 0.4895\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0158 - val_loss: 0.4908\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0156 - val_loss: 0.4911\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0154 - val_loss: 0.4909\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0152 - val_loss: 0.4912\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0150 - val_loss: 0.4918\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0148 - val_loss: 0.4920\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0146 - val_loss: 0.4936\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0144 - val_loss: 0.4940\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0143 - val_loss: 0.4939\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0141 - val_loss: 0.4932\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0139 - val_loss: 0.4936\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0138 - val_loss: 0.4946\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0136 - val_loss: 0.4955\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0134 - val_loss: 0.4961\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0133 - val_loss: 0.4967\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0131 - val_loss: 0.4984\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0130 - val_loss: 0.4986\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0128 - val_loss: 0.4994\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0127 - val_loss: 0.5005\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0125 - val_loss: 0.5008\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0124 - val_loss: 0.5006\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0122 - val_loss: 0.5009\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0121 - val_loss: 0.5011\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0120 - val_loss: 0.5022\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0118 - val_loss: 0.5026\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0117 - val_loss: 0.5040\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0116 - val_loss: 0.5040\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0114 - val_loss: 0.5042\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0113 - val_loss: 0.5044\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0112 - val_loss: 0.5047\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0111 - val_loss: 0.5051\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0109 - val_loss: 0.5057\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0108 - val_loss: 0.5062\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0107 - val_loss: 0.5072\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0106 - val_loss: 0.5060\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0104 - val_loss: 0.5052\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0103 - val_loss: 0.5061\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0102 - val_loss: 0.5060\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0101 - val_loss: 0.5057\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0099 - val_loss: 0.5060\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0098 - val_loss: 0.5056\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0097 - val_loss: 0.5062\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0096 - val_loss: 0.5069\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0095 - val_loss: 0.5071\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0094 - val_loss: 0.5075\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0093 - val_loss: 0.5073\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0092 - val_loss: 0.5080\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0091 - val_loss: 0.5088\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0090 - val_loss: 0.5089\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0090 - val_loss: 0.5102\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0089 - val_loss: 0.5112\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0088 - val_loss: 0.5123\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0087 - val_loss: 0.5128\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0086 - val_loss: 0.5134\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0085 - val_loss: 0.5135\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0084 - val_loss: 0.5135\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0084 - val_loss: 0.5135\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0083 - val_loss: 0.5138\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0082 - val_loss: 0.5141\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2473 - val_loss: 2.0849\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 1.9201 - val_loss: 1.7754\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 1.5596 - val_loss: 1.4686\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 1.2130 - val_loss: 1.2191\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.9328 - val_loss: 1.0086\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.7189 - val_loss: 0.8751\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.5579 - val_loss: 0.7988\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.4431 - val_loss: 0.7363\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.3493 - val_loss: 0.7106\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.2715 - val_loss: 0.6895\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.2249 - val_loss: 0.6716\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.1855 - val_loss: 0.6623\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.1483 - val_loss: 0.6625\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.1227 - val_loss: 0.6668\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.1005 - val_loss: 0.6523\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0817 - val_loss: 0.6551\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0679 - val_loss: 0.6541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0576 - val_loss: 0.6681\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0486 - val_loss: 0.6577\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0428 - val_loss: 0.6788\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0370 - val_loss: 0.6840\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0322 - val_loss: 0.6833\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0290 - val_loss: 0.6851\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0266 - val_loss: 0.7062\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0231 - val_loss: 0.6929\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0208 - val_loss: 0.7049\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0187 - val_loss: 0.7074\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0170 - val_loss: 0.7148\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0156 - val_loss: 0.7174\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0141 - val_loss: 0.7191\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0131 - val_loss: 0.7301\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0120 - val_loss: 0.7337\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0113 - val_loss: 0.7388\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0104 - val_loss: 0.7428\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0097 - val_loss: 0.7476\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0091 - val_loss: 0.7544\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0085 - val_loss: 0.7586\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0080 - val_loss: 0.7598\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0075 - val_loss: 0.7632\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0071 - val_loss: 0.7713\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0067 - val_loss: 0.7761\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0063 - val_loss: 0.7754\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0060 - val_loss: 0.7844\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0057 - val_loss: 0.7852\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0054 - val_loss: 0.7857\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0051 - val_loss: 0.7901\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0048 - val_loss: 0.7957\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0046 - val_loss: 0.8003\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0044 - val_loss: 0.8032\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0042 - val_loss: 0.8030\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0040 - val_loss: 0.8076\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0039 - val_loss: 0.8124\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0037 - val_loss: 0.8135\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0035 - val_loss: 0.8159\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0034 - val_loss: 0.8215\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0033 - val_loss: 0.8266\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0031 - val_loss: 0.8283\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0030 - val_loss: 0.8299\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0029 - val_loss: 0.8320\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0028 - val_loss: 0.8376\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0027 - val_loss: 0.8390\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0026 - val_loss: 0.8431\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0025 - val_loss: 0.8436\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0024 - val_loss: 0.8479\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0023 - val_loss: 0.8503\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0022 - val_loss: 0.8525\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0022 - val_loss: 0.8522\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0021 - val_loss: 0.8554\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0020 - val_loss: 0.8580\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0020 - val_loss: 0.8602\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0019 - val_loss: 0.8639\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0019 - val_loss: 0.8653\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0018 - val_loss: 0.8686\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0017 - val_loss: 0.8702\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0017 - val_loss: 0.8724\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0017 - val_loss: 0.8756\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0016 - val_loss: 0.8757\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 222us/step - loss: 0.0016 - val_loss: 0.8784\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0015 - val_loss: 0.8825\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0015 - val_loss: 0.8836\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0014 - val_loss: 0.8839\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0014 - val_loss: 0.8866\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0014 - val_loss: 0.8902\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0013 - val_loss: 0.8934\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0013 - val_loss: 0.8945\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0013 - val_loss: 0.8952\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0012 - val_loss: 0.8972\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 221us/step - loss: 0.0012 - val_loss: 0.8987\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0012 - val_loss: 0.9006\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 0.0011 - val_loss: 0.9037\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0011 - val_loss: 0.9055\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0011 - val_loss: 0.9043\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0011 - val_loss: 0.9064\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0010 - val_loss: 0.9091\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0010 - val_loss: 0.9128\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 9.8630e-04 - val_loss: 0.9151\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 9.6101e-04 - val_loss: 0.9134\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 9.3951e-04 - val_loss: 0.9157\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 9.1985e-04 - val_loss: 0.9180\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 8.9861e-04 - val_loss: 0.9202\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 8.8127e-04 - val_loss: 0.9208\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 8.5969e-04 - val_loss: 0.9235\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 8.4381e-04 - val_loss: 0.9249\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 8.2531e-04 - val_loss: 0.9283\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 8.0601e-04 - val_loss: 0.9295\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 7.9123e-04 - val_loss: 0.9306\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 7.7233e-04 - val_loss: 0.9318\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 7.5809e-04 - val_loss: 0.9336\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 7.4279e-04 - val_loss: 0.9362\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 7.2625e-04 - val_loss: 0.9370\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 7.1371e-04 - val_loss: 0.9378\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 6.9770e-04 - val_loss: 0.9407\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 6.8338e-04 - val_loss: 0.9416\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 6.7050e-04 - val_loss: 0.9430\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 6.5766e-04 - val_loss: 0.9448\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 6.4547e-04 - val_loss: 0.9464\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 6.3221e-04 - val_loss: 0.9481\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.2130e-04 - val_loss: 0.9498\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 6.1072e-04 - val_loss: 0.9510\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 5.9737e-04 - val_loss: 0.9525\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 5.8636e-04 - val_loss: 0.9549\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 5.7507e-04 - val_loss: 0.9557\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 5.6444e-04 - val_loss: 0.9574\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 5.5426e-04 - val_loss: 0.9595\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 5.4444e-04 - val_loss: 0.9620\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 5.3288e-04 - val_loss: 0.9637\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 5.2352e-04 - val_loss: 0.9644\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 5.1385e-04 - val_loss: 0.9655\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 5.0523e-04 - val_loss: 0.9670\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 4.9648e-04 - val_loss: 0.9679\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.8829e-04 - val_loss: 0.9687\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.7931e-04 - val_loss: 0.9701\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 4.7039e-04 - val_loss: 0.9727\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 4.6291e-04 - val_loss: 0.9731\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 4.5411e-04 - val_loss: 0.9759\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.4692e-04 - val_loss: 0.9780\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 4.3922e-04 - val_loss: 0.9794\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.3211e-04 - val_loss: 0.9798\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 4.2430e-04 - val_loss: 0.9818\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 4.1734e-04 - val_loss: 0.9834\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 4.1133e-04 - val_loss: 0.9852\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 4.0494e-04 - val_loss: 0.9861\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 3.9672e-04 - val_loss: 0.9857\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.9133e-04 - val_loss: 0.9871\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 3.8496e-04 - val_loss: 0.9887\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 3.7831e-04 - val_loss: 0.9917\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.7194e-04 - val_loss: 0.9941\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 3.6689e-04 - val_loss: 0.9956\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 3.6073e-04 - val_loss: 0.9961\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 3.5488e-04 - val_loss: 0.9968\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 3.4887e-04 - val_loss: 0.9989\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.4382e-04 - val_loss: 1.0009\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.3874e-04 - val_loss: 1.0023\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 3.3346e-04 - val_loss: 1.0029\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.2870e-04 - val_loss: 1.0032\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 3.2356e-04 - val_loss: 1.0043\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 3.1875e-04 - val_loss: 1.0066\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.1390e-04 - val_loss: 1.0083\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 3.0919e-04 - val_loss: 1.0099\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 3.0482e-04 - val_loss: 1.0116\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 3.0018e-04 - val_loss: 1.0126\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.9546e-04 - val_loss: 1.0134\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.9144e-04 - val_loss: 1.0141\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.8690e-04 - val_loss: 1.0161\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.8295e-04 - val_loss: 1.0171\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.7902e-04 - val_loss: 1.0178\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.7545e-04 - val_loss: 1.0183\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 2.7145e-04 - val_loss: 1.0205\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.6791e-04 - val_loss: 1.0217\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 2.6400e-04 - val_loss: 1.0228\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 207us/step - loss: 2.6036e-04 - val_loss: 1.0237\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.5713e-04 - val_loss: 1.0242\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.5356e-04 - val_loss: 1.0259\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.5018e-04 - val_loss: 1.0278\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 2.4681e-04 - val_loss: 1.0291\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.4319e-04 - val_loss: 1.0305\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.4004e-04 - val_loss: 1.0312\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.3666e-04 - val_loss: 1.0313\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.3356e-04 - val_loss: 1.0325\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 2.3078e-04 - val_loss: 1.0341\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.2785e-04 - val_loss: 1.0360\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.2499e-04 - val_loss: 1.0375\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.2174e-04 - val_loss: 1.0394\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.1954e-04 - val_loss: 1.0398\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.1631e-04 - val_loss: 1.0402\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.1378e-04 - val_loss: 1.0406\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 2.1044e-04 - val_loss: 1.0426\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 2.0788e-04 - val_loss: 1.0438\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 2.0530e-04 - val_loss: 1.0458\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 2.0290e-04 - val_loss: 1.0467\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 2.0019e-04 - val_loss: 1.0479\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 1.9759e-04 - val_loss: 1.0492\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 1.9553e-04 - val_loss: 1.0498\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 1.9290e-04 - val_loss: 1.0516\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 1.9022e-04 - val_loss: 1.0530\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 1.8788e-04 - val_loss: 1.0537\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 1.8577e-04 - val_loss: 1.0558\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 410us/step - loss: 1.8411e-04 - val_loss: 1.0585\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 1.8138e-04 - val_loss: 1.0578\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 1.7911e-04 - val_loss: 1.0589\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.2820 - val_loss: 2.2102\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.1260 - val_loss: 2.0613\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 1.8955 - val_loss: 1.8335\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 1.6244 - val_loss: 1.6230\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 1.3513 - val_loss: 1.3941\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 1.1243 - val_loss: 1.2091\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.9089 - val_loss: 1.0693\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.7607 - val_loss: 0.9904\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.6272 - val_loss: 0.8798\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.5137 - val_loss: 0.8158\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.4129 - val_loss: 0.7843\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.3376 - val_loss: 0.7544\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.2823 - val_loss: 0.7234\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.2338 - val_loss: 0.6937\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.1920 - val_loss: 0.6925\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.1685 - val_loss: 0.6795\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.1428 - val_loss: 0.6726\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.1208 - val_loss: 0.6631\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.1020 - val_loss: 0.6642\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0906 - val_loss: 0.6547\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0788 - val_loss: 0.6645\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 394us/step - loss: 0.0693 - val_loss: 0.6700\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0588 - val_loss: 0.6577\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0537 - val_loss: 0.6805\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0446 - val_loss: 0.6737\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0398 - val_loss: 0.6720\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0356 - val_loss: 0.6904\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0311 - val_loss: 0.6976\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0276 - val_loss: 0.6898\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0259 - val_loss: 0.6881\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0226 - val_loss: 0.7212\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0209 - val_loss: 0.7125\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0185 - val_loss: 0.7100\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0166 - val_loss: 0.7151\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0153 - val_loss: 0.7208\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0141 - val_loss: 0.7278\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0131 - val_loss: 0.7383\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0119 - val_loss: 0.7337\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0110 - val_loss: 0.7383\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0102 - val_loss: 0.7407\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0095 - val_loss: 0.7478\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0089 - val_loss: 0.7494\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0083 - val_loss: 0.7584\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0079 - val_loss: 0.7592\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0074 - val_loss: 0.7660\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0071 - val_loss: 0.7733\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0067 - val_loss: 0.7767\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 230us/step - loss: 0.0063 - val_loss: 0.7757\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0058 - val_loss: 0.7713\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0056 - val_loss: 0.7722\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0053 - val_loss: 0.7795\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0050 - val_loss: 0.7836\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0048 - val_loss: 0.7906\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0046 - val_loss: 0.7912\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0044 - val_loss: 0.7916\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0041 - val_loss: 0.7956\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0040 - val_loss: 0.7998\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0038 - val_loss: 0.8051\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0036 - val_loss: 0.8032\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0035 - val_loss: 0.8068\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0033 - val_loss: 0.8110\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0032 - val_loss: 0.8111\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0031 - val_loss: 0.8106\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0030 - val_loss: 0.8160\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0029 - val_loss: 0.8213\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0028 - val_loss: 0.8199\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0027 - val_loss: 0.8246\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0026 - val_loss: 0.8287\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0025 - val_loss: 0.8311\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0024 - val_loss: 0.8342\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0023 - val_loss: 0.8323\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0023 - val_loss: 0.8318\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0022 - val_loss: 0.8375\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0021 - val_loss: 0.8399\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0020 - val_loss: 0.8397\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0020 - val_loss: 0.8429\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0019 - val_loss: 0.8456\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0019 - val_loss: 0.8484\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.0018 - val_loss: 0.8505\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.8536\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0017 - val_loss: 0.8569\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0017 - val_loss: 0.8551\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0016 - val_loss: 0.8553\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0016 - val_loss: 0.8589\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0015 - val_loss: 0.8609\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0015 - val_loss: 0.8645\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0014 - val_loss: 0.8636\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0014 - val_loss: 0.8642\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0014 - val_loss: 0.8688\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0013 - val_loss: 0.8701\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0013 - val_loss: 0.8713\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0013 - val_loss: 0.8717\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 0.0012 - val_loss: 0.8743\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0012 - val_loss: 0.8783\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0012 - val_loss: 0.8787\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0011 - val_loss: 0.8799\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0011 - val_loss: 0.8808\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0011 - val_loss: 0.8840\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0011 - val_loss: 0.8865\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0010 - val_loss: 0.8885\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0010 - val_loss: 0.8884\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 9.9675e-04 - val_loss: 0.8894\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 9.7521e-04 - val_loss: 0.8920\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 9.5283e-04 - val_loss: 0.8944\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 9.3283e-04 - val_loss: 0.8959\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 9.1450e-04 - val_loss: 0.8978\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 8.9412e-04 - val_loss: 0.8990\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 8.7662e-04 - val_loss: 0.8999\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 8.5649e-04 - val_loss: 0.9010\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 8.4002e-04 - val_loss: 0.9026\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 8.2351e-04 - val_loss: 0.9039\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 8.0714e-04 - val_loss: 0.9050\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 7.9024e-04 - val_loss: 0.9040\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 7.7354e-04 - val_loss: 0.9080\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 7.6116e-04 - val_loss: 0.9105\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 7.4234e-04 - val_loss: 0.9099\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 7.2965e-04 - val_loss: 0.9109\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 7.1706e-04 - val_loss: 0.9139\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 7.0189e-04 - val_loss: 0.9154\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 6.8664e-04 - val_loss: 0.9173\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 6.7351e-04 - val_loss: 0.9201\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 6.6138e-04 - val_loss: 0.9207\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 6.4822e-04 - val_loss: 0.9219\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 6.3806e-04 - val_loss: 0.9227\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 6.2586e-04 - val_loss: 0.9234\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 6.1408e-04 - val_loss: 0.9242\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 6.0284e-04 - val_loss: 0.9243\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 5.9284e-04 - val_loss: 0.9258\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 5.8116e-04 - val_loss: 0.9275\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 5.7217e-04 - val_loss: 0.9281\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 5.6251e-04 - val_loss: 0.9308\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 5.5158e-04 - val_loss: 0.9320\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 5.4354e-04 - val_loss: 0.9343\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 5.3294e-04 - val_loss: 0.9357\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 5.2358e-04 - val_loss: 0.9372\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 5.1580e-04 - val_loss: 0.9378\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 5.0619e-04 - val_loss: 0.9383\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 4.9841e-04 - val_loss: 0.9393\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 4.8993e-04 - val_loss: 0.9416\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 4.8221e-04 - val_loss: 0.9421\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 4.7523e-04 - val_loss: 0.9445\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 4.6796e-04 - val_loss: 0.9446\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 4.6000e-04 - val_loss: 0.9460\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 4.5266e-04 - val_loss: 0.9465\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 4.4756e-04 - val_loss: 0.9468\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.4005e-04 - val_loss: 0.9513\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.3165e-04 - val_loss: 0.9520\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.2486e-04 - val_loss: 0.9529\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.1791e-04 - val_loss: 0.9537\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 4.1241e-04 - val_loss: 0.9547\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 4.0618e-04 - val_loss: 0.9553\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 4.0097e-04 - val_loss: 0.9561\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 3.9356e-04 - val_loss: 0.9581\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 3.8861e-04 - val_loss: 0.9599\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 3.8249e-04 - val_loss: 0.9582\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.7651e-04 - val_loss: 0.9598\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 3.7106e-04 - val_loss: 0.9623\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 3.6592e-04 - val_loss: 0.9635\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.6000e-04 - val_loss: 0.9636\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.5468e-04 - val_loss: 0.9645\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 3.4955e-04 - val_loss: 0.9660\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 3.4462e-04 - val_loss: 0.9675\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 3.3942e-04 - val_loss: 0.9684\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 3.3496e-04 - val_loss: 0.9696\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 3.2994e-04 - val_loss: 0.9712\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 3.2522e-04 - val_loss: 0.9716\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 3.2019e-04 - val_loss: 0.9736\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 3.1610e-04 - val_loss: 0.9748\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 242us/step - loss: 3.1196e-04 - val_loss: 0.9761\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 3.0713e-04 - val_loss: 0.9762\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 3.0238e-04 - val_loss: 0.9776\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.9813e-04 - val_loss: 0.9791\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 2.9314e-04 - val_loss: 0.9792\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.8952e-04 - val_loss: 0.9807\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.8523e-04 - val_loss: 0.9815\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.8115e-04 - val_loss: 0.9820\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 2.7728e-04 - val_loss: 0.9842\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 2.7430e-04 - val_loss: 0.9869\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 2.6995e-04 - val_loss: 0.9878\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.6555e-04 - val_loss: 0.9893\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 2.6217e-04 - val_loss: 0.9903\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 2.5811e-04 - val_loss: 0.9919\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.5455e-04 - val_loss: 0.9929\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.5081e-04 - val_loss: 0.9936\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 223us/step - loss: 2.4757e-04 - val_loss: 0.9949\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 2.4390e-04 - val_loss: 0.9965\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.4009e-04 - val_loss: 0.9973\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 2.3689e-04 - val_loss: 0.9984\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 2.3397e-04 - val_loss: 0.9998\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 2.3065e-04 - val_loss: 1.0016\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 2.2728e-04 - val_loss: 1.0030\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 2.2461e-04 - val_loss: 1.0039\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.2113e-04 - val_loss: 1.0046\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.1786e-04 - val_loss: 1.0046\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 2.1516e-04 - val_loss: 1.0050\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.1213e-04 - val_loss: 1.0068\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 2.0920e-04 - val_loss: 1.0090\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.0606e-04 - val_loss: 1.0106\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.0357e-04 - val_loss: 1.0115\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 274us/step - loss: 2.0070e-04 - val_loss: 1.0128\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2577 - val_loss: 2.1405\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 1.9963 - val_loss: 1.9550\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 1.7711 - val_loss: 1.7560\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.5413 - val_loss: 1.5842\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 1.3501 - val_loss: 1.4184\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 1.1662 - val_loss: 1.3051\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.0027 - val_loss: 1.1920\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.8663 - val_loss: 1.0995\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.7453 - val_loss: 1.0408\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.6380 - val_loss: 0.9706\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.5573 - val_loss: 0.9404\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.4855 - val_loss: 0.8837\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.4253 - val_loss: 0.8605\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.3723 - val_loss: 0.8388\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.3259 - val_loss: 0.8196\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.2879 - val_loss: 0.7904\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.2531 - val_loss: 0.7827\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.2233 - val_loss: 0.7662\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.1998 - val_loss: 0.7662\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.1791 - val_loss: 0.7372\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.1609 - val_loss: 0.7563\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.1455 - val_loss: 0.7244\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.1317 - val_loss: 0.7404\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 183us/step - loss: 0.1212 - val_loss: 0.7196\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.1091 - val_loss: 0.7280\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.1010 - val_loss: 0.7153\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0934 - val_loss: 0.7126\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0858 - val_loss: 0.7161\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0795 - val_loss: 0.7115\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 387us/step - loss: 0.0744 - val_loss: 0.6999\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0693 - val_loss: 0.7119\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.0649 - val_loss: 0.7054\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 0.0606 - val_loss: 0.7133\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.0571 - val_loss: 0.7065\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0538 - val_loss: 0.7049\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0506 - val_loss: 0.7108\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0480 - val_loss: 0.7067\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0453 - val_loss: 0.7038\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0431 - val_loss: 0.7034\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0408 - val_loss: 0.7133\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0389 - val_loss: 0.7026\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0369 - val_loss: 0.7060\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0355 - val_loss: 0.7105\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0338 - val_loss: 0.7050\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0323 - val_loss: 0.7059\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0311 - val_loss: 0.7138\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0298 - val_loss: 0.7125\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0285 - val_loss: 0.7044\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0274 - val_loss: 0.7118\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0263 - val_loss: 0.7164\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0254 - val_loss: 0.7121\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0245 - val_loss: 0.7120\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0236 - val_loss: 0.7159\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.0228 - val_loss: 0.7130\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0220 - val_loss: 0.7188\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0213 - val_loss: 0.7229\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0206 - val_loss: 0.7186\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0200 - val_loss: 0.7214\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0193 - val_loss: 0.7186\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0187 - val_loss: 0.7197\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0182 - val_loss: 0.7212\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0176 - val_loss: 0.7200\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0171 - val_loss: 0.7224\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0166 - val_loss: 0.7232\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0162 - val_loss: 0.7288\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0157 - val_loss: 0.7293\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0153 - val_loss: 0.7265\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0149 - val_loss: 0.7258\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0145 - val_loss: 0.7262\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0141 - val_loss: 0.7278\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0138 - val_loss: 0.7290\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0134 - val_loss: 0.7342\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0131 - val_loss: 0.7332\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0128 - val_loss: 0.7323\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0125 - val_loss: 0.7361\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0122 - val_loss: 0.7380\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0119 - val_loss: 0.7390\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0116 - val_loss: 0.7402\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0114 - val_loss: 0.7378\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0111 - val_loss: 0.7423\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0109 - val_loss: 0.7453\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0107 - val_loss: 0.7436\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0104 - val_loss: 0.7462\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0102 - val_loss: 0.7464\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0100 - val_loss: 0.7465\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0098 - val_loss: 0.7444\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0096 - val_loss: 0.7479\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0094 - val_loss: 0.7506\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0092 - val_loss: 0.7494\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0090 - val_loss: 0.7524\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0089 - val_loss: 0.7520\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0087 - val_loss: 0.7525\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0085 - val_loss: 0.7532\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0084 - val_loss: 0.7533\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0082 - val_loss: 0.7573\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0081 - val_loss: 0.7571\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0079 - val_loss: 0.7613\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0078 - val_loss: 0.7611\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0077 - val_loss: 0.7611\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0075 - val_loss: 0.7628\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0074 - val_loss: 0.7636\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0073 - val_loss: 0.7644\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0072 - val_loss: 0.7652\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0070 - val_loss: 0.7693\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0069 - val_loss: 0.7696\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0068 - val_loss: 0.7739\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0067 - val_loss: 0.7708\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0066 - val_loss: 0.7693\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0065 - val_loss: 0.7743\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0064 - val_loss: 0.7736\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0063 - val_loss: 0.7739\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0062 - val_loss: 0.7732\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0061 - val_loss: 0.7789\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0060 - val_loss: 0.7813\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0059 - val_loss: 0.7790\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0058 - val_loss: 0.7793\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0057 - val_loss: 0.7794\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0057 - val_loss: 0.7786\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0056 - val_loss: 0.7805\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0055 - val_loss: 0.7827\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0054 - val_loss: 0.7850\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0053 - val_loss: 0.7864\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0053 - val_loss: 0.7862\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0052 - val_loss: 0.7857\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0051 - val_loss: 0.7866\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0050 - val_loss: 0.7893\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0050 - val_loss: 0.7889\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0049 - val_loss: 0.7894\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0048 - val_loss: 0.7914\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.005 - 0s 284us/step - loss: 0.0048 - val_loss: 0.7923\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0047 - val_loss: 0.7892\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0046 - val_loss: 0.7909\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0046 - val_loss: 0.7937\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0045 - val_loss: 0.7969\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0045 - val_loss: 0.7961\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0044 - val_loss: 0.7968\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0044 - val_loss: 0.7982\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0043 - val_loss: 0.7978\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0042 - val_loss: 0.7989\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0042 - val_loss: 0.7995\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0041 - val_loss: 0.8002\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0041 - val_loss: 0.8025\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0040 - val_loss: 0.8041\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0040 - val_loss: 0.8048\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0039 - val_loss: 0.8044\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0039 - val_loss: 0.8052\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0038 - val_loss: 0.8063\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0038 - val_loss: 0.8051\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0037 - val_loss: 0.8045\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0037 - val_loss: 0.8067\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0037 - val_loss: 0.8086\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0036 - val_loss: 0.8117\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0036 - val_loss: 0.8110\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0035 - val_loss: 0.8103\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0035 - val_loss: 0.8121\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 244us/step - loss: 0.0034 - val_loss: 0.8127\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0034 - val_loss: 0.8147\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0034 - val_loss: 0.8142\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0033 - val_loss: 0.8161\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0033 - val_loss: 0.8175\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0032 - val_loss: 0.8188\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0032 - val_loss: 0.8203\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0032 - val_loss: 0.8194\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0031 - val_loss: 0.8192\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0031 - val_loss: 0.8205\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0031 - val_loss: 0.8206\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0030 - val_loss: 0.8203\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0030 - val_loss: 0.8225\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0030 - val_loss: 0.8234\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.0029 - val_loss: 0.8233\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0029 - val_loss: 0.8260\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0029 - val_loss: 0.8277\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0028 - val_loss: 0.8290\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0028 - val_loss: 0.8280\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0028 - val_loss: 0.8282\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0028 - val_loss: 0.8303\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0027 - val_loss: 0.8301\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0027 - val_loss: 0.8300\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 0.0027 - val_loss: 0.8307\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0026 - val_loss: 0.8309\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0026 - val_loss: 0.8339\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0026 - val_loss: 0.8333\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0026 - val_loss: 0.8349\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0025 - val_loss: 0.8351\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0025 - val_loss: 0.8363\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0025 - val_loss: 0.8373\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0025 - val_loss: 0.8389\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0024 - val_loss: 0.8390\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0024 - val_loss: 0.8399\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0024 - val_loss: 0.8400\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.0024 - val_loss: 0.8378\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0023 - val_loss: 0.8390\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0023 - val_loss: 0.8401\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0023 - val_loss: 0.8407\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0023 - val_loss: 0.8420\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0023 - val_loss: 0.8425\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0022 - val_loss: 0.8433\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0022 - val_loss: 0.8442\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0022 - val_loss: 0.8454\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 243us/step - loss: 0.0022 - val_loss: 0.8465\n"
     ]
    }
   ],
   "source": [
    "for k, act, arch in itertools.product(k_set, act_set, arch_set):\n",
    "    \n",
    "    if arch==\"A\"and k==None: \n",
    "        model = get_model_A(input_dim=X.shape[1], s1=50, s2=30, s3=20,s3_activation=act)\n",
    "        model.fit(X_train, y_train_oh, epochs=200, batch_size=32, validation_data=(X_test, y_test_oh))\n",
    "        preds_train = model.predict(X_train).argmax(axis=1)\n",
    "        preds_test = model.predict(X_test).argmax(axis=1)\n",
    "        acc=(np.mean(preds_test==y_test))\n",
    "        r_test.loc[arch+'-'+act,str(k)]=acc\n",
    "        acc=0\n",
    "    \n",
    "    if arch==\"B\"and k!=None:\n",
    "        X_train_extra, X_test_extra = get_X_extra(y_train, y_test, k0=k[0], k1=k[1])    \n",
    "        model = get_model_B(input_dim=X.shape[1], extra_info_dim=X_train_extra.shape[1], s1=50, s2=30, s3=20,s3_activation=act)\n",
    "        model.fit([X_train, X_train_extra], y_train_oh, epochs=200, batch_size=32,validation_data=([X_test, X_test_extra], y_test_oh))\n",
    "        preds_train = model.predict([X_train, X_train_extra]).argmax(axis=1)\n",
    "        preds_test = model.predict([X_test, X_test_extra]).argmax(axis=1)\n",
    "        acc=(np.mean(preds_test==y_test))\n",
    "        r_test.loc[arch+'-'+act,str(k)]=acc\n",
    "        acc=0\n",
    "    \n",
    "    if arch==\"C\"and k!=None:\n",
    "        X_train_extra, X_test_extra = get_X_extra(y_train, y_test, k0=k[0], k1=k[1])    \n",
    "        model = get_model_C(input_dim=X.shape[1], extra_info_dim=X_train_extra.shape[1], s1=50, s2=30, s3=20,s3_activation=act)\n",
    "        model.fit([X_train, X_train_extra], y_train_oh, epochs=200, batch_size=32,validation_data=([X_test, X_test_extra], y_test_oh))\n",
    "        preds_train = model.predict([X_train, X_train_extra]).argmax(axis=1)\n",
    "        preds_test = model.predict([X_test, X_test_extra]).argmax(axis=1)\n",
    "        acc=(np.mean(preds_test==y_test))\n",
    "        r_test.loc[arch+'-'+act,str(k)]=acc\n",
    "        acc=0\n",
    "    #else:\n",
    "     #   acc=0\n",
    "      #  r_test.loc[arch+'-'+act,str(k)]=acc\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    #print( \"%10s %8s %1s\"%(str(k), act, arch)    )\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(-0.5, 2)</th>\n",
       "      <th>(-0.5, 30)</th>\n",
       "      <th>(0, 15)</th>\n",
       "      <th>(0, 30)</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.804167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-linear</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.810833</td>\n",
       "      <td>0.767500</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-relu</th>\n",
       "      <td>0.822500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-tanh</th>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.794167</td>\n",
       "      <td>0.844167</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-linear</th>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.825833</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>0.869167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-relu</th>\n",
       "      <td>0.815833</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.875833</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-tanh</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.881667</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            (0, 1)  (-0.5, 2)  (-0.5, 30)   (0, 15)   (0, 30)      None\n",
       "A-linear       NaN        NaN         NaN       NaN       NaN  0.804167\n",
       "A-relu         NaN        NaN         NaN       NaN       NaN  0.810000\n",
       "A-tanh         NaN        NaN         NaN       NaN       NaN  0.809167\n",
       "B-linear  0.812500   0.810833    0.767500  0.872500  0.705833       NaN\n",
       "B-relu    0.822500   0.812500    0.851667  0.817500  0.819167       NaN\n",
       "B-tanh    0.805000   0.794167    0.844167  0.856667  0.773333       NaN\n",
       "C-linear  0.813333   0.825833    0.874167  0.860833  0.869167       NaN\n",
       "C-relu    0.815833   0.816667    0.875833  0.866667  0.870833       NaN\n",
       "C-tanh    0.800000   0.817500    0.860000  0.881667  0.857500       NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEyCAYAAADdgCZTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XuYXVWd7vvvSzAJd9EgLYQYQBARESUCKijxAsij0l7oBtO2bGDTF6AFxBaPHjra23P2cWN7VJT9RJtG7N0i2AixiSaCBLFBm8SESwIIkmyJeCQRAnIRmsp7/pijYGZlVdVaVWvVWlW8H5751JxjzjnGWKmifjUuc0zZJiIiYqy26nUFIiJickhAiYiIjkhAiYiIjkhAiYiIjkhAiYiIjkhAiYiIjkhAiYiIjkhAiYiIjkhAiYiYxCQdI+luSfdKOq/J+VmSrpe0QtJtko4t6S+Q9A1Jt0u6U9InRiwrT8o3N2X77bz1i3fudTVattULNvW6Cm3bfZuNva5CW1641cT7N/7dpq17XYVRefG0/XpdhbYsX758g+1dRnv/0XO38+8eGmi/3NueWmz7mKHOS5oC/AJ4B7AOuAU40fbq2jULgBW2L5K0P7DI9mxJHwTeY/sESdsCq4Ejba8dqryJ+dM2DrZ+8c689JMf6XU1Wrbdro/3ugpt+/sDru51Fdryx9tNvH/j//X7F/W6CqPyoX1+2usqtEXS/x7L/b97aID/WDyr7fumvPSeGSNccghwr+37ACRdBhxHFRwGGdix7O8EPFBL307S1sA2wNPAo8MVloASEdFjBjbRlRbw7sD9teN1wKEN18wHlkg6E9gOeHtJ/w5V8PkNsC1wtu2HhissYygRET1nBryp7Q2YIWlZbTutIWM1LWxzJwKX2J4JHAt8U9JWVK2bAWA3YE/go5L2Gu5TpIUSEdFjVQtlVOPZG2zPGeb8OmCP2vFMnuvSGnQKcAyA7ZslTQdmAB8EfmD7P4EHJf07MAe4b6jC0kKJiOgDm0bxXwtuAfaRtKekqcAJwMKGa34FvA1A0iuB6cD6kv5WVbYDDgPuGq6wtFAiInrMmIEuzLi1/YykM4DFwBTgYturJH0GWGZ7IfBR4GuSzqZqLJ1k25K+AvwTcAdV19k/2b5tuPISUCIi+sAou7xGZHsRsKgh7fza/mrgTU3ueww4vp2yElAiInrMwECXAsp4SkCJiOgD3WqhjKcElIiIHjN0ZQxlvCWgRET0gYm3sM+WxjRtWNI2km6QtLekpbX0QyT9uCxIdpekr5e1YBrvP6tZehvlz5d07hDn1jZJm1rqlUAaEX3DmIFRbP1mrM+hnAxcSfU0JQCSdgWuAD5u+xXAK4EfADs0uf8sqkf6x4Xtp4HrgD8drzIjIkZkGBjF1m/GGlDmAVdTBZTBNV5OB75h+2YAV75j+7f1GyX9DdUj/ddLur6kXVSWD1gl6dO1a9dK+rSkn5ellOtLke4vaamk+0qeg9YPUeerSr0jIvpC9aR8+1u/GXVAKU9d7mV7re37bb+vnDoAWD7S/ba/RLUEwFzbc0vyJ8syAgcCb5F0YO2WDbZfB1wE1Lu59gOOplp35u8kvaDk//ohir4DaHpO0mmDa+IMPDbxVpaNiIlKDIxi6zdjaaHMADr9Qos/kfRzYAXwKmD/2rkry9flwOxa+jW2n7K9AXgQ2HW4AmwPAE9L2qILzvYC23Nsz5my/XZj+BgREa0zsMntb/1mLAHlSao1XxqtAg5udoOkxZJWSvp6k3N7UrU83mb7QOCahvyfKl8H2Hx22lO1/cZzQ5kG/KGF6yIixsXzuoVi+2FgSlmZsu5C4MOSnl1zX9KfSfoj20fbPsj2qeXU73lusH5H4HHgkTKw/87R1q2RpLtq+y8G1pcVNCMiokPGOn12CXA4cO1ggu3fSjoBuEDSS6jGjn7Mc11WdQuA70v6je25klZQtXDuA/59jHUDQNIMNn8nwFwa1rWJiOilaumV/mtxtGusAeVC4BxqAQWqNfWBI0a62faXgS/Xjk8a4rrZtf1lwJFlf37DdQc0uf0w4Cu14w8CnxipbhER42mTn+cBxfYKSddLmlIGu/uO7X8b3C8z066yfXcPqxQRsZm0UArbF3eiIuOhPNh4aa/rERFRZ8TAJHjfYZYgiYjoA8/7Lq+IiBi7dHlFRESHiAGnyysiIsaoWssrASUiIjogXV4RETFmdrq8IiKiQzZNghbKxA+JERETXDXLa6u2t1ZIOqa8PfdeSec1OT+rPKC+QtJtko6tnTtQ0s3lHVW3N1m7cTNpoQxhqxdsYptdnuh1NVrmPlzKeiRHbPNgr6vQlluemtrrKrTtkOm/6nUVoiXd6fKSNIVq6al3AOuAWyQttL26dtmngMttXyRpf6q1DmeXV6X/M/Ah27eWhXWHXVQ3ASUiose6OMvrEOBe2/cBSLoMOA6oBxRTrfYOsBPViw8BjgJus30rgO3fjVRYAkpERB8YGN2T8jMkLasdL7C9oHa8O3B/7XgdcCibmw8skXQmsB3w9pK+L2BJi4FdgMtsf264yiSgRET02BjW8tpQXps+lGZRqrGD/ETgEtufl/QG4JuSDqCKD4dTvTL9CeA6ScttXzdUYRmUj4iYvNYBe9SOZ/Jcl9agU4DL4dlXj0ynesX7OuAG2xtsP0E1tvK64QpLQImI6AObvFXbWwtuAfaRtGd5fccJwMKGa34FvA1A0iupAsp6YDFwoKRtywD9W9h87GUL6fKKiOixwWnDHc/XfkbSGVTBYQpwse1Vkj4DLLO9EPgo8DVJZ5eqnGTbwMOS/oEqKBlYZPua4cpLQImI6DGj0Q7Kj5y3vYiG157bPr+2vxp40xD3/jPV1OGWJKBERPSBLA4ZERFjZpO1vCIiohM0KdbySkCJiOgxMzlaKB37BJK2kXSDpL0lLa2lHyLpx2VxsrskfV3StmMoZ76kc0e45khJlzRJf3Wz9IiIXuvW4pDjqZMtlJOBK4GBwQRJuwJXACfYvlmSgPcDO1A9edmUpCm2B4Y6P1q2b5c0U9Is21k1LyL6ghGbujTLazx1MsTNA66mCigPlbTTgW+Upy9x5Tu2f9t4s6S1ks6X9BPg+NLS+YGk5ZJulLRfk3uWSppT9mdIWltOPQ08MkQ9v0f1cM8WJJ0maZmkZc88OnFWGo6IiS8tlKI8gbmX7bUl6X3l6wHAN9rI6g+2Dy95Xgf8pe17JB0KfBV4ayuZ2L4JuGmI08uA84AtFjkri6otANjm5btNwAXhI2IiMrT65Htf61SX1wxgYwfy+TaApO2BNwJXVL1kAEzrQP4ADwK7dSiviIgOUN4pX/Mk1fovjVYBB1N1hW2mLIm8K9Xj/6eW5MfL162AjbYPGqHcZ3iu227YN4nVTC/1jYjoC5OlhdKRT2D7YWBKk9dDXgh8uHRZASDpzyT9ke2jbR9UCyb1/B4F1kg6vtwjSa9pUvRaqoAF8IFmdSuzzC6tJe0L3NHqZ4uIGA8DpZXSztZvOhkSl1Ctnf+sMvh+AnBBmTZ8J3AE8GgL+c0DTpF0K1VL57gm11wA/JWkm6i63ZqZxeYtkrnAsAucRUSMJ1vdWm14XHVy2vCFwDnAtfXEMsPriJFutj274XgNcEyT6+bX9u8CDqyd/lSTrA+leqcykqYBc4CzRqpPRMR4mgwPNnYsoNheIen6bj1DMlq2P1Y7nAWcZ/uZXtUnImKy6ujSK7Yv7mR+nWb7HuCeXtcjIqLOkLW8IiKiE5Qur4iIGLtq2nBaKBER0QH9uJRKuxJQIiJ6bLIsDpmAEhHRB/IK4IiIGLPqFcBpoURERAeky2sSs8XAwMRpgr7khb/vdRXa9p+eWG8I+P8Gdup1Fdo2Xb/rdRWiBdUYSnd+30g6BvgiMAX4uu3/3nB+FtVrRl5YrjnP9qKG86uB+bYvGK6sBJSIiD7QjcUeJU2hWnrqHcA64BZJC22vrl32KeBy2xdJ2h9YBMyunf8C8P1WyktAiYjosS4+h3IIcK/t+wAkXUa10G49oBjYsezvBDwweELSHwP38dyrRYaVgBIR0XOj7vKaIWlZ7XhBefPsoN2B+2vH66gWzK2bDyyRdCawHfB2AEnbAR+nat2c20plElAiIvrAKNfy2mB7zjDnm2XaOHh5InCJ7c9LegPwTUkHAJ8GvmD7sdqbc4eVgBIR0WNdnDa8DtijdjyTWpdWcQrlVSG2by4vSpxB1ZL5gKTPUQ3Yb5L0B9sXDlVYAkpERB/o0iyvW4B9JO0J/JrqhYcfbLjmV8DbgEskvZLqNenrbT/7HitJ84HHhgsmkIASEdFz3Vp6xfYzks4AFlNNCb7Y9ipJnwGW2V4IfBT4mqSzqbrDTrJHN6c/ASUiYhIrz5Qsakg7v7a/GnjTCHnMb6WsBJSIiD6QF2xFRMSY5X0oERHRMd1aemU8tfQJJG0j6QZJe0taWks/RNKPJd0t6S5JX5e0bZP7l0qaU/YXSXphxz5B8/oeKemSJumvbpYeEdFTrgbl2936TastlJOBK4GBwQRJuwJXACeUucsC3g/sADwxVEa2jx19dUcmacjPZPt2STMlzbL9q27WIyKiVWZyjKG02saaB1xNFVAeKmmnA9+wfTOAK9+x/dvhMpK0VtIMSbMl3Snpa5JWSVoiaZtyzd6SfiBpuaQbJe1X0t8t6WeSVki6tgQ1JM2XtEDSEuBS4GngkSGq8D2qudgREX1jMrRQRgwokqYCe9lea/t+2+8rpw4Alo+x/H2Ar9h+FbCRqoUDsAA40/bBVGvIfLWk/wQ4zPZrgcuAv63ldTBwnO0P2r7J9keGKHMZcESzE5JOk7RM0rKBR1taCy0iYswGB+UnekBppctrBtUv+25YY3tl2V8OzJa0PfBG4Ira+jHTyteZwLclvRSYCqyp5bXQ9pMtlPkgsFuzE2VRtQUA0/fefWK9rCMiJrR+DBDtaqXL60mqR/EbraJqFWxB0mJJKyV9fYS8n6rtD1AFuK2AjbYPqm2vLNd8GbjQ9quBv2ioV6tNiulUnykioi8MPik/0VsoIwYU2w8DU8qCYXUXAh+W9OxSyJL+TNIf2T66BIJT262Q7UeBNZKOL3lK0mvK6Z2o1qMB+HAr+ZWZaJfWkvYF7mi3XhER3bQJtb31m1YH5ZcAh9cTyuD7CcAFZdrwnVRjE492oF7zgFMk3UrVEjqupM+n6gq7EdjQYl6z2LxFMhe4pgN1jIjoDD9/xlCgao2cA1xbTywzvJoOcDdcd2Rtf3bZ3UA1sD+YfkFtfw1lOeWGfK6mmm3WmD5/mOIPpXoFJpKmAXOAs0aqc0TEeHlePSlve4Wk6yVNsT0w8h39w/bHaoezgPNsP9Or+kRENPO8CSgAti/uZkXGg+17gHt6XY+IiLpuLV8/3rKWV0REH3ACSkREdEI/ztpqVwJKRESP2ZNjDGXir5ccERF9IS2UiIg+kDGUiIjogMzyioiIDkkLZRLzJvH041N7XY2WPfDArr2uQtv+YZcRF1noK6/e9v5eV6Ft8y5qacm7vnPH/+h1DcbXZHlSPoPyERG95mqmV7tbKyQdU9ZbvFfSeU3OzyoroayQdJukY0v6O8pLDm8vX986UllpoURE9IFuPIciaQrVWobvANYBt0haaHt17bJPAZfbvkjS/sAiYDbVeovvtv2ApAOAxcDuw5WXgBIR0WOma2MohwD32r4PQNJlVKu31wOKgR3L/k7AA1Ct4Vi7ZhUwXdI02/X3WG0mASUioudGPctrhqRlteMF5c2zg3YH6oN/66hWYK+bDyyRdCawHfD2JuW8H1gxXDCBBJSIiL7Q6phIgw225wxzvlmUaizpROAS25+X9Abgm5IOsL0JQNKrgP8HOGqkyiSgRET0gS51ea0D9qgdz6R0adWcQnn/lO2by9t5ZwAPSpoJfBf4c9u/HKmwzPKKiOixataW2t5acAuwj6Q9JU2lesvuwoZrfgW8DUDSK4HpwHpJL6R6u+0nbP97K4UloERE9IFuvAK4vEzwDKoZWndSzeZaJekzkt5TLvso8F/LK9e/BZxk2+W+lwP/p6SVZXvJcOWlyysiog+McgylhXy9iGoqcD3t/Nr+auBNTe77b8B/a6esBJSIiD6QpVciImLMTMtjIn1tTGMokraRdIOkvSUtLWlHSnqk9LfdJunaofrdJJ0ladsxlD9f0rlDnFvbJG2qpB9LSiCNiL7iUWz9ZqyD8icDVwIDDek32j7I9oFUswxOH+L+s4BRB5R22X4auA740/EqMyLi+WKsAWUecDVVQHmo8aQkATsADzc59zfAbsD1kq4vaRdJWiZplaRP165dK+nTkn5eFirbr5bV/pKWSrqv5Dlo/RB1vqrUOyKiP3Rv2vC4GnVAKXOa97K91vb9tt9XO32EpJVU85vfDlzceL/tL1E9YDPX9tyS/Mny1OeBwFskHVi7ZYPt1wEXAfVurv2Ao6nWrPk7SS8o+b9+iKrfATQ9J+m0EtCWDfz+8WE/f0RER02CPq+xtFBmABuHODfY5bUH8E/A51rM808k/RxYAbwK2L927srydTnVSpiDrrH9lO0NwIPAsC8GsT0APC1phybnFtieY3vOlB22a7HKERFj97xuoQBPUj1ROZKFwJsBJC0ug/Vfb7xI0p5ULY+3lbGXaxryH1yUbIDNZ6fVFytrPDeUacAfWrguImJcdOt9KONp1LOdbD8saYqk6baH++V8OPDLcs/RDed+TzXGsoFq+eTHgUck7Qq8E1g62vrVSbrL9n5l/8XAetv/2Ym8IyLGqovL14+rsU6fXUIVMK5tSB8cQxHwCHDqEPcvAL4v6Te250paQbXu/n1AS2vHjETSDDZfcXMuDU+NRkT0lIEEFC4EzqEWUGwvpXpJy4hsfxn4cu34pCGum13bXwYcWfbnN1x3QJPbD6N6Y9mgDwKfaKV+ERHjpR+7sNo1poBie0V5F/GUMtjdd2z/2+B+mZl2le27e1iliIgtPd8DCoDtLaYE96vyYOOlva5HRMTm+nPWVruyBElERD9ICyUiIsbMmeUVERGdkhZKRER0RlooERHRCWmhRERERySgRETEmOVJ+clt660H2OUlj/S6Gi3buO24vaesY3afusVrcvra51Yf1esqtG3rt2zxmqKIrklAiYjoA5Nh6ZWxvrExIiI6oUsv2JJ0jKS7Jd0r6bwm52eVJbRWSLpN0rG1c58o990tqXG1+C2khRIR0Q+6MIYiaQrV4rjvANYBt0haaHt17bJPAZfbvkjS/lSrsc8u+ydQvexwN+BaSfsOt25jWigREX1Abn9rwSHAvbbvK2sZXgYc13CNqd5HBdVK8Q+U/eOAy8obcdcA95b8hpQWSkREr43+HfEzJC2rHS+wvaB2vDtwf+14HXBoQx7zgSWSzgS2A95eu/enDffuPlxlElAiInpOo+3y2mB7zvAZb6ExdJ0IXGL785LeAHxT0gEt3ruZBJSIiH7QnVle64A9asczea5La9ApwDEAtm+WNB2Y0eK9m8kYSkREP+jOLK9bgH0k7VleMHgCsLDhml8BbwOQ9EpgOrC+XHeCpGmS9gT2Af5juMLSQomI6AddaKHYfkbSGcBiYApwse1Vkj4DLLO9EPgo8DVJZ5danGTbwCpJlwOrgWeA00d6M28CSkREr3Vx6RXbi6imAtfTzq/trwbeNMS9nwU+22pZCSgREX2gxWnAfa1jYyiStpF0g6S9JS0taUdKekTSyvIE5rWSXjLGcuZLOneEa46UdEmT9Fc3S4+I6LkuPSk/njo5KH8ycCXQ2Md2o+2DbB9INUB0+kgZlac7O8727cBMSbO6kX9ExPNZJwPKPOBqqoCyxRKnkgTsADRdYlbSWknnS/oJcHxp6fxA0nJJN0rar8k9SyXNKfszJK0tp54Ghloq+HtUMx0iIvpGl56UH1cdGUMp09H2sr22JL2vdvoISSuBFwOPA//HMFn9wfbhJc/rgL+0fY+kQ4GvAm9tpT62bwJuGuL0MuA84HNNPsdpwGkAU1+yY+PpiIjuyftQnjUD2DjEuRttvwtA0sepfpH/5RDXfrtctz3wRuCKqmEDwLQO1fVBqoXOtlCWLFgAsN0+L+3D+B8Rk1Kfjom0q1MB5Umqh2FGshD4VwBJi4FdqeZCn1rOP16+bgVstH3QCPk9w3Pddq2UP3jdky1eGxERLerIGIrth4Ep5ZH94RwO/LLcc3QZrD+18SLbjwJrJB0P1fiLpNc0yW8tcHDZ/0CzAiUdIunSWtK+wB0j1DMiYnxlltdmllAFjEZHlGnDtwIfonoqsxXzgFPKfavYcsllgAuAv5J0E1W3WzOz2LxFMhe4psU6RESMiwzKb+5C4Bzg2sEE20up1tcfke3ZDcdrKAuWNaTPr+3fBRxYO/2pJlkfSvWCGSRNA+YAZ7VSp4iIcdOHAaJdHQsotleU10hOGWm9l/Fk+2O1w1nAebaf6VV9IiKaSkDZnO2LO5lfp9m+B7in1/WIiKjr1y6sdmUtr4iIfpDnUCIioiPSQomIiE5Il1dERHRGAkpERIxZBuUjIqJjElAiIqIjElAmr4FNW7HxsW17XY2WbRro5Co64+MbX31nr6vQlu99fIs3HvS9v5jVbDWkCWBTrysw/iZDl9fE+y0UERF9KS2UiIh+kBZKRESM2ShWGm61i0zSMZLulnSvpPOanP9CWRF+paRfSNpYO/c5Sask3SnpS6q98bCZtFAiIiYpSVOoVlt/B7AOuEXSQturB6+xfXbt+jOB15b9NwJv4rkV3X8CvAVYOlR5aaFERPSD7rxg6xDgXtv32X4auIzm75YadCLwrVqNpgNTqV7B/gLgt8MVloASEdEPRhdQZkhaVttOa8h1d+D+2vG6krYFSS8D9gR+BGD7ZuB64DdlW2z7zuE+Qrq8IiJ6TIx62vAG23NGyLrRUCWdAHxn8H1Wkl4OvBKYWc7/UNKbbf94qMLSQomI6Afd6fJaB+xRO54JPDDEtSfwXHcXwHuBn9p+zPZjwPeBw4YrLAElIqLXujfL6xZgH0l7SppKFTQWNl4k6RXAzsDNteRfAW+RtLWkF1ANyA/b5ZWAEhHRD7rQQimvOz8DWEwVDC63vUrSZyS9p3bpicBltuu5fgf4JXA7cCtwq+3vDVdexlAiIvpBlx5stL0IWNSQdn7D8fwm9w0Af9FOWS21UCRtI+kGSXtLWlrSjpT0SHkY5jZJ10p6yRD3L5U0p+wvkvTCdirZrlK3S5qkv7pZekREr3Xrwcbx1GqX18nAlcBAQ/qNtg+yfSBVX93pI2Vk+1jbG0e6brQkDdnqsn07MFPSrG6VHxExKt0ZlB9XrQaUecDVVAHlocaT5XH8HYCHR8pI0lpJMyTNLo/zf6082r9E0jblmr0l/UDSckk3StqvpL9b0s8krSgtol1L+nxJCyQtAS4FngYeGaIK36MamIqI6A+jCSYTMaCUmQF72V5r+37b76udPkLSSqrZAG8HLm6z/H2Ar9h+FbAReH9JXwCcaftg4FzgqyX9J8Bhtl9L9cTn39byOhg4zvYHbd9k+yNDlLkMOGKIz3ra4ANCA48+3uZHiYgYvcnQ5dXKoPwMql/2zdxo+10Akj4OfA74yzbKX2N7ZdlfDsyWtD3wRuCK2jpk08rXmcC3Jb2UajmANbW8Ftp+soUyHwR2a3bC9gKqYMb0vXfvw29XRExak+A3TitdXk9SrecykoXAmwEkLS6D9V8f4Z6navsDVAFuK2BjGZsZ3F5ZrvkycKHtV1PNPqjXq9UmxXSqzxQR0TcmQwtlxIBi+2FgiqSRgsrhVHOWsX10CQSntlsh248CayQdD9X4jKTXlNM7Ab8u+x9uJT9Jh0i6tJa0L3BHu/WKiOiq58MYSrGEKmA0OqK0RG4FPgR8tEP1mgecUvJdxXOrY86n6gq7EdjQYl6z2LxFMhe4pkP1jIgYu0kyKN/qg40XAucA1w4m2F5K1WIYke0ja/uzy+4G4IBa+gW1/TXAMU3yuZpqtllj+vxhij+U6n0ASJoGzAHOaqXeERHjQTRfxXGiaSmg2F4h6XpJUwZXopwobH+sdjgLOK8sRxAR0T/6sMXRrpaXXrHd7pTgvmP7HuCeXtcjImIyylpeERF9oB9nbbUrASUioh8koEREREckoERExJj16YOK7UpAiYjoBwkoERHRCWmhREREZySgRER03l7/8n/1ugrjLi2USeyAnV/KsuM/1etqTG4T7jVnZ/e6Am374aZe16B9z8dg0q9rc7UrASUioh8koERExFiJydHl1ery9RER0U1dWr5e0jGS7pZ0r6Tzmpz/QnkNyUpJv5C0sXZulqQlku6UtFrS7OHKSgslIqIPyJ1vokiaQvX6jncA64BbJC20vXrwGttn164/E3htLYtLgc/a/mF5Pfuwo3JpoURE9Fr3XrB1CHCv7ftsPw1cxnMvLGzmROBbAJL2B7a2/UMA24/ZfmK4whJQIiL6wCjfKT9D0rLadlpDtrsD99eO15W0LcuXXgbsCfyoJO0LbJR0paQVkv5HafEMKV1eERH9YHQ9XhtszxnmfLMXQQ5V0gnAd2ovUdwaOIKqC+xXwLeBk4B/HKqwtFAiIiavdcAeteOZwANDXHsCpburdu+K0l32DHAV8LrhCktAiYjoA6Ps8hrJLcA+kvaUNJUqaCzcomzpFcDOwM0N9+4saZdy/FZgdeO9dQkoERH9oAuD8qVlcQawGLgTuNz2KkmfkfSe2qUnApfZz001K11f5wLXSbqdqvvsa8OVN6YxFEnbAD8ATgb+0faRtXNfBD4A7GG76VQzSWcBC0aaOTBM+fOBx2xf0OTcWtuzG9KmAtcCby3/0BERvdfF96HYXgQsakg7v+F4/hD3/hA4sNWyxtpCORm4EhioJ0raCngv1eyCNw9z/1nAtmOsQ8vKtLnrgD8drzIjIlrSpQcbx9NYA8o84GqqgPJQLX0ucAdwEVVTaguS/gbYDbhe0vUl7aIy9W2VpE/Xrl0r6dOSfi7pdkn71bLaX9JSSfeVPAetH6LOV5V6R0T0hcGlV7owhjKuRh1QSvfRXrbX2r7f9vtqpwcfjvku8C5JL2i83/aXqGYbzLUd9FuoAAARnklEQVQ9tyR/skyBOxB4i6R6U2uD7ddRBalza+n7AUdTPcDzd4Nl2X79EFW/A2h6TtJpg/O5168fKh5FRHSB3f7WZ8bSQpkBbGxMLIHmWOAq248CPwOOajHPP5H0c2AF8Cpg/9q5K8vX5cDsWvo1tp+yvQF4ENh1uALKQNPTknZocm6B7Tm25+yyyy5N7o6I6I7J0EIZy6D8k8D0JunHADsBt0uCaozkCeAaSYupfuEvs31q/SZJe1K1PF5v+2FJlzTk/1T5OtBQ76dq+43nhjIN+EML10VEdF+fjom0a9QBpfzSnyJpuu36L+cTgVNtD64Hsx2wRtK2to9uyOb3wA7ABmBH4HHgEUm7Au8Elo62fnWS7rK9X9l/MbDe9n92Iu+IiE7QBHwZWqOxDsovAQ4fPJC0LdV4xjWDabYfB34CvLvJ/QuA70u63vatVF1dq4CLgX8fY90G6zSDzZcfmEvDFLqIiJ6bBLO8xrqW14XAOVTPdlCeJ3lR40UNA/b19C8DX64dnzTEdbNr+8uAI8v+/IbrDmhy+2FUyzcP+iDwiWblRET0Sj+OibRrTAHF9gpJ10uaUltQrK/Y/rfB/TJh4Crbd/ewShERmzN9OWurXWNebdj2xZ2oyHgoDzZe2ut6REQ0et63UCIiokMSUCIiYqwGn5Sf6BJQIiJ6rU+ffG9Xlq+PiIiOSAslIqIPpMsrIiI6IwElIiI6IS2UiIgYOwObJn5ESUCJiP6ikS+ZlCZ+PElAiYjoB+nyioiIzpgEz6EkoERE9IHJ0ELJg40REb02mnehtBiAJB0j6W5J90o6r8n5L0haWbZfSNrYcH5HSb+WdOFIZaWFEhHRY9VaXp1vokiaQvU+qHcA64BbJC20vXrwGttn164/E3htQzZ/D9zQSnlpoURE9INNo9hGdghwr+37yus7LgOOG+b6E4FvDR5IOhjYlertvCNKQImI6AOy296AGZKW1bbTGrLdHbi/dryupG1ZvvQyYE/gR+V4K+DzwMda/Qzp8oqI6LXRvyN+g+05w5xv9lTPUCWdAHyn9vbdvwYW2b5fau3hoASUiIie69ry9euAPWrHM4EHhrj2BOD02vEbgCMk/TWwPTBV0mO2txjYH5SAEhHRB7o0bfgWYB9JewK/pgoaH9yibOkVwM7AzYNptufVzp8EzBkumEDGUCIi+sPgS7ba2UbM0s8AZwCLgTuBy22vkvQZSe+pXXoicJk9tmZSxwKKpG0k3SBpb0lLG859scxjHnN5kuZLOneEa46UdEmT9Fc3S4+ImKxsL7K9r+29bX+2pJ1ve2HtmvnDtT5sX2L7jJHK6mQL5WTgSmCgnliCyHupZhq8uZWMytzpjrN9OzBT0qxu5B8RMSoGbWp/6zedDCjzgKupAspDtfS5wB3ARVTNqqYkrZV0vqSfAMeXls4PJC2XdKOk/Zrcs1TSnLI/Q9Lacupp4JEhivoeVT9iRET/6EKX13jrSECRNBXYy/Za2/fbfl/t9OCDMt8F3iXpBcNk9Qfbh9u+DFgAnGn7YOBc4Kut1sf2TbY/MsTpZcARQ3yO0wbnc69fv77V4iIixq5LS6+Mp07N8poBbGxMLIHmWOBs27+X9DPgKOCaIfL5drlve+CNwBW1+c/TOlTXB4Hdmp2wvYAqkDFnzpw+/HZFxGTVjaVXxlunAsqTwPQm6ccAOwG3l8CwLfAEcI2kxVSP9C+zfWq5/vHydStgo+2DRij3GZ5rZTUrv5nppb4REf1jEgSUjnR52X4YmCKp8Zf6icCptmfbnk31WP9Rkra1fbTtg2rBpJ7fo8AaSccDqPKaJkWvBQ4u+x9oVjdJh0i6tJa0L9WYTkREfzDdWstrXHVyUH4JcPjggaRtgaOpdW/Zfhz4CfDuFvKbB5wi6VZgFc0XNLsA+CtJN1F1uzUzi81bJHMZusstImLcifbX8erHLrJOPil/IXAOcC2A7SeAFzVe1DBgX0+f3XC8hqrLrPG6+bX9u4ADa6c/1STrQ6mWb0bSNGAOcNZwHyQiYtz1YYBoV8cCiu0Vkq6XNKW2uFjP2a6vlDkLOK88PRoR0T8SUDZn++JO5tdptu8B7ul1PSIiNjM4hjLBZXHIiIg+0I9jIu1KQImI6AcJKBERMXb9uZRKuxJQIiJ6zSSgREREh2RQPiIiOmEyDMrnjY0REdERaaFERF/Z9FRX3q/X/yZBCyUBJSKi1wxsSkCJiIgxy7ThiIjolASUiIjoiEkQUDLLKyKi1wbHUNrdWiDpGEl3S7pX0nlNzn9B0sqy/ULSxpJ+kKSbJa2SdJukPx2prLRQIiJ6zuDOP9koaQrV+6DeAawDbpG00PbqZ0u2z65dfybw2nL4BPDntu+RtBuwXNJi2xuHKi8tlIiIfmC3v43sEOBe2/fZfhq4jOZvvx10IvCtqjr+RXnlB7YfAB4EdhmusLRQIiJ6bfTThmdIWlY7XmB7Qe14d+D+2vE6qrfYbkHSy4A9gR81OXcIMBX45XCVSUCJiOgHoxuU32B7zjDn1aykIa49AfhO4xt3Jb0U+CbwYXv4frkElIiIftCdWV7rgD1qxzOBB4a49gTg9HqCpB2Ba4BP2f7pSIVlDCUioudGMX7SWgC6BdhH0p6SplIFjYWNF0l6BbAzcHMtbSrwXeBS21e0UlhLAUXSNpJukLS3pKUN574o6deShsxL0lJJc8r+IkkvbKXc0ZJ0pKRLmqS/ull6RERPGdi0qf1tpGztZ4AzgMXAncDltldJ+oyk99QuPRG4zN4sSv0J8GbgpNq04oOGK6/VLq+TgSuBxr61rYD3Ug36vBlYOlJGto9tscxRkTTkZ7J9u6SZkmbZ/lU36xER0ZYuPdhoexGwqCHt/Ibj+U3u+2fgn9spq9Uur3nA1VQB5aFa+lzgDuAiqgg3IklrJc2QNFvSnZK+Vh6cWSJpm3LN3pJ+IGm5pBsl7VfS3y3pZ5JWSLpW0q4lfb6kBZKWAJcCTwOPDFGF71E1+yIi+kd3urzG1YgBpfSj7WV7re37bb+vdnpwzvJ3gXdJekGb5e8DfMX2q4CNwPtL+gLgTNsHA+cCXy3pPwEOs/1aqvnUf1vL62DgONsftH2T7Y8MUeYy4IghPutpkpZJWrZ+/fo2P0pExGiN4in5PlyduJUurxlUv+w3UwLNscDZtn8v6WfAUVQzAlq1xvbKsr8cmC1pe+CNwBXSszPeppWvM4Fvl2lsU4E1tbwW2n6yhTIfBHZrdqLM314AMGfOnP77bkXE5GQYYUbuhNBKQHkSmN4k/RhgJ+D28ot/W6pH9a+RtBjYFVhm+9Rh8n6qtj8AbEPVatpou9ngz5eBf7C9UNKRwPzaucdb+CxQfZZWAk9ERLRhxC4v2w8DUyQ1BpUTgVNtz7Y9m+oJy6MkbWv7aNsHjRBMhirvUWCNpOMBVHlNOb0T8Ouy/+FW8pN0iKRLa0n7Uo37RET0j0nQ5dXqoPwS4PDBA0nbAkdT696y/TjVGMe7O1CvecApkm4FVvHc2jPzqbrCbgQ2tJjXLDZvkcylvW65iIjumwSD8q1OG74QOAe4FsD2E8CLGi9qGLCvpx9Z259ddjcAB9TSL6jtr6HqUmvM52qq2WaN6fOHqfuhVKttImkaMAc4a5jrIyLGl93ScyX9rqWAYnuFpOslTWlc56Xf2f5Y7XAWcF552Ccion/0YYujXS2v5WX74m5WZDyUpZjv6XU9IiIa+fnSQomIiG7qzzGRdiWgRET02ujfh9JXElAiIvrB8+TBxoiI6CIDTgslIiLGzE4LJSIiOiMtlIiI6IxJ0EKRJ8FUtW6QtB74313IegatLxvTLyZanSdafSF1Hg/drO/LbO8y2psl/YCqfu3aYHuLVUV6JQFlnElaZntOr+vRjolW54lWX0idx8NEq+9E1OrikBEREcNKQImIiI5IQBl/C3pdgVGYaHWeaPWF1Hk8TLT6TjgZQ4mIiI5ICyUiIjoiASUiIjoiAWWMJG0j6QZJU8rxhyXdU7YR33sv6XhJqyRtkjSnlv5qSZd0ql4N56ZJ+rakeyX9TNLsIfJYK+l2SSslLWuhzHmSbivbTZJeU9KnSvqxpK0bru9FHY8r9VspaZmk+qutm37vJF0raecW8u7Wz8JsSU+WOq+U9D/brVuX6vv3tX/LJZJ2K+mS9KXyvbtN0utK+i7leYuOkGRJn68dnytpfqfyj1GwnW0MG3A68JGy/yLgvvJ157K/8wj3vxJ4BbAUmNNw7lpg1ljr1eTcXwP/s+yfAHx7iOvWAjPaKPONg58XeCfws9q5vwPm9UEdt+e5scMDgbtG+t4BHwY+2aufBWA2cMcQ97RUty7Vd8fa/t/Uvl/HAt8HBBzW8HPwT8CbRlPfJuX/AVgz+P0HzgXmdyLvbKPb0kIZu3k89577o4Ef2n7I9sPAD4Fhn2K1faftu4c4/T2qX6ZjrVej44BvlP3vAG+TpFGW8yzbN5XPDfBTYGbt9FWlTr2u42Muv32A7agWeoXhv3cLgRNbyL6bPwtDabVuzYy1vo/WDuv/lscBl7ryU+CFkl5azjX7ORitZ6hmbp3deELSyyRdV1pI10maVdIvKa2nmyTdJ+kDtXs+JumWcs+nO1TH55UElDGQNBXYy/bakrQ7cH/tknUlbbSWAUd0oF6Nnq2n7WeAR4AXN7nOwBJJyyWd1mY1TqH6K3XQHcDr+6GOkt4r6S7gGuDkxvKKZ7935RfsNEnNyh/q83T6Z2FPSStKF9WzPxOt1K2b9ZX0WUn3UwWJ81vIa1Q/08P4CjBP0k4N6RdSBbUDgf8FfKl27qXA4cC7gP9ePsdRwD7AIcBBwMGS3tzBej4vJKCMzQxgY+242V/QY5mX/SCw2yjua6xXo1br+Sbbr6Pqvjq91f/BJM2lCigffzZzewB4WtIOva6j7e/a3g/4Y+DvWyxvpO9FN38WfkPV9fla4BzgXyTt2EbdmulIfW1/0vYeVL+0z2ghr9H+TA9V/qPApVRdbnVvAP6l7H+TKoAMusr2JturgV1L2lFlWwH8HNiPKsBEGxJQxuZJYHrteB2wR+14JvDAGPKfXsoYU73KX5ErJa0sSc/WswyU7wQ81JiJ7QfK1weB71L99TYsSQcCXweOs/27htPTqPq9e1rH2r0/BvaWNIORv3cjfS+69rNg+6nBf0vby4FfAvu2UbdmOl3ffwHe30Jeo/2ZHs7/S/UHzHbDXFMPjk/V9lX7+n/bPqhsL7f9jx2u56SXgDIGpbthiqTB/zEXA0dJ2rnMvDmqpCHpUkkt/7Ir9qXqKhpTvcpfkQfZPqhcspBqMBfgA8CPauMKlPpuN9iakLRd+Sx3lOMzJJ1Bg9JPfSXwIdu/aDj3YmC97f/scR1fPjgWU2YfTQV+x/DfOwF/RDUBoKlu/iyU2VGDM7H2ovrL+b5W69at+kqq/wX/HuCusr8Q+PMy2+sw4BHbvynnRvUzPcJneQi4nCqoDLqJ58Yf5wE/GSGbxcDJkrYHkLS7pJd0sp7PC72eFTDRN+AfgbfXjk8G7i3bf6mlrwT2aHL/e6n+onsK+C2wuHbuQuDdnahXw7npwBWljv9B1ZcOVVfEorK/F3Br2VZRm0lU6nVik3y/DjxcPutKYFnt3AeAz/dBHT9erl0J3Awc3sL3bg7wr736WaD6y39V+Zw/r/9MtFq3LtX3X6mCw21UE0h2L+miGtv4JXA7m89YOxc4s0P/7z1W298VeIIyy4tqZtyPSt2uo8yWBC4BPjBEHh8p9b29/Gzs3Yl6Pp+2nldgom/Aa4FvjnDNjsAVbeY7jWqm1NbdqtcYPvO/AVPbvOdK4BX9XMdh8voi8LZe/Sx0om59VN8fM8J05GwTd0uX1xjZXgFcryYP59WuedT28W1mPQs4z9UMp67Ua7Rsv8v2061eX2YUXeWGKbH9VMcR3GH7uhbK7NbPwpjrNkRdxrW+knYB/sHPTS2PSSaLQ0ZEREekhRIRER2RgBIRER2RgBIRER2RgBIRER2RgBIRER3x/wNeKAce3G6sLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pcolor(r_test)\n",
    "plt.yticks(np.arange(0.5, len(r_test.index), 1), r_test.index)\n",
    "plt.xticks(np.arange(0.5, len(r_test.columns), 1), r_test.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8115277777777777,\n",
       " 0.8129166666666666,\n",
       " 0.8455555555555555,\n",
       " 0.8593055555555557,\n",
       " 0.8159722222222222,\n",
       " 0.8077777777777778]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promA=r_test.loc[:,'None'].mean()\n",
    "promB=r_test.loc[['B-tanh','B-relu','B-linear'],:].mean().mean()\n",
    "promC=r_test.loc[['C-tanh','C-relu','C-linear'],:].mean().mean()\n",
    "prom=[promA,promB,promC]\n",
    "prom\n",
    "promk1=r_test.loc[:,'(0, 1)'].mean()\n",
    "promk2=r_test.loc[:,'(-0.5, 2)'].mean()\n",
    "promk3=r_test.loc[:,'(-0.5, 30)'].mean()\n",
    "promk4=r_test.loc[:,'(0, 15)'].mean()\n",
    "promk5=r_test.loc[:,'(0, 30)'].mean()\n",
    "promk6=promA\n",
    "promK=[promk1,promk2,promk3,promk4,promk5,promk6]\n",
    "promK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.76, 0.9)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "x1=['A','B','C']\n",
    "x2=['(0,1)','(-0.5,2)','(-0.5,30)','(0,15)','(0,30)','None']\n",
    "plt.bar(x1,prom)\n",
    "plt.ylabel('Precision promedio')\n",
    "plt.xlabel('Arquitectura')\n",
    "plt.ylim(0.76,0.9)\n",
    "plt.subplot(122)\n",
    "plt.bar(x2,promK)\n",
    "plt.ylabel('Precision promedio')\n",
    "plt.xlabel('(k0, k1)')\n",
    "plt.ylim(0.76,0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
